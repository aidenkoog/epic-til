# Concepts, Features, Types and Pros and Cons
 
Organize concepts, features, types and Pros and Cons
 
## Database
 
- 데이터베이스(Database)의 개념과 필요성
    - 개념
        - 데이터베이스(Database, DB)는 체계적으로 정리된 데이터의 집합으로, 데이터를 효율적으로 저장, 관리, 검색, 수정, 삭제할 수 있도록 만든 시스템
        - 컴퓨터 시스템에서 데이터를 지속적으로 저장하고 활용할 수 있도록 설계된 구조이며, 다양한 애플리케이션이 데이터를 공유할 수 있도록 한다
        - 데이터베이스는 데이터를 저장하는 "디지털 기록장"
            - 예: 은행 고객 정보, 쇼핑몰의 주문 내역, SNS의 게시글 등이 데이터베이스에 저장됨
    - 필요성
        - 데이터의 일관성, 보안성, 접근성 보장 가능
        - 데이터 무결성(일관성) 유지
            - 데이터베이스는 중복 데이터 최소화 및 데이터 정합성(Consistency) 유지
            - 예: 은행 시스템에서 한 고객의 계좌 정보가 여러 곳에서 동일하게 유지됨 (잔액 데이터 불일치 방지)
        - 데이터 보안 및 접근 제어
            - 데이터베이스는 사용자별 권한 관리가 가능하여, 불법적인 데이터 접근을 방지
            - 예: 온라인 쇼핑몰에서 관리자는 모든 정보를 볼 수 있지만, 일반 사용자는 자신의 주문 정보만 조회 가능
        - 데이터 검색 및 처리 속도 향상
            - 대량의 데이터를 빠르게 검색, 정렬, 분석할 수 있음
            - 인덱스(Index)와 SQL을 활용하여 효율적인 검색 가능
            - 예: 수백만 개의 고객 정보 중 특정 고객의 데이터를 즉시 검색
        - 데이터 공유 및 동시 접근 지원
            - 여러 사용자가 동시에 데이터베이스에 접근 가능
            - 동시 수정 시 트랜잭션(Transaction) 관리를 통해 데이터 정합성 유지
            - 예: 온라인 예약 시스템에서 여러 사용자가 동일한 좌석을 예약하지 않도록 관리
        - 데이터 백업 및 복구 기능
            - 시스템 장애, 서버 오류, 해킹 등으로 인한 데이터 손실을 방지하기 위해 자동 백업 및 복구 기능 제공
            - 예: 클라우드 데이터베이스를 사용하면 실시간 데이터 백업이 가능하여 장애 발생 시 데이터 복구 가능
    - 데이터베이스와 파일 시스템 비교
        - 데이터 구조
          - DB: 정형화된 구조(SQL 테이블)
          - File: 비정형 구조(텍스트, 로그 파일)
        - 검색 속도	
          - DB: 빠름 (인덱스, SQL 쿼리 지원)	
          - File: 느림 (파일을 직접 검색)
        - 데이터 중복
          - DB: 최소화 (정규화)
          - File: 중복 발생 가능
        - 보안 관리
          - DB: 강력한 보안 기능 제공
          - File: 파일 단위 접근 제한
        - 동시 접근
          - DB: 다중 사용자 지원 (트랜잭션 관리)
          - File: 동시 수정 어려움
        - 백업 및 복구
          - DB: 자동 백업 및 복구 지원
          - File: 수동 백업 필요
    - 데이터베이스의 유형
        - 관계형 데이터베이스(RDB, Relational Database)
            - 데이터를 테이블(행과 열) 형태로 저장
            - SQL(Structured Query Language) 사용
            - 무결성, 정규화, 트랜잭션 관리가 강력
            - 예시: MySQL, PostgreSQL, Oracle, SQL Server
        - 비관계형(NoSQL) 데이터베이스
            - 구조화되지 않은 데이터(문서, 키-값, 그래프 등)를 저장
            - 대규모 데이터 처리에 유리, 스키마가 없음
            - 예시: MongoDB, Redis, Cassandra
        - 클라우드 데이터베이스
            - 클라우드 환경에서 운영되는 DB, 확장성 뛰어남
            - 예시: AWS RDS, Google Firebase, Azure SQL
    - 결론
        - 데이터베이스는 데이터를 체계적으로 저장하고, 효율적으로 관리하는 필수 시스템
        - 데이터 일관성, 보안, 빠른 검색, 다중 사용자 지원 등의 이유로 데이터베이스가 필수적으로 사용됨
        - 관계형(RDB)과 비관계형(NoSQL) 데이터베이스를 적절히 선택하여 활용 가능 

- 파일 시스템(File System)과 데이터베이스 시스템(DBMS)의 차이를 설명
    - 데이터베이스와 파일 시스템 비교
        - 데이터 구조
          - DB: 정형화된 구조(SQL 테이블)
          - File: 비정형 구조(텍스트, 로그 파일)
        - 검색 속도	
          - DB: 빠름 (인덱스, SQL 쿼리 지원)	
          - File: 느림 (파일을 직접 검색)
        - 데이터 중복
          - DB: 최소화 (정규화)
          - File: 중복 발생 가능
        - 보안 관리
          - DB: 강력한 보안 기능 제공
          - File: 파일 단위 접근 제한
        - 동시 접근
          - DB: 다중 사용자 지원 (트랜잭션 관리)
          - File: 동시 수정 어려움
        - 백업 및 복구
          - DB: 자동 백업 및 복구 지원
          - File: 수동 백업 필요

- 관계형 데이터베이스(RDBMS)의 개념과 주요 특징
    - 개념
        - RDBMS, Relational Database Management System
        - 데이터를 테이블 형태로 저장하고 각 테이블 관계(Relationship)를 정의하여 관리하는 데이터베이스 시스템
        - 각 테이블 간에는 기본 키(Primary Key)와 외래 키(Foreign Key)를 통해 관계 설정
    - 주요 특징
        - 테이블 기반 데이터 저장 (Table-based)
            - 데이터를 행(Row, Record)과 열(Column, Attribute)의 형태로 저장
            - 각 행은 한 개의 개체(예: 학생, 직원, 제품 등)를 나타냄
            - 각 열은 해당 개체의 속성을 정의
        - 데이터 무결성 (Data Integrity)
            - 기본 키(Primary Key): 테이블의 각 행을 고유하게 식별
            - 외래 키(Foreign Key): 다른 테이블과의 관계를 정의하며 데이터 일관성 유지
            - 제약 조건(Constraints)을 사용하여 데이터의 정확성과 일관성을 보장 (예: NOT NULL, UNIQUE, CHECK)
        - 데이터 중복 최소화 (Normalization)
            - 정규화(Normalization) 기법을 사용하여 데이터 중복을 최소화하고 데이터 무결성을 유지
            - 데이터의 일관성을 유지하고, 저장 공간을 절약
        - 관계 설정 가능 (Relational)
            - 테이블 간 기본 키(PK)와 외래 키(FK)를 통해 관계를 정의
            - JOIN 연산을 통해 여러 테이블의 데이터를 조합하여 원하는 정보를 조회 가능
        - SQL(Structured Query Language) 사용
            - 데이터 검색(SELECT), 삽입(INSERT), 수정(UPDATE), 삭제(DELETE) 등의 작업을 수행하는 표준 언어
            - 복잡한 쿼리를 작성하여 데이터를 쉽게 조작 가능
        - 트랜잭션 관리 (Transaction Management)
            - 트랜잭션(Transaction): 하나의 작업 단위(예: 송금 시 돈 빼기 + 돈 넣기)
            - ACID 특성을 준수하여 데이터의 일관성과 신뢰성을 보장
                - Atomicity (원자성): 모든 작업이 완료되거나, 전혀 수행되지 않아야 함
                - Consistency (일관성): 트랜잭션 수행 후 데이터의 무결성이 유지
                - Isolation (고립성): 트랜잭션은 서로 간섭하지 않아야 함
                - Durability (지속성): 트랜잭션이 완료된 후 데이터가 영구적으로 저장
        - 동시성 제어 및 백업/복구 기능
            - 다수의 사용자가 동시에 접근해도 데이터 충돌을 방지하는 동시성 제어(Concurrency Control) 제공
            - 장애 발생 시 데이터를 복구할 수 있는 백업 및 복구(Backup & Recovery) 기능 지원
    - 주요 관계형 데이터베이스 관리 시스템
        - MySQL
        - PostgreSQL
        - Oracle DB
        - Microsoft SQL Server
        - MariaDB
    - 관계형 데이터베이스(RDBMS) vs NoSQL 데이터베이스
        - 데이터 구조
            - RDBMS: 테이블(Table) 기반
            - NoSQL: 키-값(Key-Value), 문서(Document), 컬럼(Column) 등
        - 관계 지원
            - RDBMS: 기본 키/외래 키를 통한 관계 설정 가능
            - NoSQL: 관계가 없거나 느슨한 관계
        - SQL 사용 여부
            - RDBMS: SQL 사용 (표준화된 쿼리 언어)
            - NoSQL (다양한 쿼리 방식)
        - 확장성
            - RDBMS: 수직 확장(Scale-up) 중심
            - NoSQL: 수평 확장(Scale-out) 중심
        - 트랜잭션
            - RDBMS: ACID 준수
            - NoSQL: 대부분 Eventually Consistent
        - 사용 예시
            - RDBMS: 금융, ERP, 전자상거래
            - NoSQL: 빅데이터, IoT, 소셜미디어, 실시간 분석
    - 결론
        - 관계형 데이터베이스(RDBMS)는 데이터 무결성을 보장하고 복잡한 관계를 처리하는 데 적합
        - SQL을 사용하여 효율적으로 데이터 조작이 가능
        - 웹 애플리케이션, 금융, ERP 시스템 등 다양한 분야에서 필수적으로 사용

- 데이터베이스 관리 시스템(DBMS)의 개념과 주요 기능
    - DBMS (Database Management System) 개념
        - 데이터를 체계적으로 저장하고, 관리하며, 필요할 때 쉽게 조회하고 수정할 수 있도록 해주는 소프트웨어 시스템
    - DBMS의 역할
	    - 데이터를 안정적으로 저장하고 효율적으로 관리
	    - 여러 사용자들이 동시에 데이터를 안전하게 접근
	    - 데이터의 무결성(Integrity)과 보안(Security) 유지
	    - 대량의 데이터를 효율적으로 검색 및 처리
	    - 데이터 백업 및 복구 기능 제공
    - DBMS의 예시
	    - 관계형 DBMS(RDBMS): MySQL, PostgreSQL, Oracle, SQL Server
	    - NoSQL DBMS: MongoDB, Redis, Cassandra
    - DBMS의 주요 기능
        - 개요: DBMS는 데이터를 저장, 관리, 보호하는 여러 가지 기능을 제공
        - 주요 기능
            - 데이터 정의 (DDL: Data Definition Language)
	            - 데이터베이스 구조(스키마)를 정의하는 기능
	            - 테이블, 인덱스, 뷰 등을 생성, 수정, 삭제하는 역할
                - 예제 (SQL): CREATE TABLE users
            - 데이터 조작 (DML: Data Manipulation Language)
	            - 데이터를 삽입, 수정, 삭제, 조회하는 기능
	            - CRUD 연산 (Create, Read, Update, Delete) 제공
                - 예제 (SQL)
                    - INSERT INTO users
                    - SELECT * FROM users
                    - UPDATE users SET name
                    - DELETE FROM users WHERE
            - 데이터 제어 (DCL: Data Control Language)
	            - 데이터 접근 권한을 관리하는 기능
	            - 보안과 권한 제어를 위해 사용자 및 역할을 설정
                - 예제 (SQL): GRANT SELECT ON users / REVOKE INSERT ON users
            - 동시성 제어 (Concurrency Control)
	            - 다중 사용자가 동시에 데이터에 접근할 때 데이터의 일관성을 유지하는 기능
	            - 트랜잭션 충돌 방지 (예: 은행 계좌 입출금 처리 중 오류 발생 방지)
                - 트랜잭션 예제 (SQL)
                    - START TRANSACTION;
                    - UPDATE accounts SET
                    - COMMIT (모든 변경 사항을 저장)
                    - ROLLBACK (트랜잭션 중 오류 발생 시 변경 사항을 되돌림)
            - 데이터 무결성 (Integrity) 유지
	            - 데이터의 정확성과 일관성을 보장하는 기능
	            - 제약 조건(Constraints) 사용
	            - PRIMARY KEY: 기본 키 (중복 불가)
	            - FOREIGN KEY: 외래 키 (다른 테이블과 관계 유지)
	            - UNIQUE: 중복 방지
	            - CHECK: 특정 조건 만족 여부 검사
	            - NOT NULL: NULL 값 입력 방지
            - 백업 및 복구 (Backup & Recovery)
	            - 데이터 손실을 방지하기 위해 정기적으로 백업을 수행
	            - 장애 발생 시 데이터를 복구하는 기능 제공
                - 예제
                    - mysqldump -u root -p database_name > backup.sql
                    - mysql -u root -p database_name < backup.sql
            - 보안 및 접근 제어 (Security & Access Control)
	            - 사용자 인증(Authentication) 및 권한(Role) 관리
	            - 암호화(Encryption) 및 접근 제어(Access Control) 제공
    - DBMS의 장점
        - 데이터 무결성 유지: 데이터 정확성과 일관성을 유지
        - 동시 접근 가능: 여러 사용자가 동시에 데이터에 접근 가능
        - 보안 강화: 접근 권한 제어 및 데이터 암호화 지원
        - 백업 및 복구 가능: 장애 발생 시 데이터 복구 가능
        - 데이터 중복 최소화: 데이터의 중복 저장을 방지하고 공간 절약
    - 결론
	    - DBMS(Database Management System) 는 데이터를 효율적으로 저장, 관리, 보호하는 소프트웨어
	    - 주요 기능
            - 데이터 정의 (DDL) → 테이블 생성, 스키마 정의
            - 데이터 조작 (DML) → 데이터 입력, 수정, 삭제, 조회
            - 데이터 제어 (DCL) → 권한 관리, 보안 설정
            - 동시성 제어 → 여러 사용자가 동시에 접근 가능
            - 데이터 무결성 유지 → 일관성 있는 데이터 저장
            - 백업 및 복구 → 장애 발생 시 데이터 복구 가능
            - 보안 및 접근 제어 → 사용자 인증 및 접근 권한 관리
        - DBMS는 데이터 관리의 핵심이며, RDBMS와 NoSQL 등 다양한 형태로 발전
        - 효율적인 데이터 관리를 위해 기업 및 IT 시스템에서 필수적으로 사용됨

        
- 데이터 독립성(Data Independence)의 개념과 논리적 독립성과 물리적 독립성
    - 데이터 독립성(Data Independence) 개념
        - 데이터베이스(DB) 시스템에서 데이터의 논리적 구조와 물리적 구조가 변경되더라도 응용 프로그램이 최소한의 영향을 받도록 하는 특성
        - 응용 프로그램과 데이터 저장 방식 간의 결합도를 낮춰 유지보수성을 향상시키는 핵심 개념
        - 3단계 데이터베이스 구조(ANSI-SPARC DBMS 모델)를 기반으로 논리적 독립성과 물리적 독립성으로 구분

    - 논리적 독립성(Logical Independence) : 논리적 변경 > 응용 프로그램 영향 X
        - 개념
            - 논리적 독립성이란 데이터베이스의 논리적 구조(스키마)가 변경되더라도 응용 프로그램이 영향을 받지 않는 성질을 의미
            - 개념 스키마(Conceptual Schema)가 변경되더라도 외부 스키마(External Schema, 사용자 관점)가 영향을 받지 않아야 함

        - 논리적 독립성이 필요한 이유
	        - 사용자 요구사항 변경: 새로운 필드 추가, 관계 변경 등
	        - 데이터 모델의 확장성 확보: 기존 프로그램을 수정하지 않고 새로운 기능을 추가
	        - 애플리케이션 유지보수 비용 절감: 프로그램이 데이터 구조 변경에 덜 의존

        - 예제
	        - 기존 데이터 모델에서 고객(Customer) 테이블에 이메일(Email) 필드를 추가하더라도, 기존 애플리케이션이 영향을 받지 않도록 유지하는 것.
	        - 관계형 데이터베이스에서 뷰(View)를 활용하면 논리적 독립성을 높일 수 있음

    - 물리적 독립성(Physical Independence) : 물리적 방식 변경 > 논리적 구조 & 응용 프로그램 영향 X
        - 개념
            - 데이터의 물리적 저장 방식(파일 구조, 인덱스 등)이 변경되더라도 논리적 구조(개념 스키마)나 응용 프로그램이 영향을 받지 않는 성질을 의미
            - 내부 스키마(Internal Schema, 데이터 저장 방식)가 변경되더라도 개념 스키마(Conceptual Schema)가 영향을 받지 않아야 함

        - 물리적 독립성이 필요한 이유
	        - 하드웨어 성능 향상: 새로운 저장 장치(HDD → SSD)로 변경될 때 응용 프로그램이 영향을 받지 않아야 함
	        - 데이터베이스 최적화: 인덱스 추가, 파티셔닝 등 데이터 저장 방식을 변경해도 논리적 데이터 모델은 그대로 유지됨
	        - 스토리지 관리 비용 절감: 데이터 압축 방식 변경, 파일 구조 최적화 등이 가능

        - 예제
	        - 기존 데이터 파일이 B-Tree 인덱스에서 해시(Hash) 인덱스로 변경되더라도, 응용 프로그램이 영향을 받지 않는 것.
	        - 테이블을 다른 저장소로 옮겨도(SSD로 이동) 기존 SQL 쿼리는 변경 없이 실행됨.

    - 결론
	    - 데이터 독립성은 논리적 독립성과 물리적 독립성으로 나뉘며, 이를 통해 데이터베이스의 유연성과 확장성 확보 가능
	        - 논리적 독립성(Logical Independence): 데이터의 논리적 구조(개념 스키마) 변경이 발생해도 응용 프로그램이 영향을 받지 않도록 하는 것.
	        - 물리적 독립성(Physical Independence): 데이터의 물리적 저장 방식(파일 구조, 인덱스, 저장 장치 등) 변경이 있어도 논리적 구조는 유지되는 것.
	    - 궁극적인 목표: 애플리케이션이 데이터 저장 방식에 의존하지 않고 동작하도록 하여 유지보수를 쉽게 하고, 성능 최적화를 가능하게 하는 것.

- 데이터 모델(Data Model)의 개념과 주요 유형(계층형, 네트워크형, 관계형, 객체지향형)
    - 데이터 모델(Data Model) 개념
	    - 데이터 모델(Data Model)은 데이터를 구조화하고, 저장하며, 조작하는 방법을 정의하는 개념적 프레임워크
	    - 데이터베이스(DB)에서 데이터 간의 관계(Relationship), 제약조건(Constraint), 연산(Operation) 등을 정의하여 효율적인 데이터 관리가 가능하도록 함
	    - 3가지 주요 요소로 구성
	        - 구조(Structure): 데이터의 논리적 구조와 관계를 정의 (예: 테이블, 트리, 그래프)
	        - 연산(Operation): 데이터를 추가, 수정, 삭제, 조회하는 기능 정의 (예: SQL, CRUD 연산)
	        - 제약조건(Constraint): 데이터 무결성을 유지하기 위한 규칙 설정 (예: 기본키, 외래키)

    - 데이터 모델의 주요 유형 (계층형 > 네트워크형 > 관계형 > 객체지향형)
        - (1) 계층형 데이터 모델 (Hierarchical Data Model)
            - 개념
	            - 데이터를 트리(Tree) 구조로 구성하며, 부모-자식(Parent-Child) 관계를 가짐.
	            - 상위 데이터(부모)가 하위 데이터(자식)를 포함하는 1:N 관계를 형성함.
	            - IBM의 IMS(Information Management System, 1966년)에서 최초로 사용됨.

            - 특징
	            - 빠른 데이터 접근 가능 (트리 구조 탐색)
	            - 데이터 종속성이 높아 변경이 어려움
	            - 부모-자식 관계가 엄격하여 유연성이 낮음

            - 예시 (한 부모(부서)는 여러 자식을 가질 수 있지만, 자식(직원)은 하나의 부모(부서)만 가질 수 있음)
                ```
                회사
                ├── 인사부
                │   ├── 직원1
                │   ├── 직원2
                │   ├── 직원3
                ├── 재무부
                │   ├── 직원4
                │   ├── 직원5
                ```

            - 장점
	            - 데이터 검색 속도가 빠름 (인덱스 기반 탐색)
	            - 1:N 관계를 효율적으로 관리 가능

            - 단점
	            - 유연성이 부족 (데이터 구조 변경 어려움)
	            - 데이터 중복 문제 발생 가능 (중복 저장 필요)

        - (2) 네트워크형 데이터 모델 (Network Data Model)
            - 개념
	            - 그래프(Graph) 형태의 구조를 가지며, M:N(다대다) 관계를 지원하는 데이터 모델
	            - CODASYL(Database Task Group)이 1971년 제안함
	            - 레코드(Record)와 관계(Set)를 사용하여 데이터를 연결함

            - 특징
	            - 계층형 모델보다 유연하며, 다중 경로(M:N 관계) 지원
	            - 데이터 간 링크(Link)로 연결되어 탐색 가능
	            - 데이터 구조가 복잡하여 유지보수가 어려움

            - 예시 (학생과 과목은 M:N 관계로 연결될 수 있음)
                ```
                과목
                ├── 학생1
                ├── 학생2
                └── 학생3
                (학생들은 여러 개의 과목을 들을 수 있음)
                ```
            - 장점
	            - 다대다(M:N) 관계 표현 가능
	            - 데이터 검색이 빠름 (직접적인 링크 활용)

            - 단점
	            - 구조가 복잡하여 관리가 어려움
	            - 데이터 삽입/삭제 시 연결 관계를 고려해야 함 (링크 유지 부담)

        - (3) 관계형 데이터 모델 (Relational Data Model)
            - 개념
	            - 데이터를 테이블(Table, 릴레이션) 형태로 저장하고 행(Row)과 열(Column)으로 관리하는 모델.
	            - 에드거 F. 코드(Edgar F. Codd, 1970년)가 제안.
	            - SQL(Structured Query Language)을 사용하여 데이터를 조작함

            - 특징
	            - 2차원 테이블 기반으로 데이터 저장
	            - 데이터 무결성(Integrity) 및 정규화(Normalization) 적용 가능
	            - 기본키(Primary Key)와 외래키(Foreign Key)를 통해 관계 설정

            - 예시 (학생과 과목을 연결하는 별도의 테이블(중간 테이블, 관계 테이블)을 사용하여 M:N 관계를 관리)
                ```
                학생 테이블
                +--------+--------+----------+
                | 학번   | 이름   | 전공     |
                +--------+--------+----------+
                | 1001   | 홍길동 | 컴퓨터공학 |
                | 1002   | 김철수 | 전자공학  |
                +--------+--------+----------+
                ```
                ```
                과목 테이블
                +--------+----------+------------+
                | 과목코드 | 과목명  | 교수       |
                +--------+----------+------------+
                | CS101  | 데이터베이스 | 박교수   |
                | CS102  | 운영체제     | 이교수   |
                +--------+----------+------------+
                ```
                ```
                학생-과목 관계 테이블
                +--------+--------+
                | 학번   | 과목코드 |
                +--------+--------+
                | 1001   | CS101  |
                | 1002   | CS102  |
                +--------+--------+
                ```

            - 장점
	            - 데이터 중복 최소화 (정규화)
	            - 표준화된 SQL을 사용하여 데이터 조작이 용이
	            - 데이터 무결성(Integrity) 보장 가능

            - 단점
	            - 복잡한 쿼리 연산 시 성능 저하 가능
	            - 대규모 데이터를 다룰 경우 성능 튜닝 필요

        - (4) 객체지향형 데이터 모델 (Object-Oriented Data Model)
            - 개념
	            - 객체지향 프로그래밍(OOP) 개념을 데이터 모델에 적용한 방식
	            - 객체(Object), 클래스(Class), 상속(Inheritance), 캡슐화(Encapsulation) 개념을 활용
	            - 관계형 데이터베이스와 객체지향 개념을 통합하여 사용 가능 (예: OODBMS, ORDBMS)

            - 특징
	            - 객체(Object) 단위로 데이터를 저장
	            - 객체 간 상속(Inheritance) 및 다형성(Polymorphism) 지원
	            - 관계형 모델보다 복잡한 데이터 구조 표현 가능

            - 예시 (객체(Employee)로 데이터 관리, 상속 및 다형성 적용 가능)
                ```
                클래스: 직원(Employee)
                {
                    이름: 문자열;
                    나이: 정수;
                    부서: 문자열;
                    업무(): void;
                }
                ```
            - 장점
	            - 객체지향 프로그래밍과 호환 가능
	            - 복잡한 데이터 구조 표현 가능

            - 단점
	            - 관계형 모델보다 일반적인 활용도가 낮음
	            - SQL 대신 새로운 질의 언어 사용 필요

    - 결론
	    - 계층형, 네트워크형 데이터 모델은 과거에는 많이 사용되었으나, 현재는 거의 사용되지 않음.
	    - 관계형 데이터 모델(RDBMS)이 가장 널리 사용
        - 객체지향형 데이터 모델(OODBMS)은 특정 분야(예: CAD, 멀티미디어)에 활용됨
	    - 현대 시스템에서는 관계형 데이터베이스(RDBMS)가 표준적으로 사용되지만, 빅데이터 환경에서는 NoSQL과 객체지향형 DB도 증가하는 추세

- 데이터베이스 스키마(Database Schema)와 인스턴스(Instance)의 차이
	- 스키마(Schema):
		- 데이터베이스의 구조와 제약 조건을 정의한 틀로, 테이블, 속성, 관계, 제약 조건 등을 기술한 설계도이다. 
		- 변경이 거의 없고 정적(Static)이다.

	- 인스턴스(Instance):
		- 스키마에 따라 실제로 저장된 데이터의 집합으로, 시간에 따라 계속 변하며 동적(Dynamic)이다.
		- 즉, 스키마는 데이터의 틀이고, 인스턴스는 그 틀에 채워진 실제 데이터이다.

- DBMS의 주요 구성 요소 (DDL, DML, DCL, TCL)
	- DDL(Data Definition Language): 데이터 구조 정의
		- 예: CREATE, ALTER, DROP
	- DML(Data Manipulation Language): 데이터 조작
		- 예: SELECT, INSERT, UPDATE, DELETE
	- DCL(Data Control Language): 권한 제어
		- 예: GRANT, REVOKE
	- TCL(Transaction Control Language): 트랜잭션 제어
		- 예: COMMIT, ROLLBACK, SAVEPOINT

	- 각 언어는 데이터 정의, 처리, 제어, 보안 측면에서 서로 다른 역할을 수행한다.

- 데이터베이스 아키텍처 (1-Tier, 2-Tier, 3-Tier)
	- 1-Tier: 사용자와 데이터베이스가 같은 시스템에 존재, 단일 계층.
		- 장점: 간단한 구조
		- 단점: 보안, 확장성 낮음
	- 2-Tier: 클라이언트와 서버로 분리. 클라이언트는 UI 및 일부 로직 담당, 서버는 DB 처리.
		- 장점: 성능 좋고 구조 단순
		- 단점: 여러 클라이언트가 접속하면 서버 부담 증가
	- 3-Tier: UI(클라이언트), 애플리케이션 서버, DB 서버로 3단계 분리
	- 장점: 유지보수, 확장성, 보안 우수
	- 단점: 구조 복잡, 초기 비용 증가

- 데이터 무결성(Integrity) 개념과 주요 제약 조건
	- 무결성: 데이터의 정확성, 일관성, 신뢰성을 보장하는 제약 조건들의 집합이다.

	- 주요 제약 조건:
		- 기본키(Primary Key): 유일성 + NULL 불가. 한 테이블 내에서 레코드 식별
		- 외래키(Foreign Key): 다른 테이블의 기본키 참조. 테이블 간 관계 설정
		- 고유성(Unique): 중복 불허, NULL은 허용
		- 도메인 제약(Domain): 속성에 허용된 데이터 타입 및 값의 범위 제한
		- 체크(Check): 사용자 지정 조건 만족 여부 검증

- SQL(Structured Query Language)의 개념과 주요 기능
	- 개념:
		- SQL은 관계형 데이터베이스에서 데이터를 정의, 조작, 제어하기 위한 표준 질의 언어이다.

	- 주요 기능:
		- 데이터 정의: 테이블, 뷰, 인덱스 등 생성 및 수정 (DDL)
		- 데이터 조작: 데이터 조회, 삽입, 수정, 삭제 (DML)
		- 데이터 제어: 사용자 권한 부여 및 취소 (DCL)
		- 트랜잭션 처리: 데이터 일관성 유지 위한 작업 단위 제어 (TCL)

- 관계형 데이터 모델 개념과 주요 특징
	- 개념:
		- 관계형 모델은 데이터를 테이블(릴레이션) 형태로 표현하며, 각 테이블은 행(튜플)과 열(속성)로 구성된다.

	- 주요 요소:
		- 릴레이션(Relation): 테이블 구조
		- 튜플(Tuple): 한 행의 데이터(레코드)
		- 속성(Attribute): 열(필드)의 이름과 데이터 타입
		- 도메인(Domain): 속성이 가질 수 있는 값의 집합

	- 특징:
		- 데이터 간 관계를 테이블 간의 연결로 표현
		- 명확한 구조, 무결성 제어 용이, 표준화된 질의 언어(SQL) 지원

- 관계 대수(Relational Algebra)와 관계 해석(Relational Calculus)의 차이
	- 관계 대수(Relational Algebra):
		- 절차적 언어로, 어떻게 데이터를 얻을 것인지(How)를 명시한다. 연산자 기반으로 릴레이션을 조작하며, SELECT, PROJECT, JOIN, UNION 등이 포함된다.

	- 관계 해석(Relational Calculus):
		- 비절차적 언어로, 무엇을 원하는지(What)만 기술한다. 조건을 기반으로 원하는 데이터를 기술하며, 튜플 관계 해석(Tuple Relational Calculus)과 도메인 관계 해석(Domain Relational Calculus)로 나뉜다.

	- 차이점: 관계 대수는 연산 절차 중심, 관계 해석은 논리 표현 중심이다.

- SQL의 주요 명령어 (DDL, DML, DCL, TCL)의 개념과 차이
	- DDL (Data Definition Language):
		- 데이터베이스 구조 정의 (예: CREATE, DROP, ALTER)
	- DML (Data Manipulation Language):
		- 데이터 조작 (예: SELECT, INSERT, UPDATE, DELETE)
	- DCL (Data Control Language):
		- 접근 권한 설정 (예: GRANT, REVOKE)
	- TCL (Transaction Control Language):
		- 트랜잭션 처리 (예: COMMIT, ROLLBACK, SAVEPOINT)
	- 차이:
		- DDL은 구조 정의,
		- DML은 데이터 조작,
		- DCL은 보안 제어,
		- TCL은 일관성 유지를 위한 제어로 목적이 서로 다르다.

- 조인(JOIN)의 개념과 주요 유형
	- 개념:
		- 두 개 이상의 테이블을 연결하여 공통 속성을 기준으로 데이터를 통합하는 연산이다.
	- 주요 유형:
		- INNER JOIN: 조건을 만족하는 행만 반환
		- LEFT JOIN: 왼쪽 테이블의 모든 행 + 오른쪽 일치 행
		- RIGHT JOIN: 오른쪽 테이블의 모든 행 + 왼쪽 일치 행
		- OUTER JOIN: LEFT, RIGHT의 총칭. 일치하지 않는 행도 포함
		- CROSS JOIN: 데카르트 곱. 모든 조합 반환

	- JOIN은 테이블 간 관계를 활용해 데이터의 통합적인 조회를 가능하게 한다.

- 서브쿼리(Subquery)의 개념과 활용 사례
	- 개념:
		- 다른 쿼리 내부에 포함된 SELECT 문으로, 결과를 외부 쿼리에 제공하는 구조이다. WHERE, FROM, SELECT 절에서 사용 가능하다.

	- 활용 사례:
		- 조건 조회: WHERE price > (SELECT AVG(price) FROM product)
		- 결과 필터링: 특정 그룹의 최대값, 최소값 등 추출
		- IN/EXISTS 연산: 존재 여부 확인

	- 서브쿼리는 동적 조건 생성과 복잡한 논리 표현에 유용하다.

- 그룹 함수(Group Function)와 윈도우 함수(Window Function)의 차이
	- 그룹 함수:
		- SUM, AVG, MAX, MIN, COUNT 등과 같이 그룹 전체에 대해 단일 결과를 반환하는 함수. 
		- GROUP BY와 함께 사용된다.

	- 윈도우 함수:
		- OVER() 절을 사용하여 행별 결과를 유지한 채로 집계 연산을 수행한다. 예: ROW_NUMBER(), RANK(), SUM() OVER(PARTITION BY ...)

	- 차이점:
		- 그룹 함수는 그룹당 한 행 반환,
		- 윈도우 함수는 모든 행 유지하면서 추가 계산 컬럼 생성

- 인덱스(INDEX)의 개념과 주요 유형
	- 개념:
		- 테이블의 검색 속도를 높이기 위해 사용하는 보조 데이터 구조이다. 책의 색인처럼 특정 값의 위치를 빠르게 찾게 해준다.
	- 주요 유형:
		- 클러스터형(Clustered): 테이블 자체가 인덱스 순서대로 저장
		- 비클러스터형(Non-Clustered): 별도의 인덱스 구조 존재
		- B-Tree 인덱스: 범위 탐색과 균형 트리 구조에 효과적
		- Bitmap 인덱스: 비트맵을 활용해 다중 조건 검색에 강력, 읽기 중심 시스템에 적합

	- 인덱스는 검색 성능 향상에 핵심이지만, 쓰기 성능 저하나 저장 공간 증가를 유발할 수 있다.

- 뷰(View)의 개념과 주요 장점 및 단점
	- 개념:
		- 하나 이상의 테이블에서 유도된 가상 테이블로, 물리적으로 저장되지 않으며 쿼리 결과처럼 작동한다.
	- 장점:
		- 데이터 보안 강화 (열 제한 가능)
		- 복잡한 쿼리 단순화
		- 논리적 독립성 제공
		- 유지관리 용이
	- 단점:
		- 성능 저하 (복잡한 뷰 다중 중첩 시)
		- 업데이트 제한: 일부 뷰는 직접 수정 불가
	- 뷰는 읽기 전용 또는 보안용 데이터 제공에 많이 사용된다.

- 트리거(Trigger)의 개념과 활용 사례
	- 개념:
		- 트리거는 테이블에 대한 INSERT, UPDATE, DELETE 등의 이벤트가 발생할 때 자동으로 실행되는 저장 프로시저이다. 트랜잭션처럼 작동하며 조건이 충족되면 즉시 수행된다.

	- 활용 사례:
		- 이력 관리: 데이터 변경 시 로그 테이블에 자동 기록
		- 무결성 유지: 특정 필드 값 자동 보정 또는 확인
		- 알림 기능: 변경 시 외부 시스템 호출
		- 보안 통제: 민감 데이터의 변경 추적 및 방지

	- 트리거는 자동화, 감사, 통합 처리에 효과적이나, 과도한 사용 시 복잡성과 성능 저하 우려가 있다.

- 데이터 모델링(Data Modeling)의 개념과 주요 단계
	- 개념:
		- 데이터 모델링은 정보 시스템 구축을 위한 데이터 구조와 관계를 논리적으로 설계하는 과정이다.

	- 주요 단계:
		- 개념적 모델링: 사용자 요구 중심. ERD 등으로 표현
		- 논리적 모델링: DBMS에 독립적인 구조화, 정규화 적용
		- 물리적 모델링: 실제 DBMS 기반으로 테이블, 인덱스, 타입 등 구체화

	- 각 단계는 상호 연계되며, 요구 사항 → 설계 → 구현으로 흐른다.

- 정규화(Normalization)의 개념과 필요성
	- 개념:
		- 정규화는 데이터 중복과 이상(anomaly)을 제거하기 위해 테이블을 작은 단위로 분해하는 과정이다. 
		- 함수적 종속성에 기반하여 구조를 체계화한다.
	- 필요성:
		- 데이터 중복 최소화
		- 삽입/삭제/갱신 이상 방지
		- 데이터 무결성 향상
		- 구조적 명확성 확보

	- 정규화는 논리적 모델링의 핵심 과정으로, 데이터 품질 확보에 기여한다.

- 정규형(Normal Form, 1NF~5NF)의 개념과 특징
	- 1NF (제1정규형): 원자값만 포함, 반복 그룹 제거
	- 2NF (제2정규형): 부분 함수 종속 제거 (기본키 전체에 종속)
	- 3NF (제3정규형): 이행적 함수 종속 제거 (비주요 속성 간 종속 제거)
	- BCNF: 모든 결정자가 후보키 (3NF보다 강화된 형태)
	- 4NF: 다치 종속 제거
	- 5NF: 조인 종속 제거, 분해된 릴레이션의 무손 조인 보장

	- 정규형은 단계별로 데이터의 정합성과 구조 안정성을 높인다.

- 반정규화(Denormalization)의 개념과 필요성
	- 개념:
		- 반정규화는 성능 향상이나 사용 편의성 등을 위해 정규화된 테이블을 일부 다시 병합하거나 중복을 허용하는 과정이다.
	- 필요성:
		- 조인 비용 절감
		- 쿼리 속도 향상
		- 단순화된 데이터 구조로 개발 및 운영 용이

	- 반정규화는 성능 개선 목적의 설계 전략으로, 무결성 유지 장치가 병행되어야 한다.

- 엔티티(Entity), 속성(Attribute), 관계(Relationship)의 개념
	- 엔티티(Entity): 독립적으로 존재하는 객체 또는 개체, 예: 고객, 주문 등
	- 속성(Attribute): 엔티티가 가지는 특성, 예: 고객 이름, 주문 날짜 등
	- 관계(Relationship): 엔티티 간의 연관성, 예: 고객이 주문을 한다

	- 이 세 요소는 ERD 모델의 핵심 구성요소로, 데이터 간 논리적 구조를 정의한다.

- ERD(Entity-Relationship Diagram)의 개념과 주요 요소
	- 개념:
		- ERD는 시스템의 데이터를 시각적으로 표현하는 개념적 데이터 모델로, 엔티티, 속성, 관계 등을 도형으로 나타낸다.
	- 주요 요소:
		- 엔티티: 사각형으로 표현
		- 속성: 타원형
		- 관계: 마름모(다이아몬드형)
		- 카디널리티(Cardinality): 관계의 수량 (1:1, 1:N, N:M)
		- 키: 식별자 속성 강조

	- ERD는 요구사항 분석, 시스템 설계, 이해관계자 간 의사소통에 매우 유용하다.

- 식별 관계(Identifying Relationship)와 비식별 관계(Non-Identifying Relationship)의 차이
	- 식별 관계:
		- 자식 엔티티가 부모 엔티티의 기본키를 자신의 기본키 일부로 포함하는 관계이다. 
		- 부모 없이는 자식이 존재할 수 없는 존속 의존성이 강한 관계이며, ERD에서는 실선으로 표현된다.

	- 비식별 관계:
		- 부모 엔티티의 기본키가 자식 엔티티의 외래키로만 사용되고 기본키에는 포함되지 않는 관계이다. 
		- 자식 엔티티는 독립적인 기본키를 가지며, ERD에서는 점선으로 표현된다.

- 관계형 데이터 모델에서 키(Key)의 종류
	- 기본키(Primary Key): 테이블에서 각 튜플을 고유하게 식별하는 키. NULL 불가, 중복 불가.
	- 후보키(Candidate Key): 기본키로 선택될 수 있는 유일성과 최소성을 만족하는 모든 키.
	- 대체키(Alternate Key): 후보키 중 기본키로 선택되지 않은 나머지 키.
	- 슈퍼키(Super Key): 유일성만 만족하는 속성 집합. 후보키 + 추가 속성이 포함될 수도 있음.
	- 외래키(Foreign Key): 다른 테이블의 기본키를 참조하여 테이블 간 관계를 정의하는 키.

- 데이터 무결성을 유지하기 위한 주요 기법
	- 제약 조건(Constraints): 기본키, 외래키, NOT NULL, UNIQUE, CHECK 등을 통해 데이터 오류 방지
	- 트리거(Trigger): 데이터 변경 시 자동 실행되는 로직을 통해 무결성 보조
	- 규칙 기반 입력 검증: 애플리케이션 또는 DB 레벨에서 도메인/유효성 검사
	- 참조 무결성 유지: 외래키로 연결된 테이블 간 삭제/갱신 시 일관성 보장
	- 트랜잭션 처리: 데이터 갱신의 원자성 및 일관성 유지

- 관계형 데이터 모델에서 이상(Anomaly)의 개념과 발생 원인
	- 이상(Anomaly)
		- 데이터베이스에서 정규화가 미흡하거나 중복된 데이터가 존재할 경우 발생하는 비정상적인 데이터 현상이다.

	- 종류 및 원인:
		- 삽입 이상: 일부 속성의 부재로 인해 데이터를 삽입할 수 없음
		- 삭제 이상: 특정 데이터를 삭제할 때 원치 않는 정보도 함께 삭제됨
		- 갱신 이상: 중복된 데이터 갱신 시 일관성 유지 어려움

	- 주로 비정규형 구조 또는 다중 의미 혼합된 테이블에서 발생한다.

- 트랜잭션(Transaction)의 개념과 ACID 특성
	- 개념:
		- 트랜잭션은 데이터베이스에서 하나의 논리적 작업 단위로, 반드시 완전하게 실행되거나 전혀 실행되지 않아야 한다.

	- ACID 특성:
		- Atomicity(원자성): 모든 작업이 전부 수행되거나 전혀 수행되지 않아야 함
		- Consistency(일관성): 트랜잭션 전후 데이터 무결성 보장
		- Isolation(격리성): 동시 실행되는 트랜잭션 간 간섭 없음
		- Durability(지속성): 트랜잭션 완료 시 결과는 영구히 저장됨

- 트랜잭션의 원자성(Atomicity)과 보장 기법
	- 개념:
		- 트랜잭션은 부분 수행 없이 완전 실행 또는 완전 취소되어야 한다.
	- 보장 기법:
		- Undo 로그: 실패 시 이전 상태로 복원
		- 체크포인트 및 복구 시스템: 실패 지점까지 Rollback
		- 트랜잭션 관리기: commit/rollback 제어 및 상태 추적

- 트랜잭션의 일관성(Consistency)과 보장 기법
	- 개념:
		- 트랜잭션이 실행되기 전과 후의 데이터가 모든 무결성 제약 조건을 만족해야 한다.
	- 보장 기법:
		- 무결성 제약 조건(Primary/Foreign key 등)을 DBMS 수준에서 자동 체크
		- 어플리케이션 로직 검증: 논리적으로 일관된 상태 유지
		- 트리거 및 제약 설정: 데이터 간 논리적 연결 유지

- 트랜잭션의 격리성(Isolation)과 주요 격리 수준
	- 격리성(Isolation):
		- 여러 트랜잭션이 동시에 실행될 때 서로의 중간 상태를 보지 못하게 하여 독립적으로 실행되도록 보장하는 특성이다.
	- 격리 수준:
		- Read Uncommitted: 다른 트랜잭션의 미확정 데이터를 읽을 수 있음 → 가장 낮은 수준, Dirty Read 발생
		- Read Committed: 커밋된 데이터만 읽음 → Non-Repeatable Read 가능
		- Repeatable Read: 같은 쿼리를 반복해도 동일 결과 → Phantom Read 발생 가능
		- Serializable: 트랜잭션이 직렬 실행된 것처럼 처리 → 가장 높은 수준, 모든 이상 방지

	- 격리 수준은 성능과 일관성 간 트레이드오프 관계가 존재한다.

- 트랜잭션의 지속성(Durability)과 보장 기법
	- 지속성(Durability):
		- 트랜잭션이 커밋된 이후에는 시스템 장애가 발생해도 그 결과는 손실되지 않고 반드시 유지되어야 한다.
	- 보장 기법:
		- 로그 기록(Redo Log): 커밋된 변경 내용을 디스크에 반영
		- Write-Ahead Logging(WAL): 실제 데이터 반영 전에 로그 기록
		- 저널링 파일 시스템 및 RAID: 장애 복구 지원

	- 지속성은 장애 복구 시스템의 핵심 요소이다.

- 트랜잭션 충돌 문제와 해결 방법
	- (1) Dirty Read:
		- 정의: 다른 트랜잭션의 아직 커밋되지 않은 데이터를 읽음
		- 해결: Read Committed 이상 격리 수준 설정

	- (2) Non-Repeatable Read:
		- 정의: 같은 쿼리를 반복할 때 결과가 다름 (다른 트랜잭션이 데이터를 수정)
		- 해결: Repeatable Read 이상 설정

	- (3) Phantom Read:
		- 정의: 같은 조건의 쿼리를 실행했는데 결과 행의 수가 달라짐 (행 삽입/삭제 발생)
		- 해결: Serializable 격리 수준 사용 또는 범위 기반 잠금

- 동시성 제어(Concurrency Control)와 주요 기법
	- 개념:
		- 여러 트랜잭션이 동시에 실행될 때 데이터의 일관성을 유지하면서 상호 간섭을 방지하는 기술이다.
	- 주요 기법:
		- 로킹(Locking): 공유 자원에 대한 접근을 제한하여 충돌 방지
		- 타임스탬프 순서 기법: 트랜잭션 시작 시 타임스탬프를 부여하고 이 순서대로 작업
		- 낙관적 기법: 충돌이 거의 없다고 가정하고, 커밋 시 충돌 검사 → Rollback 가능성 있음
		- 다중 버전 제어(MVCC): 트랜잭션별 버전 관리로 읽기-쓰기 충돌 방지

- 로킹(Locking)의 개념과 주요 유형
	- 개념:
		- 트랜잭션 간 충돌을 방지하기 위해 데이터에 대한 접근 권한을 제한하는 제어 방법이다.
	- 주요 유형:
		- 공유 잠금(Shared Lock): 읽기만 허용, 다른 트랜잭션도 읽기 가능
		- 배타 잠금(Exclusive Lock): 읽기/쓰기 독점, 다른 트랜잭션 접근 불가
		- 데드락(Deadlock): 트랜잭션 간 상호 자원 대기 상태 발생 → 교착 상태

- 데드락(Deadlock)의 개념과 해결 기법
	- 개념:
		- 두 개 이상의 트랜잭션이 서로가 가진 자원을 기다리며 무한 대기 상태에 빠지는 현상이다.
	- 해결 기법:
		- 예방(Prevention): 자원 요청 순서 강제, 타임아웃 설정 등
		- 탐지(Detection): Wait-For 그래프 분석, 주기적 데드락 탐지
		- 회복(Recovery): 트랜잭션 중단(Rollback) 후 재시도

	- 데드락은 트랜잭션 관리에서 반드시 고려해야 할 병행성 이슈이다.

- 트랜잭션 로그(Transaction Log)의 개념과 복구 기법
	- 트랜잭션 로그:
		- 트랜잭션이 수행하는 모든 변경 사항을 시점별로 기록하는 로그 파일로, 장애 발생 시 복구를 위한 핵심 정보이다.

	- 복구 기법:
		- Undo: 트랜잭션 실패 시 로그를 바탕으로 이전 상태로 되돌림
		- Redo: 커밋된 트랜잭션을 다시 적용하여 반영되지 않은 변경사항 복구
		- Checkpoint: 일정 시점의 데이터 상태를 저장하여 복구 시 기준점 제공, 전체 로그 대신 체크포인트 이후 로그만 분석

	- 이들은 장애 복구, 원자성·지속성 보장의 핵심 수단이다.

- 파일 기반 저장 방식과 데이터베이스 저장 방식의 차이
	- 파일 기반 저장 방식:
		- 데이터를 일반 파일 형태로 저장하고 애플리케이션에서 직접 파일을 열고, 읽고, 쓰는 방식
		- 특징:
			- 구조 정의가 개발자 책임
			- 동시 접근 제어, 무결성 보장 어려움
			- 검색 성능 낮고, 트랜잭션 지원 없음

	- 데이터베이스 저장 방식:
		- DBMS가 데이터를 테이블 형태로 저장하고 트랜잭션, 무결성, 보안, 백업, 인덱싱 등을 제공

	- 차이점 핵심:
		- 파일은 단순 저장, DB는 구조화 + 제어 + 관리 기능 포함

- 데이터 블록(Data Block), 익스텐트(Extent), 세그먼트(Segment)의 개념과 관계
	- 데이터 블록: 디스크 I/O의 최소 단위. 한 블록에 하나 이상의 행이 저장됨
	- 익스텐트: 여러 개의 연속된 데이터 블록의 집합
	- 세그먼트: 논리적 객체(테이블, 인덱스 등)가 사용하는 모든 익스텐트의 집합

	- 관계: 블록 → 익스텐트 → 세그먼트로 구성되며, 이는 물리적 저장 단위의 계층 구조를 이룬다.

- 데이터 파일 구조와 테이블 스페이스(Table Space)의 개념
	- 데이터 파일(Data File): 실제로 데이터를 저장하는 물리적 파일
	- 테이블스페이스(TableSpace): 하나 이상의 데이터 파일로 구성된 논리적 저장 공간
		- → 테이블, 인덱스 등의 세그먼트가 배치됨
		- 역할: 테이블스페이스는 스토리지 공간을 논리적으로 분리 및 관리하기 위한 단위이다. 백업, 보안, 성능 관리에 유리하다.

- B-Tree와 B+Tree 인덱스의 개념과 차이
	- B-Tree 인덱스: 모든 노드(내부+리프)에 키와 포인터가 존재
	- B+Tree 인덱스: 리프 노드에만 실제 데이터에 대한 포인터 존재, 내부 노드는 키만 포함

	- 차이점:
		- B+Tree는 리프 노드에 정렬된 순서로 연결되어 범위 검색에 유리
		- B-Tree는 구조가 단순하지만 검색 및 순차 조회에 비효율적

	- 대부분의 DBMS는 범용성과 성능을 위해 B+Tree를 기본 인덱스 구조로 사용한다.

- 해시 인덱스(Hash Index)의 개념과 B-Tree 인덱스와의 차이
	- 해시 인덱스:
		- 검색 키에 해시 함수를 적용하여 고정 위치에 접근하는 방식의 인덱스이다.
	- 특징:
		- 빠른 정확한 값 검색(O(1) 수준)
		- 범위 검색은 비효율적
	- 차이점:
		- B-Tree는 범위 검색, 정렬이 유리
		- 해시 인덱스는 동등 비교(Equal Match)에 최적화
		- 해시 충돌 시 별도 처리 필요 → 복잡도 증가
	- 일반적으로 OLTP 시스템에서 정확한 키 검색이 많을 경우 유용하다.

- 클러스터 인덱스(Clustered Index)와 비클러스터 인덱스(Non-Clustered Index)의 차이
	- 클러스터 인덱스(Clustered Index):
		- 테이블의 데이터 자체가 인덱스 순서대로 정렬되어 저장된다. 테이블당 하나만 존재 가능하다. 인덱스 자체가 실제 데이터를 포함하므로 별도의 데이터 페이지 접근이 필요 없다.

	- 비클러스터 인덱스(Non-Clustered Index):
		- 인덱스는 별도의 구조로 존재하며, 인덱스를 통해 실제 데이터의 위치(포인터)를 찾는다. 하나의 테이블에 여러 개 생성 가능.

	- 차이점:
		- 클러스터 인덱스는 정렬된 데이터 자체
		- 비클러스터 인덱스는 간접적인 주소 참조
		- 클러스터 인덱스는 범위 조회나 정렬 쿼리에 유리

- 파티셔닝(Partitioning)의 개념과 주요 유형
	- 개념:
		- 대용량 테이블을 논리적으로 분할하여 관리하는 방식
		- 쿼리 성능 및 유지보수 효율 향상을 위한 기법
	- 주요 유형:
		- Range Partitioning: 특정 범위 값 기준 분할 (예: 날짜)
		- List Partitioning: 명시된 값 집합 기준 분할 (예: 지역 코드)
		- Hash Partitioning: 해시 함수를 이용해 균등 분산
		- Composite Partitioning: 위 기법들을 복합적으로 결합한 형태

	- 파티셔닝은 백업, 아카이빙, 쿼리 최적화 측면에서 유리하다.

- 테이블 압축(Table Compression)의 개념과 장단점
	- 개념:
		- 테이블에 저장되는 데이터를 압축하여 저장 공간을 줄이고 I/O를 최적화하는 기법이다.
	- 장점:
		- 스토리지 절감
		- I/O 성능 향상: 디스크 접근 횟수 감소
		- 캐시 효율 증대
	- 단점:
		- CPU 사용 증가 (압축/해제 시 연산 필요)
		- 실시간 처리 부하 가능성
		- 일부 DBMS에서는 쓰기 성능 저하
	- 주로 읽기 위주의 시스템, DW(데이터 웨어하우스)에서 효과적이다.

- I/O 성능 최적화를 위한 데이터베이스 저장 기법
	- 기법들:
		- 파티셔닝: 쿼리 대상 범위 축소
		- 인덱스 최적화: 적절한 인덱스 구성
		- 압축 기술: I/O 감소, 캐시 적중률 향상
		- In-Memory 저장소: 자주 사용하는 테이블을 메모리 상주
		- 스토리지 계층화(Tiering): 자주 접근하는 데이터는 고속 디스크, 오래된 데이터는 저속 저장소로 분산
		- 비동기 쓰기, 배치 처리: 디스크 부하 완화

	- 목표는 디스크 접근 횟수 최소화와 캐시 효율 극대화이다.

- 블록체인 기반 저장 방식의 개념과 활용 사례
	- 개념:
		- 블록체인은 데이터를 블록 단위로 연결(체인 구조)하여 변경 불가능하고 투명하게 저장하는 분산형 원장 기술이다.
		- 트랜잭션 기반 시스템에 적합하다.

	- 특징:
		- 불변성(Immutable): 한번 기록된 데이터는 수정 불가
		- 분산 저장: 노드 간 동일한 데이터 공유
		- 신뢰성: 중재자 없이도 무결성 확보

	- 활용 사례:
		- 금융 거래 기록
		- 공공 행정 문서 보존
		- 의료 데이터 이력 관리
		- 디지털 자산 추적 등

	- 블록체인은 기존 RDB와 다르게 변경보다는 이력 유지에 강점을 가진다.

- 데이터베이스 성능 튜닝의 개념과 주요 기법
	- 개념:
		- 데이터베이스 시스템의 응답 속도, 처리량, 자원 사용 등을 최적화하여 성능을 향상시키는 활동이다.
	- 주요 기법:
		- SQL 튜닝: 비효율 쿼리 개선
		- 인덱스 설계 최적화
		- 파티셔닝, 압축 등 저장 구조 개선
		- 메모리, 버퍼 캐시 설정 조정
		- 병렬 처리 및 비동기화 활용
		- 통계 정보 갱신 및 실행 계획 분석

	- 성능 튜닝은 시스템 자원 낭비 방지와 사용자 만족도 향상에 매우 중요하다.

- SQL 튜닝(SQL Optimization)의 개념과 주요 기법
	- 개념:
		- SQL 문장을 분석하여 불필요한 자원 사용을 줄이고 빠르게 원하는 데이터를 추출할 수 있도록 개선하는 작업이다.
	- 주요 기법:
		- 힌트(Hint) 사용: 옵티마이저에게 인덱스 강제 사용 등 지시
		- 실행 계획(Execution Plan) 분석: 비용이 큰 연산 제거
		- 불필요한 조인, 서브쿼리 제거
		- 조건 순서 조정 및 인덱스 활용 가능한 형태로 변경
		- 데이터 양 고려한 바인딩 변수 적용

	- SQL 튜닝은 개발자 수준에서 가장 빠르게 효과를 볼 수 있는 성능 개선 방법이다.

- 데이터베이스 버퍼 캐시(Buffer Cache)와 성능 향상 기법
	- 개념:
		- 버퍼 캐시는 디스크에서 읽어온 데이터를 메모리에 일시 저장하는 공간으로, 동일한 데이터를 재요청할 때 디스크 I/O 없이 처리할 수 있도록 한다.

	- 성능 향상 기법:
		- 히트율 최적화: 자주 접근하는 데이터를 버퍼 캐시에 유지
		- 버퍼 크기 조정: 사용량과 워크로드에 맞게 메모리 설정
		- LRU 알고리즘 적용: 오래 사용되지 않은 데이터부터 교체
		- In-Memory Table 사용: 성능 민감 데이터는 항상 메모리 상주

	- 버퍼 캐시는 디스크 접근 최소화 → 응답 속도 향상에 핵심적이다.

- 쿼리 실행 계획(Execution Plan)의 개념과 분석 방법
	- 개념:
		- DBMS가 SQL을 실행할 때 사용하는 데이터 접근 경로, 조인 방식, 인덱스 활용 여부 등 내부 수행 흐름 정보이다.
	- 분석 방법:
		- EXPLAIN PLAN / EXPLAIN / TRACE 명령어 사용
		- 각 단계의 비용(COST), 예상 ROW 수, JOIN 방식, 인덱스 유무 확인
		- TABLE ACCESS FULL vs INDEX SCAN 비교
		- 불필요한 FULL SCAN이나 SORT, NESTED LOOP 확인 → 성능 병목 지점 파악 가능

	- 실행 계획은 SQL 튜닝의 출발점이자 진단 도구이다.

- 인덱스를 효과적으로 사용하기 위한 전략
	- 조건절의 좌측 컬럼에 인덱스 적용
	- 다중 조건 WHERE절은 합성 인덱스 구성 고려
	- ORDER BY, GROUP BY 사용 시 인덱스 정렬 활용
	- 조회 대상 컬럼이 인덱스에 모두 포함된 Covering Index 구성
	- 불필요한 함수나 연산 사용 자제 (예: TO_CHAR(컬럼) → 인덱스 미사용)
	- 자주 갱신되는 컬럼은 신중히 인덱스 구성 (쓰기 성능 저하 가능)
	- 인덱스는 읽기 성능 향상 도구이나, 과도한 사용은 오히려 부하를 유발할 수 있다.

- OLTP와 OLAP의 차이
	- OLTP (Online Transaction Processing):
		- 실시간 트랜잭션 처리 중심
		- INSERT, UPDATE, DELETE 빈번
		- 데이터 정합성과 응답 속도 중시
		- 예: 은행 거래, 쇼핑몰 결제
	- OLAP (Online Analytical Processing):
		- 다차원 데이터 분석 중심
		- 대량 조회 및 집계 위주
		- 데이터 정제 후 사용, 비정형 질의 많음
		- 예: 매출 분석, 마케팅 보고서

	- 핵심 차이는 실시간 처리 vs 분석용 조회 중심 구조에 있다.

- 오라클 및 MySQL의 성능 튜닝 주요 기법
	- 오라클 튜닝:
		- AUTOTRACE, AWR, STATSPACK 활용
		- 힌트 사용 (/*+ INDEX */, /*+ FULL */)
		- PGA, SGA 크기 조절
		- 파티셔닝 및 병렬 처리

	- MySQL 튜닝:
		- EXPLAIN, SHOW PROFILE 활용
		- innodb_buffer_pool_size, query_cache_size 등 파라미터 조정
		- 쿼리 캐시, Slow Query Log 분석
		- 스키마 정규화 및 인덱스 최적화

	- DBMS별로 도구와 파라미터는 다르지만, 공통적으로는 쿼리, 인덱스, 메모리 조정이 핵심이다.

- 조인 방식(Nested Loop, Hash Join, Merge Join)과 성능 비교
	- Nested Loop Join:
		- 내부 루프를 돌며 한 건씩 비교
		- 소규모 테이블 조인, 인덱스 존재 시 효율적
		- 대량 데이터 시 비효율
	- Hash Join:
		- 한 테이블을 해시 테이블로 만들고 다른 테이블과 매칭
		- 대용량 조인에 적합, 정렬 불필요
		- 메모리 사용량 많음
	- Merge Join:
		- 정렬된 두 테이블을 병합하며 조인
		- 범위 조인이나 대규모 정렬된 데이터에 효과적

	- 조인 방식 선택은 데이터 양, 인덱스 유무, 정렬 여부에 따라 달라진다.

- 성능 병목(Bottleneck) 분석 방법
	- 분석 영역:
		- CPU 사용률: 고부하 연산 확인
		- 메모리 사용률: 버퍼 부족 여부
		- I/O 지연: 디스크 접근 병목 여부
		- SQL 실행 계획: 비효율 쿼리 존재 여부
		- 세션 동시성: 락 경합, 데드락 유무 확인
		- 네트워크 지연: 대규모 데이터 전송 확인

	- 도구: AWR, Performance Schema, V$ 뷰, SHOW PROCESSLIST 등 활용
		- → 병목 지점을 파악해 적절한 자원 할당 및 튜닝을 진행한다.

- 페이징 쿼리(Pagination Query) 성능 최적화 기법
	- OFFSET은 비용이 크므로 WHERE 기반 커서 방식 활용
		- → 예: WHERE id > :last_id LIMIT 10
	- 인덱스 활용 가능한 정렬 기준 사용
	- 중간 페이지 이동 최소화, 무한 스크롤 도입 고려
	- LIMIT은 적절히, OFFSET은 피하기
	- COUNT(*) 최소화 또는 캐싱

	- 특히 대용량 테이블에서는 OFFSET 방식 대신 조건 기반 페이징이 핵심 성능 전략이다.

- 데이터 웨어하우스(Data Warehouse)의 개념과 기존 데이터베이스 시스템과의 차이
	- 개념:
		- 데이터 웨어하우스는 기업 내 여러 출처의 데이터를 통합, 정제, 저장하여 분석 및 의사결정에 활용하는 목적의 데이터 저장소이다.

	- 기존 DBMS와의 차이:
		- OLTP vs OLAP: 운영 처리용 vs 분석 처리용
		- 정규화 vs 비정규화: 정규화된 트랜잭션용 vs 분석 중심 비정규화 구조
		- 실시간 처리 vs 배치 처리: 즉시 반영 vs 주기적 적재
		- 쓰기 중심 vs 읽기 중심: 업무 처리 vs 집계·리포트 분석

	- 데이터 웨어하우스는 대규모 분석 최적화를 위해 설계된다.

- 데이터 마트(Data Mart)의 개념과 데이터 웨어하우스와의 차이
	- 개념:
		- 데이터 마트는 특정 부서나 주제에 특화된 소규모 분석 전용 데이터 저장소로, 데이터 웨어하우스의 하위 개념이다.

	- 차이점:
		- 스코프: 웨어하우스는 전사 통합, 마트는 부서별 세분화
		- 구축 비용: 마트가 구축과 운영이 저렴함
		- 데이터 소스: 웨어하우스에서 가져오거나 운영 DB에서 직접 추출 가능

	- 마이크로 분석 또는 빠른 데이터 소비에 적합하다.

- 스타 스키마와 스노우플레이크 스키마의 개념과 차이
	- 스타 스키마:
		- 중심에 하나의 팩트 테이블, 주변에 여러 차원 테이블이 직접 연결
		- 구조가 단순하고 쿼리 효율이 높음
		- 일부 데이터 중복 허용
	- 스노우플레이크 스키마:
		- 차원 테이블이 정규화되어 여러 테이블로 나뉨
		- 구조가 복잡하지만 저장 공간 효율이 높고 무결성 유지에 유리

	- 쿼리 성능 위주라면 스타, 저장 최적화나 복잡한 분석에는 스노우플레이크 사용.

- OLAP의 개념과 주요 연산
	- 개념:
		- OLAP은 다차원 데이터를 기반으로 복잡한 질의, 분석, 시계열 비교 등을 수행하는 기술로, 주로 데이터 웨어하우스 상에서 동작한다.

	- 주요 연산:
		- Roll-Up: 상세 데이터를 요약
		- Drill-Down: 요약 데이터를 세분화
		- Slice: 특정 차원의 고정값 추출
		- Dice: 다차원 범위 지정 추출
		- Pivot: 행과 열의 차원 전환

	- 이 연산들을 통해 다양한 각도에서 데이터 탐색 및 인사이트 도출이 가능하다.

- ETL의 개념과 주요 프로세스
	- 개념:
		- ETL은 데이터 웨어하우스에 데이터를 적재하기 위해 수행되는 Extract, Transform, Load 과정이다.

	- 프로세스:
		- Extract: 다양한 시스템(DB, 로그, 파일 등)에서 데이터 추출
		- Transform: 정제, 필터링, 데이터 형 변환, 조인 등 가공 처리
		- Load: 웨어하우스에 저장 (일괄 또는 증분 방식)

	- ETL은 데이터 품질 확보 및 통합의 핵심 역할을 수행한다.

- 팩트 테이블과 차원 테이블의 차이
	- 팩트 테이블:
		- 측정 가능한 숫자형 데이터(매출, 수량 등)를 저장
		- 일반적으로 외래키 기반
		- 크기가 크고 정규화 정도 낮음
	- 차원 테이블:
		- 팩트를 설명하는 속성 정보(시간, 지역, 제품 등) 포함
		- JOIN을 통해 분석을 위한 다차원 데이터 구성

	- 팩트는 “무엇을 측정했는가”, 차원은 “어떻게 분류되는가”를 나타낸다.

- 빅데이터와 데이터 웨어하우스의 차이
	- 데이터 구조:
		- 웨어하우스는 구조화된 데이터 중심
		- 빅데이터는 구조화 + 비정형(텍스트, 이미지 등) 포함
	- 처리 방식:
		- 웨어하우스는 배치 중심
		- 빅데이터는 실시간 스트리밍 포함 가능
	- 기술 스택:
		- 웨어하우스: RDB 기반
		- 빅데이터: Hadoop, Spark, NoSQL 등 사용
	- 목적:
		- 웨어하우스는 기업 내부 분석
		- 빅데이터는 외부 데이터와 대규모 상관 분석

- 데이터 레이크와 데이터 웨어하우스의 차이
	- 데이터 레이크: 원본 데이터 그대로!
		- 원시(raw) 데이터를 구조화 없이 그대로 저장하는 방식의 저장소
		- 다양한 포맷(이미지, 로그, 영상 등)을 수용할 수 있다.

	- 차이점:
		- 저장 방식: 
			- 레이크는 스키마 적용 전 저장(Schema-on-read)
			- 웨어하우스는 스키마 적용 후 저장(Schema-on-write)
		- 유연성:
			- 레이크가 유연하지만 품질 통제 어려움
		- 분석 목적:
			- 웨어하우스는 정형 분석 중심
			- 레이크는 비정형/AI 학습용 포함

	- 데이터 레이크는 확장성 및 미래 분석을 위한 전제 조건으로서 활용된다.

- 실시간 데이터 처리(Real-time Processing)와 배치 처리(Batch Processing)의 차이
	- 실시간 처리:
		- 데이터가 생성되는 즉시 바로 처리하고 반영하는 방식이다.
		- 반응 속도가 중요하고 주로 스트리밍 기술을 사용한다.

	- 배치 처리:
		- 여러 데이터를 일정 시간 간격 또는 조건에 따라 한꺼번에 처리하는 방식으로, 대량 처리에 유리하다.

	- 차이점:
		- 실시간: Kafka, Flink, Storm 등
		- 배치: Hadoop, Spark (batch 모드), ETL 시스템
		- 실시간은 속도 중시, 배치는 정확성·효율 중시

- 데이터 거버넌스(Data Governance)와 데이터 웨어하우스의 관계
	- 데이터 거버넌스:
		- 조직 내에서 데이터의 품질, 보안, 일관성, 책임을 관리하는 체계이다.
	- 관계:
		- 웨어하우스는 거버넌스 정책이 집행되는 저장소
		- 정의된 메타데이터 관리, 접근 권한 통제, 데이터 표준화 등 거버넌스 요구사항을 충족
		- 웨어하우스를 통해 거버넌스의 정책 준수 상태를 모니터링 가능

	- 즉, 웨어하우스는 데이터 거버넌스의 실행 기반 인프라로 작용한다.

- 분산 데이터베이스의 개념과 주요 장단점
	- 개념:
		- 데이터를 물리적으로 분산된 여러 노드에 저장·관리하면서 논리적으로는 하나의 DB처럼 동작하는 시스템이다.

	- 장점:
		- 가용성 향상: 일부 노드 장애에도 시스템 운영 가능
		- 확장성 우수: 노드 추가로 수평 확장 가능
		- 지역 최적화: 지리적으로 가까운 노드에서 빠른 접근 가능

	- 단점:
		- 데이터 정합성 유지 어려움
		- 복잡한 트랜잭션 처리(분산 트랜잭션)
		- 네트워크 비용 증가

	- 분산 DB는 클라우드, 글로벌 서비스에서 확장성과 유연성 확보에 중요하다.

- CAP 이론과 분산 데이터베이스와의 관계
	- CAP 이론:
		- 분산 시스템에서 세 가지 속성 중 두 가지만 동시에 만족 가능하다는 이론.
			- (C)Consistency (일관성): 모든 노드가 동일한 데이터 상태
			- (A)Availability (가용성): 모든 요청에 대해 응답 보장
			- (P)Partition Tolerance (분할 허용): 네트워크 분리 상황에서도 시스템 유지

	- 분산 데이터베이스와의 관계:
		- 대부분의 분산 시스템은 P는 기본으로 고려하고, C vs A를 선택해야 한다.
		- 예: Cassandra는 AP, HBase는 CP, RDB는 일반적으로 CA

	- 설계자는 비즈니스 목적에 따라 트레이드오프를 명확히 이해해야 한다.

- 분산 트랜잭션과 2PC(Two-Phase Commit Protocol)의 개념
	- 분산 트랜잭션:
		- 여러 노드 또는 DB 인스턴스에서 동시에 발생하는 트랜잭션으로, 단일 트랜잭션처럼 원자성 보장이 필요하다.

	- 2PC 프로토콜:
		- 분산 트랜잭션의 일관성과 원자성을 보장하기 위한 2단계 커밋 절차
			- 1단계(Prepare): 각 노드에 커밋 가능한지 질의(예비 승인)
			- 2단계(Commit): 모든 노드가 OK 응답 시 전체 커밋 수행

	- 단점은 중단 시 블로킹 발생 가능 → 해결을 위해 3PC, Paxos 등 등장

- 데이터베이스 샤딩(Sharding)의 개념과 주요 기법
	- 개념: 분산 저장 방식 (샤딩)
		- 하나의 테이블을 데이터 기준(사용자, 지역 등)으로 나누어 여러 DB에 분산 저장하는 방식이다. 
		- 수평 분할(Horizontal Partitioning)의 일종이다.

	- 주요 기법:
		- Range Sharding: 범위 기반 분할
		- Hash Sharding: 해시 함수를 이용한 균등 분할
		- Directory-based Sharding: 샤드 위치를 별도 매핑 테이블로 관리
		- Geo Sharding: 지역 기반 분산

	- 샤딩은 확장성, 처리량 향상, 데이터 분산에 효과적이나 관리 복잡성 증가를 유발한다. (분산되어 저장되므로 관리 요소 증가)

- 레플리케이션(Replication)과 샤딩(Sharding)의 차이
	- 레플리케이션:
		- 같은 데이터를 여러 노드에 복제하여 읽기 성능 향상 및 장애 대비.
	- 샤딩:
		- 데이터를 수평 분할하여 서로 다른 노드에 저장 → 쓰기 성능 향상 및 데이터 분산
	- 차이점 요약:
		- 레플리케이션: 읽기 확장, 고가용성, 백업 목적
		- 샤딩: 쓰기 확장, 데이터 양 분산
		- 레플리케이션은 데이터 중복, 샤딩은 데이터 분리

	- 대규모 시스템에서는 둘을 조합하여 사용하는 경우가 많다.

- NewSQL의 개념과 RDBMS, NoSQL과의 차이
	- NewSQL:
		- 전통적 RDBMS의 ACID 보장 및 SQL 사용 특성은 유지하면서도, NoSQL처럼 수평 확장성과 고성능 처리를 제공하는 차세대 DBMS이다.
	- 차이점:
		- RDBMS: ACID 보장, SQL 사용, 확장성 제한
		- NoSQL: 유연한 스키마, 수평 확장, 일관성보다는 가용성 중시
		- NewSQL: SQL 기반 + ACID 보장 + 수평 확장성 결합
		- 예: Google Spanner, CockroachDB, TiDB

- 분산 데이터베이스에서 일관성 유지 기법
	- 2PC(2단계 커밋): 분산 트랜잭션에서 원자성 보장
	- Quorum Protocol: 다수 노드의 응답을 기준으로 읽기/쓰기 결정
	- Version Vector: 버전 정보로 동기화 충돌 해결
	- Conflict-free Replicated Data Types (CRDT): 자동 병합 가능한 데이터 구조
	- Timestamp Ordering: 시간 순서 기반 일관성 유지

	- 이 기법들은 CAP 이론의 제한 속에서 최적의 일관성 전략을 제공한다.

- 병렬 데이터베이스 시스템의 개념과 주요 유형
	개념:
		- 데이터를 여러 노드나 프로세서에서 동시에 처리하여 성능과 처리량을 향상시키는 DB 시스템이다.

	- 유형:
		- Shared Memory: 모든 프로세서가 하나의 메모리 공유
		- Shared Disk: 프로세서는 독립적, 저장소만 공유
		- Shared Nothing: 프로세서, 메모리, 디스크 모두 독립
		- MPP (Massively Parallel Processing): 대규모 노드 간 병렬 처리

	- 대규모 DW 시스템에서 많이 채택된다.

- 분산 데이터 저장 방식과 일관성 유지 방법
	- 저장 방식:
		- 샤딩: 데이터 수평 분할
		- 레플리케이션: 복제 저장
		- DHT (분산 해시 테이블): 키 기반 분산 저장

	- 일관성 유지 방법:
		- Eventual Consistency: 시간이 지나면 일관 상태 도달
		- Strong Consistency: 항상 최신 데이터 보장
		- CAP 이론 기반 조정: 시스템 목적에 따라 전략 선택

	- 데이터 저장 구조에 따라 가용성과 일관성 간 균형 조정이 필요하다.

- Apache Hadoop과 Spark의 차이
	- Hadoop:
		- 배치 처리 기반, 느리지만 안정적
		- MapReduce 방식, 디스크 I/O 중심
		- HDFS를 사용한 분산 파일 시스템
	- Spark:
		- 인메모리 처리 중심으로 빠른 속도 제공
		- 반복 연산, 실시간 스트리밍 처리 강점
		- DAG(Directed Acyclic Graph) 기반 실행

	- Spark는 Hadoop의 한계를 극복한 차세대 빅데이터 엔진으로, 다양한 모듈(Spark SQL, MLlib 등)을 제공한다.

- NoSQL의 개념과 주요 유형
	- 개념:
		- Not Only SQL의 약자로, 스키마가 유연하고 수평 확장이 가능한 비관계형 DB를 의미한다.
	- 주요 유형:
		- Key-Value Store: 단순한 키-값 쌍 저장 (예: Redis, DynamoDB)
		- Document Store: JSON/XML 기반 문서 저장 (예: MongoDB, CouchDB)
		- Column Store: 열 단위 저장, 대량 분석에 적합 (예: Cassandra, HBase)
		- Graph DB: 노드-엣지로 복잡한 관계 표현 (예: Neo4j, ArangoDB)

	- 각 유형은 데이터 구조와 용도에 맞춰 선택된다.

- Key-Value Store 개념과 대표 DB
	- 개념:
		- 각 데이터 항목이 고유한 키를 가지며, 값은 비정형 또는 임의 구조를 갖는 단순한 저장소이다.
	- 특징:
		- 빠른 접근 속도
		- 데이터 구조 단순
		- 수평 확장 용이
	- 대표 DB:
		- Redis: 인메모리 기반, 빠른 처리, 캐시 용도
		- DynamoDB: AWS 기반 고가용성 분산 DB
	- Key-Value Store는 로그 저장, 세션 관리, 캐싱 등에 유용하다.

- Document Store의 개념과 대표적인 데이터베이스
	- 개념:
		- 문서 지향 데이터베이스는 데이터를 JSON, BSON, XML과 같은 문서 형태로 저장하고, 각 문서는 독립적인 구조를 가진다. 
		- 관계형 DB의 테이블 대신 컬렉션(Collection)이라는 단위를 사용한다.
	- 특징:
		- 스키마가 유연함
		- 중첩 구조 지원
		- 문서 단위로 빠른 조회 가능
	- 대표 DB:
		- MongoDB: NoSQL 대표 주자, JSON 기반 문서 저장
		- CouchDB: 분산 환경에 강함, 충돌 해결 메커니즘 제공

	- 문서형 DB는 웹 애플리케이션, CMS, 로그 데이터 저장 등에 적합하다.

- Column Store의 개념과 대표적인 데이터베이스
	개념:
		- 열 지향 데이터베이스는 데이터를 행(Row)이 아닌 열(Column) 단위로 저장하여, 집계 및 분석 질의에 최적화된 구조이다.
	- 특징:
		- 특정 열만 조회하는 쿼리에 효율적
		- 데이터 압축 효율 우수
		- DW, OLAP 분석 환경에서 유리
	- 대표 DB:
		- Cassandra: 고가용성 및 분산 환경에 적합, 페이스북 개발
		- HBase: Hadoop 기반 열지향 DB, 대규모 분산 환경에 최적화

	- Column Store는 대용량 로그 분석, 통계 처리, 리포트 시스템에 적합하다.

- Graph Database의 개념과 대표적인 데이터베이스
	- 개념:
		- 그래프 데이터베이스는 노드(Node)와 엣지(Edge)를 이용해 객체와 관계를 표현하고 탐색하는 데이터 모델이다.
		- 관계형 DB보다 관계 탐색 성능이 우수하다.
	- 특징:
		- 관계 중심 모델
		- JOIN 없이 다차원 관계 탐색 가능
		- 탐색 성능 우수 (SNS, 추천 시스템에 강함)
	- 대표 DB:
		- Neo4j: 가장 널리 사용되는 그래프 DB
		- ArangoDB: 멀티 모델 지원 (그래프 + 문서)
	- Graph DB는 소셜 네트워크, 추천 시스템, 경로 탐색 등에 많이 활용된다.

- NoSQL과 RDBMS의 차이 및 NoSQL 활용 사례
	- 차이점:
		- 스키마: RDBMS는 고정 스키마, NoSQL은 유연한 스키마
		- 확장성: RDBMS는 수직 확장, NoSQL은 수평 확장
		- 데이터 모델: RDBMS는 정형 데이터, NoSQL은 비정형/반정형
		- 트랜잭션: RDBMS는 ACID 강력 지원, NoSQL은 BASE 기반 (유연한 일관성)

	- NoSQL 활용 사례:
		- SNS 사용자 활동 로그
		- 실시간 IoT 센서 데이터 수집
		- 사용자 세션 캐싱
		- 제품 추천 기반 데이터 저장

- NoSQL의 일관성 모델: Eventual Consistency vs Strong Consistency
	- Eventual Consistency:
		- 모든 노드가 결국 동일한 상태에 도달
		- 일시적 불일치 허용, 가용성 중심
		- 예: Amazon Dynamo, Cassandra
	- Strong Consistency:
		- 모든 노드가 항상 동일한 데이터 반환
		- 읽기와 쓰기 모두 지연 가능
		- 예: Google Spanner
	- 선택은 성능 vs 정합성 우선순위에 따라 달라진다.

- 수직 확장(Vertical Scaling) vs 수평 확장(Horizontal Scaling)
	- 수직 확장(Scale Up):
		- 하나의 서버의 CPU, RAM, 디스크 등 성능을 업그레이드
		- 한계 존재, 고비용
	- 수평 확장(Scale Out):
		- 서버 수를 늘려 부하 분산
		- 유연한 확장성, 분산 처리 기반

	- 현대 시스템은 수평 확장을 전제로 설계된 클라우드 및 분산 환경을 선호한다.

- Multi-Model Database의 개념과 활용 사례
	- 개념:
		- 하나의 DBMS에서 여러 데이터 모델(문서형, 그래프형, 키-값형 등)을 통합 지원하는 데이터베이스이다.
	- 특징:
		- 데이터 유형에 따라 최적 모델 선택 가능
		- 데이터 중복 없이 다양한 질의 가능
		- 복잡한 데이터 관계 처리에 유리
	- 활용 사례:
		- ArangoDB, OrientDB, Cosmos DB 등
		- 이커머스(문서 + 그래프 + 키-값), IoT(시간 + 문서 + 관계) 등 복합 서비스에 적합

	- 멀티모델 DB는 플랫폼 통합 및 복잡한 데이터 요구사항 대응에 효과적이다.

- 블록체인(Blockchain)과 전통적인 데이터베이스의 차이
	- 블록체인:
		- 탈중앙화된 분산 원장 기술로, 데이터가 블록 단위로 연결되고 변경이 불가능한 구조를 갖는다. 
		- 데이터는 참여자들 간에 공유되며, 합의 알고리즘을 통해 추가된다.

	- 전통적 데이터베이스(RDBMS):
		- 중앙화된 서버에서 데이터를 저장·수정하며, 데이터 변경 및 삭제가 가능하고 성능 중심이다.

	- 차이점 요약:
		- 구조: 블록체인 = 분산 체인 구조 / DB = 테이블 기반
		- 무결성: 블록체인 = 변경 불가 / DB = 변경·삭제 가능
		- 신뢰: 블록체인은 중개자 없이 신뢰 확보, DB는 중앙 서버 신뢰
		- 속도: DB는 빠른 처리, 블록체인은 느리지만 신뢰성 우수

- 데이터베이스 보안(Database Security)의 개념과 필요성
	- 개념:
		- 데이터베이스에 저장된 데이터와 시스템을 무단 접근, 변조, 유출 등으로부터 보호하는 모든 기술적·관리적 조치를 의미한다.
	- 필요성:
		- 개인정보 및 기밀 정보 보호
		- 데이터 무결성 및 가용성 유지
		- 법적·규제 준수 (예: GDPR, ISMS)
		- 해킹, 내부자 위협, 시스템 오작동 등 리스크 대응

	- 보안은 기술 + 정책 + 교육의 통합적 접근이 필요하다.

- 데이터베이스 접근 제어(Access Control) 개념과 주요 기법
	- 개념:
		- 사용자 또는 시스템이 데이터에 접근하거나 조작하는 행위를 허용 또는 차단하는 방식이다.

	- 주요 기법:
		- RBAC (Role-Based Access Control): 역할 기반 권한 관리
		- MAC (Mandatory Access Control): 보안 등급 기반 강제 제어
		- DAC (Discretionary Access Control): 데이터 소유자가 권한 부여

	- 접근 제어는 최소 권한 원칙(Least Privilege)을 기준으로 설계해야 한다.

- 데이터베이스 암호화 개념과 주요 암호화 기법
	- 개념:
		- 데이터를 암호 알고리즘으로 변환하여 비인가자가 내용을 볼 수 없도록 하는 기술이다.

	- 주요 기법:
		- 컬럼 암호화: 특정 민감 컬럼만 암호화 (예: 주민번호, 카드번호)
		- 파일 암호화: 전체 파일 또는 테이블 단위 암호화
		- TDE (Transparent Data Encryption): DBMS 자체에서 자동 암호화 수행, 애플리케이션 변경 불필요

	- 암호화는 성능 영향 고려와 함께 키 관리(Key Management)도 필수적이다.

- 데이터 마스킹(Data Masking)의 개념과 활용 사례
	- 개념:
		- 실제 데이터를 기반으로 의미를 유지하되 민감 정보를 식별할 수 없도록 변환하는 기술이다. 
		- 복구 불가능하거나 제한적으로 복원 가능한 방식이다.

	- 활용 사례:
		- 개발·테스트 환경에서 민감 데이터 제거
		- 외주, 파트너 시스템에서 개인정보 보호
		- 사용자 화면에서 주민번호, 전화번호 일부 마스킹 처리

	- 데이터 마스킹은 개인정보 보호법 준수와 실환경 테스트를 동시에 만족시키는 기술이다.

- GDPR, CCPA 등 개인정보 보호법에 따른 DB 보안 요구사항
	- 주요 요구사항:
		- 데이터 주체의 권리 보장: 열람, 수정, 삭제, 이동 등
		- Privacy by Design: 설계 단계부터 보안 고려
		- 기록 및 감사: 접속 로그, 변경 이력 보관
		- 암호화 및 마스킹: 민감정보 보호
		- 위반 시 보고 의무: 데이터 유출 발생 시 법적 보고 필요

	- GDPR(유럽), CCPA(미국 캘리포니아)는 글로벌 수준의 DB 보안 정책 수립의 기준이 된다.

- 감사 로그(Audit Log)와 데이터베이스 감사를 통한 보안 정책
	- 감사 로그(Audit Log):
		- 데이터베이스에서 발생하는 접근, 변경, 삭제, 로그인 등의 모든 활동을 기록한 로그이다.
	- 활용:
		- 보안 사고 분석 (누가, 언제, 어떤 데이터에 접근했는지 확인)
		- 접근 권한 오남용 탐지
		- 내부자 위협 대응 및 법적 증거 확보
		- 정책 위반 감사 및 감사 대응

	- 감사 로그는 사후 보안뿐 아니라 실시간 위협 탐지에도 활용된다.

- SQL Injection 공격의 개념과 주요 대응 방법
	- 개념:
		- SQL Injection은 사용자 입력값에 악의적인 SQL 구문을 삽입하여 데이터베이스 명령을 조작하는 공격이다.
		- 인증 우회, 데이터 유출, DB 파괴 등이 가능하다.

	- 대응 방법:
		- Prepared Statement (바인딩 변수) 사용: SQL 구문과 파라미터 분리
		- 입력값 검증 및 필터링: 특수문자 제거 또는 허용된 패턴만 입력
		- 최소 권한 원칙 적용: DB 계정 권한 제한
		- 오류 메시지 숨김: 에러로 내부 구조 노출 방지
		- WAF(웹 방화벽) 적용: 자동 탐지 및 차단

	- SQL Injection은 방어 코드 작성이 가장 확실한 대응이다.

- 데이터베이스 패치 및 취약점 관리 방법
	- 필요성:
		- DBMS 및 관련 라이브러리의 보안 취약점은 외부 공격의 주요 진입점이 되므로, 정기적인 패치와 취약점 관리는 필수이다.

	- 관리 방법:
		- 정기 보안 패치 적용: 벤더가 제공하는 공식 패치 반영
		- 보안 취약점 스캐닝 도구 활용: DB 보안 설정 진단
		- 패치 테스트 환경 운영: 실제 적용 전 사전 검증
		- CVE, NVD 모니터링: 공개된 취약점 대응

	- 패치는 업데이트뿐 아니라 환경 테스트 및 리스크 분석이 동반되어야 한다.

- 데이터베이스 보안 정책 수립 시 고려 요소
	- 접근 통제: 사용자 인증, 역할 기반 권한 설정
	- 암호화 정책: 컬럼/파일 단위 암호화 적용 여부
	- 로그 및 감사: 접속, 변경 이력 저장 및 분석 체계
	- 개인정보 보호: 마스킹, 비식별화 기술 적용
	- 취약점 관리: 점검, 보안 패치 주기 설정
	- 백업 및 복구 체계: 랜섬웨어, 시스템 장애 대비
	- 외부 감사 대응: GDPR, ISMS 등 인증 대응 전략

	- 정책은 기술 + 조직 + 관리 프로세스를 통합적으로 고려해야 한다.

- DLP(Data Loss Prevention)를 활용한 데이터 보호 방법
	- 개념:
		- DLP는 조직의 민감 데이터가 허가되지 않은 방식으로 외부 유출되지 않도록 탐지하고 차단하는 기술이다.

	- 활용 기법:
		- 콘텐츠 기반 검사: 특정 키워드, 패턴 탐지 (예: 주민번호, 계좌번호)
		- 행위 기반 검사: 비정상 접근, 대량 조회 등 이상 행동 감지
		- 암호화 연동: 유출 전 자동 암호화 또는 접근 차단
		- 정책 기반 차단: 이메일, USB, 클립보드 복사 등 경로 차단

	- DLP는 사고 예방 중심의 실시간 모니터링 보안 기술로 각광받는다.

- 데이터 품질 관리(Data Quality Management)의 개념과 주요 평가 지표
	- 개념:
		- 데이터 품질 관리는 데이터의 정확성, 완전성, 일관성, 유효성 등을 지속적으로 측정하고 개선하는 활동

	- 주요 평가 지표:
		- 정확성(Accuracy): 실제 값과 일치 여부
		- 일관성(Consistency): 서로 다른 시스템 간 데이터 불일치 여부
		- 완전성(Completeness): 누락 데이터 존재 여부
		- 유효성(Validity): 규칙에 맞는 값인지 여부
		- 중복성(Duplicates): 동일 항목 중복 존재 여부
		- 적시성(Timeliness): 최신 정보 유지 여부

	- 품질 관리는 데이터 기반 의사결정의 신뢰성 확보에 직결된다.

- 데이터 정제(Data Cleansing)의 개념과 주요 기법
	- 개념:
		- 데이터 정제는 오류, 중복, 불필요한 데이터를 식별하고 정리하여 품질을 개선하는 과정이다.

	- 주요 기법:
		- 결측치 보완/제거
		- 중복 데이터 제거(Deduplication)
		- 형식 표준화 및 도메인 정합성 확인
		- 이상치 탐지 및 보정
		- 불일치 데이터 병합(예: 성명, 주소 등)

	- 정제는 ETL 과정의 핵심 단계이며, 정확한 분석의 기초가 된다.

- 메타데이터 관리(Metadata Management)의 개념과 주요 구성 요소
	- 개념:
		- 메타데이터 관리는 데이터에 대한 정의, 구조, 출처, 연관성, 흐름 등의 정보를 관리하여 데이터 이해도와 활용도를 높이는 활동이다.

	- 주요 구성 요소:
		- 기술 메타데이터: 테이블, 컬럼, 타입 등 구조 정보
		- 비즈니스 메타데이터: 용어 정의, 업무 의미, 책임자 등
		- 운영 메타데이터: 생성 시점, 변경 이력, 접근 기록 등
		- 계보(Lineage): 데이터의 흐름과 생성·변형 과정 추적
		- 카탈로그: 메타데이터 탐색 기능 제공

	- 메타데이터 관리는 데이터 거버넌스와 품질 관리의 핵심 인프라이다.

- 데이터 거버넌스(Data Governance)의 개념과 주요 프레임워크
	- 개념:
		- 데이터 거버넌스는 조직 내 데이터를 효율적이고 책임 있게 관리하기 위한 정책, 표준, 절차, 책임체계를 포함한 관리 체계이다. 데이터 품질, 보안, 표준, 메타데이터 등을 포괄한다.

	- 주요 프레임워크:
		- DAMA-DMBOK: 데이터 관리 지식체계 표준 (Data Architecture, Data Quality, Metadata 등 포함)
		- COBIT, ISO 38500: IT 거버넌스와 연계된 데이터 관리 관점 제시
		- EDM Council DCAM: 금융권 중심의 데이터 통제 모델
		- 국내 K-DMF: 공공/민간 데이터 거버넌스 통합 프레임워크

- 마스터 데이터 관리(MDM)의 개념과 주요 기법
	- 개념:
		- 조직의 핵심 엔터티(고객, 제품, 공급자 등)에 대한 중복 없는 단일 버전의 진실(SSOT)을 유지하기 위한 데이터 관리 방법론이다.

	- 주요 기법:
		- 중앙 집중형(Centralized): 하나의 마스터 DB에서 통제
		- 등록소형(Registry): 마스터 데이터를 외부 시스템에서 유지하고 참조
		- 협업형(Coexistence): 중앙과 분산의 혼합 방식
		- 동기화 및 데이터 정제: 중복 제거, 코드 통일, 키 정합성 유지

- 데이터 표준화(Data Standardization)의 개념과 주요 전략
	- 개념:
		- 데이터의 이름, 형식, 단위, 도메인 등을 통일하여 시스템 간 데이터 정합성과 통합을 용이하게 하는 관리 활동이다.

	- 주요 전략:
		- 데이터 사전 구축: 명칭, 정의, 속성, 도메인 등 일관화
		- 공통 코드 체계 수립: 국가코드, 성별코드 등 표준 코드 사용
		- 명명 규칙 정립: 테이블, 컬럼 명명 일관화
		- 데이터 모델 표준 적용: 논리/물리 모델링 기준 통일

- 데이터 분류(Data Classification)의 개념과 주요 기준
	- 개념:
		- 조직 내 데이터를 보안, 관리, 활용 목적에 따라 분류하여 적절한 통제 및 보호를 적용하는 활동이다.

	- 주요 기준:
		- 기밀성: 공개/내부/제한/기밀/최기밀 등
		- 중요도: 업무 영향도, 복구 우선순위
		- 법적 민감도: 개인정보, 금융정보 등 규제 적용 여부
		- 사용 주체/사용 빈도: 부서별, 조회/수정 패턴 기반 분류

- 데이터 감사(Data Audit)와 무결성 확보 방법
	- 데이터 감사:
		- 데이터 변경, 접근, 처리 이력 등을 추적하여 위법 행위 또는 품질 이상을 탐지하는 활동이다.
	- 무결성 확보 방법:
		- 제약조건(Primary/Foreign key, Check 등)
		- Trigger 및 Stored Procedure를 통한 자동 검증
		- Hash값 기반 무결성 검증
		- 이중 입력 확인 및 승인 절차

	- 감사와 무결성 관리는 거버넌스 실행의 핵심 요소이다.

- DB 성능 모니터링 및 장애 대응 주요 지표
	- 주요 지표:
		- CPU, 메모리 사용률
		- I/O 지연 시간
		- Lock, Deadlock 발생 빈도
		- Slow Query 비율
		- Connection 수, Cache Hit Ratio
		- TPS (Transaction per Second), QPS (Query per Second)

	- 장애 대응:
		- 사전 경고 알람, APM 도입, 자동 페일오버, 로그 분석 기반 원인 추적

- 데이터 품질 관리에서 AI 및 머신러닝 기반 자동화 기법
	- 활용 방안:
		- 데이터 정합성 자동 탐지: 이상값, 결측값 패턴 식별
		- 자동 매핑/정제 추천: 머신러닝 기반 유사 속성 자동 매칭
		- 중복 탐지: AI로 유사 엔티티 군집화
		- 품질 점수 자동 평가: 규칙 학습 기반 스코어링
		- 자연어 기반 데이터 설명 자동 생성

	- AI 기반 품질 관리는 정적 규칙 중심에서 지능형 품질 관리 체계로의 전환을 의미한다.

- 빅데이터(Big Data)의 개념과 기존 데이터베이스 시스템과의 차이
	- 개념:
		- 빅데이터는 기존 데이터 처리 기술로는 수집, 저장, 분석이 어려운 대규모·다양한·고속성의 데이터 집합을 의미하며, 일반적으로 3V(Volume, Variety, Velocity) 또는 5V(+ Veracity, Value)로 설명된다.

	- 기존 DB와의 차이점:
		- 데이터 구조: 정형 위주의 RDBMS vs 비정형 포함
		- 처리 방식: SQL 기반 vs 분산 처리/병렬 분석
		- 확장성: 수직 확장 vs 수평 확장
		- 처리 목적: 정합성 중심 vs 패턴/트렌드 중심 분석

- 빅데이터 처리 기술(Hadoop, Spark)의 개념과 차이
	- Hadoop:
		- 분산 저장(HDFS) + 분산 처리(MapReduce) 기반
		- 대규모 배치 작업에 최적화
		- 디스크 기반 처리로 느리지만 안정적
	- Spark:
		- 인메모리 기반의 고속 처리
		- 반복 연산, 스트리밍, 머신러닝 처리 가능
		- Hadoop보다 빠르고 유연한 API 제공

	- 차이점: Hadoop은 배치 중심의 전통적 처리 프레임워크, Spark는 범용 실시간 분석 엔진에 가깝다.

- 데이터 레이크(Data Lake)와 데이터 웨어하우스의 차이
	- 데이터 레이크:
		- 원시 데이터 중심, 스키마 미적용(Schema-on-Read)
		- 비정형, 반정형 데이터 수용 가능
		- 데이터 과학, AI/ML 분석에 활용
		- 유연하고 확장성 높은 저장소
	- 데이터 웨어하우스:
		- 정형 데이터, 스키마 선 적용(Schema-on-Write)
		- 고품질, 통제된 데이터 기반의 BI 분석
		- 성능 최적화된 구조화 저장

	- 데이터 레이크는 수집 중심, 웨어하우스는 분석 중심으로 역할이 구분된다.

- 클라우드 데이터베이스의 개념과 온프레미스와의 차이
	- 클라우드 DB:
		- 클라우드 환경에서 운영되는 데이터베이스로, 인프라 관리 없이 확장성과 고가용성 중심의 DB 서비스를 제공한다.

	- 차이점:
		- 운영 방식: 직접 설치 vs 서비스형(DBaaS)
		- 유지보수: 자체 관리 vs 자동 패치/백업
		- 확장성: 물리적 한계 vs 무제한 수평 확장
		- 비용: 초기 투자 많음 vs 사용량 기반 과금

	- 클라우드 DB는 민첩한 배포와 운영 효율이 강점이다.

- 주요 클라우드 데이터베이스 서비스 비교
	- 주요 클라우드 데이터베이스 서비스
		- AWS RDS: 관계형 DB 관리 서비스, 다수 엔진(MySQL, Oracle 등) 지원
		- Google BigQuery: 대규모 분석을 위한 컬럼 기반 DWH, 서버리스
		- Azure Cosmos DB: 멀티모델 DB, 전 세계 분산, 빠른 응답 보장

	- 특징 비교:
		- RDS: 관리 편의 중심
		- BigQuery: 대규모 쿼리 분석 최적화
		- Cosmos DB: 글로벌 분산 + 다양한 데이터 모델 지원

- 클라우드 DB의 데이터 이중화 및 백업 전략
	- 이중화:
		- 멀티 AZ 배치, 리전 간 복제
		- Read Replica 구성
		- 장애 시 자동 페일오버
	- 백업:
		- 자동 스냅샷, 수동 백업
		- 백업 보존 주기 및 암호화 설정
		- RTO/RPO 기준에 따른 복원 전략 수립

	- 클라우드 환경에서는 가용성과 복구 목표 기반의 설계가 핵심이다.

- 멀티 클라우드 환경에서 DB 관리 고려사항
	- 데이터 일관성: 클라우드 간 동기화 전략 필요
	- 이중화 설계: 리전/벤더 간 장애 복원 능력 확보
	- 보안 정책 통합: IAM, 암호화, 감사 로그 표준화
	- API/플랫폼 호환성: 클라우드 종속 방지
	- 비용 관리: 이중 저장, 데이터 이동 비용 최적화

	- 멀티 클라우드는 유연성과 리스크 분산의 장점이 있지만, 관리 복잡성이 높다.

- 클라우드 기반 데이터 웨어하우스의 개념과 주요 특징
	- 개념:
		- 클라우드 기반 데이터 웨어하우스는 클라우드 환경에서 제공되는 확장 가능하고 관리가 용이한 분석 전용 데이터 저장소이다.
		- 구조화된 데이터를 저장하고 고속 분석을 지원한다.

	- 주요 특징:
		- 무제한 확장성: 사용량에 따라 자동 확장/축소
		- 서버리스 아키텍처: 인프라 관리 필요 없음
		- 고성능 병렬 처리(MPP): 대규모 쿼리 성능 우수
		- 분리된 저장/컴퓨팅 계층: 유연한 리소스 최적화
		- 대표 제품: AWS Redshift, Snowflake, Google BigQuery

	- 클라우드 DWH는 데이터 분석과 BI 업무에 최적화된 환경을 제공한다.

- 클라우드 환경에서 데이터 주권(Data Sovereignty)과 보안 이슈
	- 데이터 주권:
		- 데이터는 저장된 물리적 위치의 법률과 규제의 영향을 받는다. 국가 간 법률 충돌 문제 발생 가능 (예: GDPR vs Patriot Act)

	- 보안 이슈:
		- 데이터 암호화 및 키 관리: 고객이 직접 제어 가능한 KMS 필요
		- 접근 통제: 클라우드 IAM 정책 철저히 설정
		- 다중 테넌시 환경 분리: 다른 고객 데이터와의 논리적 분리 보장
		- 감사 및 인증: ISO/IEC 27001, SOC2 등 준수 여부 확인

	- 데이터 주권과 보안은 클라우드 채택 시 필수 고려 요소이다.

- 서버리스 데이터베이스(Serverless DB)의 개념과 주요 장단점
	- 개념:
		- 서버리스 DB는 인프라 관리 없이 자동으로 확장되고 과금되는 DB 서비스로, 개발자는 쿼리 작성과 데이터 설계에 집중 가능하다.

	- 장점:
		- 자동 확장 및 자동 중지로 비용 효율성
		- 초기 설정 및 관리 부담 없음
		- 빠른 배포 및 운영 가능

	- 단점:
		- 지연 발생 가능성 (Cold Start 문제)
		- 커스터마이징 및 튜닝 제한
		- 사용량 기반 과금으로 비예측적 비용 발생 우려

	- 예: AWS Aurora Serverless, Firebase Realtime DB

- 블록체인 기반 데이터 저장 방식과 기존 DB의 차이
	- 블록체인:
		- 불변성: 기록 후 변경 불가
		- 분산 합의: 중앙 통제자 없음
		- 투명성: 모든 참여자가 동일 데이터 보유
		- 추적성: 데이터 생성·변경 이력 추적 가능

	- 기존 DB:
		- 수정 가능, 중앙 집중 관리, 성능 중심

	- 블록체인은 신뢰 기반 기록 시스템에 적합하며, 기존 DB는 속도와 복잡한 질의에 적합하다.

- 데이터베이스에서 AI 및 머신러닝을 활용한 자동화·최적화 기술
	- 활용 분야:
		- 자동 인덱스 추천 및 생성 (예: Oracle Automatic Indexing)
		- 실행 계획 튜닝 최적화 (예: SQL Plan Management with ML)
		- 이상 쿼리 탐지 및 성능 분석
		- 데이터 정합성 검사 및 오류 탐지
		- 질의 추천 및 자동 작성

	- AI 기반 DB는 튜닝 자동화와 관리 효율성을 극대화한다.

- 엣지 컴퓨팅에서 데이터베이스 활용 방안
	- 개념:
		- 엣지 컴퓨팅은 데이터가 생성되는 장치나 근처에서 실시간 처리와 저장을 수행하는 분산 처리 모델이다.

	- 활용 방안:
		- 로컬 DB 내장: SQLite, Realm, LiteDB 등 사용
		- 오프라인 처리 후 동기화: 중앙 서버와 지연 없는 데이터 동기화
		- 센서 데이터의 실시간 분석 및 필터링
		- 보안성 강화: 데이터가 외부로 이동하지 않음

	- 엣지 DB는 지연 최소화, 네트워크 의존성 해소, 프라이버시 확보에 유리하다.

- 양자 데이터베이스(Quantum DB)의 개념과 기존 DB와의 차이
	- 개념:
		- 양자 컴퓨팅 기반 데이터베이스로, 큐비트(qubit)를 활용하여 고속 병렬 연산과 암호화를 수행한다.
		- 현재는 연구 및 이론 수준이지만 향후 고속 검색 및 보안 혁신 기대.

	- 차이점:
		- 데이터 표현: 이진 비트 vs 양자 상태
		- 처리 능력: 지수적 병렬성 vs 선형 처리
		- 보안 모델: 양자암호 기반 보안성 강화
		- 상용화 수준: 전통 DB는 성숙, 양자 DB는 초기 연구 단계

	- 양자 DB는 암호화, 대규모 탐색, 복잡 쿼리 최적화에 응용 가능성이 있다.

- 디지털 트윈(Digital Twin)과 데이터베이스의 연관성
	- 개념:
		- 디지털 트윈은 현실 세계의 물리적 객체나 시스템을 디지털 환경에 동일하게 구현한 가상 모델이다.
		- 실시간 데이터와 시뮬레이션을 통해 상태 예측, 유지보수, 최적화에 활용된다.

	- DB 연관성:
		- 센서 데이터 수집 및 저장: IoT 장비에서 수집된 데이터를 DB에 저장
		- 이력 관리: 시계열 DB 활용하여 트윈의 상태 변화 추적
		- 시뮬레이션 결과 저장: 예측 정보, 결과 데이터를 분석 가능하도록 저장
		- 연동 분석: 분석 엔진과 DB 간 실시간 연계 필요 (AI, ML, BI 등)

	- 디지털 트윈은 고속·대용량 데이터 처리, 정합성, 시계열 DB 요구가 크다.

- 데이터베이스와 IoT 데이터 처리 방식의 차이
	- IoT 데이터 처리 특징:
		- 데이터 양이 방대하고 생성 주기가 짧다
		- 다양한 센서 형식(비정형, 반정형)이 존재
		- 실시간 수집 및 분석이 요구됨
		- 장치 간 데이터 상호 작용이 많음

	- 전통 DB 처리와의 차이:
		- RDBMS: 정형 데이터, 트랜잭션 중심
		- IoT DB: 시계열(Time Series), 스트리밍 처리 기반
		- 저장 구조: 디스크 기반 vs In-Memory, 분산 저장
		- 처리 방식: 주기적 트랜잭션 vs 이벤트 기반 비동기 처리

	- 대표 IoT용 DB: InfluxDB, TimescaleDB, Firebase Realtime DB 등

- NoSQL과 NewSQL 데이터베이스의 차이
	- NoSQL:
		- 스키마 유연, 수평 확장
		- BASE 일관성
		- 문서형, 키-값형, 그래프형 등 다양
		- 예: MongoDB, Cassandra
	
	- NewSQL:
		- SQL 문법 유지
		- ACID 지원
		- 수평 확장성 + 관계형 모델
		- 예: Google Spanner, CockroachDB

	- 차이점:
		- NoSQL은 비정형 데이터 처리에 최적
		- NewSQL은 기존 SQL 기반 환경의 확장성과 정합성 동시 확보가 장점이다.

- 데이터 스트리밍 플랫폼(Kafka, Flink)과 데이터베이스의 관계
	- 데이터 스트리밍 플랫폼
		- Kafka:
			- 분산 메시지 큐
			- 실시간 데이터 수집 및 전달
			- 데이터 저장보다 전달·중계 중심
		- Flink:
			- 실시간 스트리밍 처리 엔진
			- 이벤트 기반 연산, 상태 유지, 복합 이벤트 처리 가능

	- DB 연계 역할:
		- Kafka로 수집 → DB 저장 또는 분석 시스템 연계
		- Flink는 데이터 흐름 중간에서 필터링/집계 후 DB에 반영
		- 스트리밍 처리 이후 결과를 RDB, DWH, NoSQL 등에 저장

	- 이들은 DB와 연계된 실시간 데이터 파이프라인의 핵심 구성요소이다.

- 개인정보 보호를 위한 분산 데이터 저장 기술
	- 동형암호(Homomorphic Encryption):
		- 암호화된 상태에서 연산 가능
		- 데이터 복호화 없이 분석 가능
		- 개인정보 노출 없이 머신러닝 수행 가능

	- 안전 다자간 계산(Secure Multi-Party Computation):
		- 여러 당사자가 서로의 정보를 알지 않고도 연산 수행
		- 예: 병원 간 의료 데이터 협력 분석

	- 특징:
		- 데이터 이동 없이 보호 중심의 연산 가능
		- 비식별화·암호화와 함께 활용 가능
		- 의료, 금융, 공공 분야에서 활용성 증가

- IT 및 데이터베이스 관리에서 ESG 트렌드의 영향
	- Environmental (환경):
		- 에너지 절감형 인프라: 그린 데이터센터, 탄소 배출 최소화
		- 서버리스·가상화 인프라 사용 확대

	- Social (사회):
		- 개인정보 보호 및 윤리적 데이터 활용
		- 사용자 데이터의 투명한 처리 정책 강화

	- Governance (지배구조):
		- 데이터 거버넌스 강화
		- AI/DB 운영 윤리 기준 수립
		- ESG 보고용 데이터 추적 가능 시스템 필요

	- DB 운영도 지속 가능성, 책임성, 투명성의 관점에서 재설계되는 흐름이다.

- 트랜잭션(Transaction)의 개념과 ACID 특성
	- 트랜잭션:
		- 데이터베이스에서 하나의 논리적 작업 단위를 이루는 연산 집합으로, 모두 수행되거나 전혀 수행되지 않아야 하는 원자적 작업이다.

	- ACID 특성:
		- Atomicity(원자성): 전부 수행 또는 전부 취소
		- Consistency(일관성): 수행 전후 DB 상태가 규칙에 부합
		- Isolation(격리성): 동시 수행 시 서로 간섭 없음
		- Durability(지속성): 커밋된 변경은 영구 보존

	- 트랜잭션은 데이터 무결성과 신뢰성 확보의 핵심 개념이다.

- 트랜잭션 장애의 유형
	- 논리적 장애: 애플리케이션 오류, 사용자 실수로 인한 데이터 손상
	- 시스템 장애: 전원 장애, OS/DBMS 다운 등 일시적 장애
	- 미디어 장애: 디스크 손상, 스토리지 물리적 오류 등

	- 각 장애 유형에 따라 복구 범위와 방식이 달라진다.

- 트랜잭션의 격리 수준과 주요 유형
	- 격리 수준(Isolation Level):
		- 트랜잭션이 다른 트랜잭션의 중간 결과를 볼 수 있는지의 허용 범위를 의미한다.
	- 주요 수준:
		- Read Uncommitted: 커밋 전 데이터도 읽음 → Dirty Read 발생
		- Read Committed: 커밋된 데이터만 읽음 → Non-repeatable Read 가능
		- Repeatable Read: 같은 조건 재조회 결과 일치 → Phantom Read 가능
		- Serializable: 트랜잭션 직렬 실행처럼 처리 → 가장 엄격, 성능 저하

	- 높은 수준일수록 데이터 정합성은 보장되나 동시성은 떨어진다.

- 데이터베이스 장애 복구 개념과 주요 기법
	- 개념:
		- 트랜잭션 처리 중 발생한 장애를 복구하여 데이터의 무결성과 일관성을 유지하는 기술이다.

	- 주요 기법:
		- Redo: 커밋된 트랜잭션의 변경 사항을 반영
		- Undo: 비정상 종료된 트랜잭션의 변경사항을 취소
		- Checkpoint: 특정 시점의 상태를 저장하여 복구 시간 단축

	- 이들은 로그 파일과의 연동을 통해 복구 작업을 수행한다.

- 로그 기반 회복 기법(Log-Based Recovery)의 개념과 주요 방식
	- 개념:
		- 트랜잭션 수행 내역을 로그에 기록하여 장애 발생 시 해당 로그를 이용해 복구 작업을 수행하는 방법이다.

	- 주요 방식:
		- Deferred Update: 트랜잭션 완료 후에만 DB 반영 (Redo 중심)
		- Immediate Update: 수행과 동시에 DB 반영, 실패 시 Undo 필요
		- 로그 순서 기록: Before/After Image 사용하여 변경 이력 추적

	- 로그 기반 복구는 ACID 중 원자성과 지속성 보장을 위한 핵심 수단이다.

- 데이터베이스 복제(Replication)와 이중화(Failover)의 차이
	- Replication:
		- 데이터 실시간 복제
		- 읽기 부하 분산, 가용성 향상
		- 마스터-슬레이브 구조, 멀티 마스터 구조 가능
	- Failover:
		- 장애 발생 시 대체 시스템 자동 전환
		- 고가용성(HA) 구현에 필수
		- 복제와 함께 구성되어 장애 대비

	- Replication은 성능 확장 중심, Failover는 무중단 서비스 보장 중심이다.

- 트랜잭션 커밋(Commit)과 롤백(Rollback)의 개념과 차이
	- Commit:
		- 트랜잭션 정상 종료 → 변경사항 영구 반영
		- 지속성(Durability) 확보
	- Rollback:
		- 트랜잭션 실패 또는 취소 → 변경사항 취소
		- 원자성(Atomicity) 확보

	- 이 둘은 트랜잭션의 종료 처리 방식이며, DB 일관성 유지에 핵심 역할을 한다.

- WAL(Write-Ahead Logging)의 개념과 필요성
	- 개념:
		- 변경 내용이 데이터베이스에 반영되기 전에, 해당 변경 내용을 먼저 로그에 기록하는 방식이다.

	- 필요성:
		- 장애 발생 시 로그 기반으로 복구 가능
		- Redo/Undo를 위한 로그 일관성 확보
		- 트랜잭션 원자성과 지속성 보장

	- WAL은 거의 모든 DBMS의 기본적인 복구 아키텍처로 적용된다.

- MVCC(Multi-Version Concurrency Control) 기법의 개념과 주요 특징
	- 개념:
		- MVCC는 데이터의 다중 버전을 유지하여, 트랜잭션 간 충돌 없이 읽기와 쓰기를 동시에 병행할 수 있도록 하는 동시성 제어 기법이다.

	- 주요 특징:
		- 쓰기 잠금 없이 읽기 가능(Read without Lock)
		- 트랜잭션은 자신이 시작된 시점의 스냅샷을 기반으로 동작
		- 오래된 버전은 Garbage Collection 또는 Vacuum으로 정리
		- PostgreSQL, Oracle, MySQL(InnoDB) 등에서 사용

	- MVCC는 고성능 OLTP 시스템의 동시성 확보에 효과적이다.

- ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)의 개념과 주요 특징
	- 개념:
		- ARIES는 DBMS에서 장애 발생 시 정확하고 빠른 복구를 보장하기 위한 고급 로그 기반 복구 알고리즘이다. 
		- IBM System R을 기반으로 개발되었다.

	- 주요 특징:
		- WAL(Write-Ahead Logging) 기반
		- Redo/Undo 모두 수행 가능
		- 로그 순서 제어 (LSN) 기반 복구
		- 세 단계 복구 절차:
			- Analysis: 실패 지점 파악
			- Redo: 마지막 커밋된 상태까지 반영
			- Undo: 비정상 트랜잭션 롤백

	- ARIES는 복잡한 트랜잭션 처리와 높은 신뢰성을 요구하는 환경에서 표준처럼 사용된다.

- 데이터 마이닝(Data Mining)의 개념과 주요 활용 사례
	- 개념:
		- 대용량 데이터에서 숨겨진 패턴, 관계, 지식 등을 자동으로 발견하여 의미 있는 정보를 추출하는 분석 기법이다.

	- 주요 활용 사례:
		- 이커머스: 상품 추천, 구매 연관 분석
		- 금융: 이상 거래 탐지, 고객 이탈 예측
		- 의료: 질병 예측, 유전자 분석
		- 산업: 품질 이상 탐지, 설비 고장 예측
		- 마케팅: 고객 세분화, 캠페인 효과 분석

	- 데이터 마이닝은 AI, 빅데이터 분석의 기반 기술로 활용된다.

- 데이터 마이닝의 주요 기법
	- 연관 분석(Association Analysis): 아이템 간 연관 규칙 추출 (예: 장바구니 분석)
	- 분류(Classification): 레이블이 있는 데이터를 기반으로 예측 모델 생성 (예: 스팸 메일 분류)
	- 군집화(Clustering): 유사한 특성의 데이터를 자동으로 그룹화 (예: 고객 유형 분류)
	- 회귀 분석(Regression): 연속형 값을 예측 (예: 매출 예측, 온도 예측)

	- 이 기법들은 머신러닝 알고리즘(SVM, Decision Tree, KNN 등)과 연계되어 적용된다.

- 연관 규칙 분석(Association Rule Mining)과 Apriori 알고리즘
	- 연관 규칙 분석:
		- 데이터 내에서 항목 간의 조건적 관계(If-Then)를 추출하는 기법으로, 대표적으로 마트 장바구니 분석에 활용된다.

	- Apriori 알고리즘:
		- 빈발 항목집합(Frequent Itemset)을 기반으로 연관 규칙 생성
		- 지지도(Support), 신뢰도(Confidence) 기준으로 필터링
		- 후보 집합을 단계적으로 생성하고 가지치기(Pruning)하여 효율 개선

	- Apriori는 이항 관계 분석에서 가장 널리 사용되는 알고리즘이다.

- 군집 분석(Clustering)의 개념과 주요 기법
	- 개념:
		- 레이블이 없는 데이터에서 유사한 속성을 가진 데이터끼리 그룹화(클러스터링) 하는 비지도 학습 기법이다.
	- 주요 기법:
		- K-Means: 중심점(k)을 기준으로 데이터 군집화
		- Hierarchical Clustering: 계층적 병합 또는 분할 방식
		- DBSCAN: 밀도 기반 클러스터링, 이상치 탐지에 유리
		- Gaussian Mixture Model: 확률적 모델 기반 군집화

	- 군집 분석은 마케팅, 추천 시스템, 이미지 분류 등에서 폭넓게 활용된다.

- 차원 축소(Dimensionality Reduction) 기법(PCA, t-SNE)의 개념과 활용 사례
	- 개념:
		- 차원 축소는 고차원 데이터를 정보 손실을 최소화하면서 저차원으로 변환하여 시각화, 연산 효율 향상, 노이즈 제거 등에 활용하는 기법이다.

	- 주요 기법:
		- PCA (주성분 분석): 분산이 큰 방향(주성분)을 기준으로 정사영
		- t-SNE: 비선형 차원 축소 기법, 고차원 데이터의 클러스터 시각화에 강함

	- 활용 사례:
		- 이미지, 텍스트, 유전자 등 고차원 데이터 시각화
		- 노이즈 제거 및 특성 추출
		- 모델 학습 전 데이터 전처리

- 이상치 탐지(Anomaly Detection)의 개념과 주요 기법
	- 개념:
		- 정상 데이터의 패턴에서 벗어난 비정상적인 데이터(이상치)를 탐지하는 기법
		- 보안, 품질, 금융 등 분야에 필수적이다.

	- 주요 기법:
		- 통계 기반: 평균 ± 3표준편차
		- 거리 기반: KNN, DBSCAN 등
		- 밀도 기반: LOF(Local Outlier Factor)
		- 기계학습 기반: Isolation Forest, Autoencoder 등

	- 이상치 탐지는 침입 탐지, 부정 결제, 고장 예측에 자주 활용된다.

- 텍스트 마이닝(Text Mining)의 개념과 주요 활용 사례
	- 개념:
		- 비정형 텍스트 데이터에서 의미 있는 정보를 자동으로 추출하는 분석 기법이다.
		- 자연어처리(NLP) 기술과 밀접한 관련이 있다.

	- 활용 사례:
		- 감성 분석 (리뷰 긍/부정)
		- 키워드 추출 및 문서 요약
		- 문서 분류 및 유사 문서 탐색
		- 챗봇 및 검색 시스템 개선

	- 대표 알고리즘: TF-IDF, Word2Vec, BERT 등

- 시계열 분석(Time Series Analysis)의 개념과 주요 활용 사례
	- 개념:
		- 시간의 흐름에 따라 수집된 데이터를 분석하여 추세, 계절성, 이상값, 예측 모델을 구축하는 기법이다.

	- 활용 사례:
		- 매출/재고 예측
		- 기상, 에너지, 수요 예측
		- 이상 징후 탐지 (서버 CPU 급증 등)
		- 주식·환율 등 금융 예측

	- 모델: ARIMA, Prophet, LSTM 등

- 피처 엔지니어링(Feature Engineering)의 개념과 주요 기법
	- 개념:
		- 데이터의 예측력을 높이기 위해 의미 있는 특징(Feature)을 생성, 선택, 변환하는 과정이다.
		- 머신러닝 모델 성능에 결정적인 영향을 미친다.

	- 주요 기법:
		- 피처 생성: 날짜 → 요일, 시간대 등
		- 피처 선택: 중요도 기반 필터링, L1 정규화
		- 정규화/표준화: 데이터 분포 정규 조정
		- 원-핫 인코딩, 로그 변환 등

	- 잘 설계된 피처는 복잡한 모델보다 더 나은 성능을 발휘할 수 있다.

- 빅데이터 분석에서 AI 및 머신러닝 활용 방안
	- 활용 분야:
		- 예측 분석: 수요, 판매량, 장비 고장 등 예측
		- 분류/군집 분석: 고객 세분화, 문서 자동 분류
		- 이상 탐지: 부정 행위, 장애 징후 탐지
		- 추천 시스템: 사용자 행동 기반 개인화 추천
		- 자연어처리: 챗봇, 문서 분류, 요약 등

	- 적용 기술:
		- Spark MLlib, TensorFlow, Scikit-Learn, PyTorch
		- AutoML, Feature Store, MLOps 기반 운영

	- AI/ML은 빅데이터를 실시간·지능형 의사결정의 핵심 자산으로 전환시켜준다.

- 데이터베이스 설계의 주요 과정과 단계
	- 개념:
		- 데이터베이스 설계는 업무 요건을 기반으로 데이터 구조를 체계적으로 정의하고 최적화하는 일련의 절차이다.

	- 단계:
		- 개념적 설계: ERD 작성, 엔터티 및 관계 정의
		- 논리적 설계: 관계형 모델로 변환, 정규화 수행
		- 물리적 설계: 저장 구조, 인덱스, 파티셔닝 등 물리 자원 최적화 설계

	- 설계는 상위 단계에서 점차 구체화되며, 성능·보안·확장성에 영향을 미친다.

- 데이터베이스 아키텍처(1-Tier, 2-Tier, 3-Tier)의 개념과 차이
	- 1-Tier: 사용자와 DB가 동일 시스템에 존재 (단일 계층)
	- 2-Tier: 클라이언트-서버 구조, 클라이언트는 UI, 서버는 DB 처리
	- 3-Tier: 프레젠테이션-비즈니스 로직-DB로 역할 분리 → 유지보수 용이, 보안 강화

	- 3-Tier 구조는 대규모 시스템에서 확장성과 안정성을 확보할 수 있는 대표적 아키텍처다.

- OLTP와 OLAP의 개념과 차이
	- OLTP (Online Transaction Processing):
		- 실시간 트랜잭션 처리 시스템
		- INSERT/UPDATE 중심, 정규화 구조
		- 빠른 응답과 일관성 유지 중요
	- OLAP (Online Analytical Processing):
		- 분석 및 집계 중심 시스템
		- SELECT/JOIN 중심, 비정규화 구조
		- 복잡 쿼리 성능 최적화 중점

	- OLTP는 운영, OLAP은 분석 용도로 구분된다.

- 데이터베이스 성능 모니터링 및 튜닝 기법
	- 모니터링 항목:
		- 쿼리 성능(Slow Query), CPU/메모리, I/O 지연
		- Lock, Deadlock, Wait Event, Cache Hit Ratio 등

	- 튜닝 기법:
		- 인덱스 설계 최적화
		- SQL 재작성 (JOIN 순서, 서브쿼리 개선 등)
		- 통계 정보 갱신
		- 파티셔닝, 병렬 처리 적용
		- 커넥션 풀 관리

	- 튜닝은 전체 시스템 자원의 병목 구간을 찾아 점진적 최적화가 원칙이다.

- 데이터베이스 백업과 복구의 주요 방법
	- 백업:
		- 정지 백업(Cold): DB 중지 후 전체 백업
		- 운영 중 백업(Hot): 트랜잭션 중에도 백업 가능
		- 증분/차등 백업: 변경분만 백업하여 효율화
		- 스냅샷: 순간 시점 전체 복사본 생성

	- 복구:
		- 전체 복구(Full Recovery), 시점 복구(Point-in-Time), 트랜잭션 복구(Redo/Undo)

	- 백업/복구는 RTO/RPO 기준에 따라 전략이 달라진다.

- 관계형 DB와 비관계형 DB의 차이
	- 관계형(RDBMS):
		- 정형 데이터, 고정 스키마
		- SQL 기반, ACID 보장
		- 예: Oracle, MySQL
	- 비관계형(NoSQL):
		- 비정형/반정형 데이터, 유연한 스키마
		- 수평 확장성 중심, BASE 특성
		- 예: MongoDB, Cassandra, Redis

	- 데이터 유형과 확장성 요구에 따라 선택 기준이 달라진다.

- 온프레미스와 클라우드 DB의 차이
	- 온프레미스:
		- 자체 구축, 직접 관리
		- 보안성과 통제력 높음
		- 초기 비용과 유지비 부담 큼
	- 클라우드 DB:
		- DBaaS 형태, 자동 관리
		- 탄력적 확장, 비용 효율성
		- 벤더 종속과 보안 규제 이슈 존재

	- 클라우드 DB는 민첩성과 확장성이 중요할 때 유리하다.

- 데이터베이스 시스템에서 장애 발생 시 대응 전략
	- 장애 유형별 대응 전략:
		- 논리적 장애: 트랜잭션 롤백, Undo 로그 활용
		- 시스템 장애: 체크포인트 이후 로그 기반 복구
		- 미디어 장애: 전체 백업 + Redo 로그로 복원

	- 대응 방안:
		- 장애 감지를 위한 모니터링 시스템 구축
		- 자동 Failover 구성 (이중화)
		- 복구 시나리오 사전 정의 (RTO/RPO 기준)
		- 정기적 백업 및 복구 테스트 수행

	- 핵심: 데이터 무결성 유지와 서비스 연속성 보장이 목표

- 대용량 데이터 처리를 위한 분산 데이터베이스 설계 방법
	- 설계 전략:
		- 샤딩(Sharding): 수평 분할을 통한 성능 분산
		- 복제(Replication): 읽기 부하 분산 및 고가용성
		- 분산 쿼리 처리: 분산 실행 계획 기반 최적화
		- 데이터 정합성 관리: Eventual vs Strong Consistency 고려

	- 기술 적용: NoSQL, NewSQL, Hadoop 기반 DBMS 등

	- 핵심: 확장성과 정합성 사이의 균형 있는 구조 설계

- DB 보안 강화를 위한 접근 제어 및 암호화 기법
	- 접근 제어:
		- RBAC: 역할 기반 권한 설정
		- DAC/MAC: 소유자 중심 또는 보안등급 기반 제어
		- IAM 연동: 클라우드/통합 인증과 연계

	- 암호화 기법:
		- TDE: 테이블·파일 전체 암호화
		- 컬럼 암호화: 민감 데이터 선택적 암호화
		- 전송 구간 암호화: SSL/TLS로 네트워크 보호

	- 보안 정책 수립과 함께 정기적인 감사를 병행해야 한다.

- DB 관리에서 AI 기반 자동화 및 최적화 기술
	- 자동화 영역:
		- 자동 인덱스 관리
		- SQL 튜닝 추천 및 실행 계획 최적화
		- 이상 탐지 및 성능 경고
		- 리소스 사용량 예측 및 Auto-Scaling

	- 활용 기술: 머신러닝, 딥러닝, Reinforcement Learning

	- AI 기반 DB 관리는 관리자의 개입 없이 자가 최적화하는 자율 DB 구현을 지향한다.

- Graph Database의 개념과 RDBMS/NoSQL과의 차이
	- 개념:
		- 노드(Node)와 엣지(Edge)로 데이터와 관계를 표현하는 DB. 관계 중심 문제 해결에 특화.

	- 특징:
		- JOIN 없이 빠른 관계 탐색
		- 유연한 스키마, 실시간 탐색
		- Cypher, Gremlin 등 쿼리 언어 사용

	- 비교:
		- RDBMS: 정형, 테이블 기반, JOIN 성능 저하
		- NoSQL: 비정형, 문서 중심, 관계 탐색 어려움
		- GraphDB: 복잡한 관계형 구조에 최적화

	- 활용 사례: SNS, 추천 시스템, 네트워크 분석

- 엣지 컴퓨팅 환경에서 데이터베이스의 역할
	- 역할:
		- 로컬 데이터 저장: 지연 없는 처리 (SQLite, InfluxDB 등)
		- 실시간 분석: 필터링, 경보 판단, AI 추론 수행
		- 오프라인 운영: 연결 불안정한 환경에서도 동작 보장
		- 중앙 DB 동기화: 주기적 또는 이벤트 기반 전송

	- 엣지 DB는 속도, 안정성, 프라이버시 보호 측면에서 중요하며, IoT·스마트팩토리·의료 등에서 활용도 높음.

- 데이터 프라이버시 보호를 위한 동형 암호화(Homomorphic Encryption) 기법
	- 개념:
		- 동형 암호는 암호화된 상태에서 연산이 가능한 암호 방식으로, 복호화하지 않고도 합산, 곱셈 등의 연산을 수행할 수 있다.

	- 특징:
		- 보안성과 데이터 활용의 양립 가능
		- 암호화된 데이터를 외부에 위탁 처리해도 원본 노출 없음
		- 완전 동형 암호(FHE), 부분 동형 암호(PHE)로 구분됨

	- 활용 사례:
		- 민감 데이터 기반 분석, 클라우드 기반 AI 연산, 의료·금융 데이터 보호

- Serverless Database의 개념과 주요 활용 사례
	- 개념:
		- 서버 인프라를 직접 관리하지 않고, 자동 확장·중단·과금이 이루어지는 완전 관리형 데이터베이스 서비스

	- 특징:
		- 사용량 기반 요금 (pay-per-use)
		- Cold Start 이슈 존재 가능
		- 복잡한 설정 없이 빠른 구축 가능

	- 활용 사례:
		- 소규모 스타트업의 민첩한 개발 환경
		- 간헐적 트래픽이 있는 서비스 (예: 이벤트성 앱, 테스트 서버)
		- 백엔드리스(Backendless) 모바일 앱

- 블록체인 기반 데이터베이스의 개념과 기존 DB와의 차이
	- 개념:
		- 데이터를 블록 단위로 체인처럼 연결하고 참여자 간 합의를 통해 분산 저장하는 탈중앙형 DB 시스템

	- 특징:
		- 변조 불가능(불변성)
		- 트랜잭션 추적성 및 투명성 확보
		- 성능보다 신뢰 확보 중심

	- 기존 DB와 차이점:
		- 중앙 서버 vs P2P 분산 구조
		- 빠른 응답 vs 신뢰 기반 처리
		- 수정·삭제 가능 vs 불가능

	- 활용 사례: 디지털 계약, 물류 추적, 분산 인증 등

- 멀티 클라우드 데이터베이스(Multi-Cloud DB)의 개념과 주요 장단점
	- 개념:
		- 두 개 이상의 클라우드 플랫폼에서 데이터베이스를 동시에 구성·운영하여 이중화, 가용성, 벤더 종속 최소화를 실현하는 전략

	- 장점:
		- 장애 시 빠른 전환 및 백업
		- 클라우드 간 경쟁력 활용
		- 규제 대응 및 지역 이중화 가능

	- 단점:
		- 운영 복잡성 증가
		- 데이터 정합성 및 동기화 이슈
		- 네트워크 비용 증가

	- 멀티 클라우드는 탄력적이고 회복력 높은 아키텍처를 지향할 때 적합하다.

- NewSQL의 개념과 기존 RDBMS, NoSQL과의 차이
	- NewSQL:
		- 관계형 DB의 장점(ACID, SQL)을 유지하면서도 NoSQL 수준의 수평 확장성과 고성능을 제공하는 차세대 DBMS

	- 비교:
		- RDBMS: SQL + ACID, 단일 서버 중심
		- NoSQL: 유연한 스키마 + 수평 확장, 정합성 낮음
		- NewSQL: SQL + ACID + 수평 확장

	- 대표 제품: Google Spanner, CockroachDB, TiDB 등

	- NewSQL은 대규모 트랜잭션을 분산 환경에서도 정합성 있게 처리하고자 할 때 적합하다.

- Federated Database System의 개념과 활용 사례
	- 개념:
		- 서로 다른 DBMS나 스키마를 갖는 데이터베이스들을 논리적으로 통합하여 단일 시스템처럼 조회하고 관리할 수 있도록 구성한 시스템

	- 특징:
		- 물리적으로 분산된 DB 간 연결
		- 중앙 통합 없이 독립성 유지
		- 이기종 DB 간 데이터 연동 가능

	- 활용 사례:
		- 대기업 계열사별 DB 통합 분석
		- 병원 간 환자 진료 이력 공유
		- 공공기관 간 이기종 시스템 통합

	- Federated DB는 데이터 분산성과 독립성을 동시에 유지할 수 있다.

- Digital Twin과 데이터베이스의 연관성
	- Digital Twin:
		- 현실 세계의 물리적 대상(설비, 도시 등)을 가상 모델로 실시간 동기화하여 시뮬레이션, 예측, 분석이 가능한 시스템

	- DB 연관성:
		- 센서 데이터 저장 및 시계열 관리
		- 이력 정보와 가상 상태 비교
		- AI 분석 결과 저장 및 추론 연동
		- IoT, 엣지 DB, 그래프 DB 등과 통합

	- Digital Twin은 DB를 통해 현실과 가상의 연결 고리를 실시간으로 유지한다.

- 관계형 데이터베이스 설계에서 개념적 설계와 논리적 설계의 차이
	- 개념적 설계: (ERD)
		- 사용자의 요구사항을 바탕으로 데이터 구조를 비즈니스 관점에서 시각화
		- ERD(Entity-Relationship Diagram) 작성 중심
		- 데이터 간 관계, 엔터티, 속성 식별

	- 논리적 설계: (릴레이션)
		- 개념 모델을 기반으로 DBMS에 맞는 논리적 구조(릴레이션)로 변환
		- 정규화 수행, 기본키·외래키 지정
		- 스키마 정의(SQL DDL 작성 전 단계)

	- 차이점 요약:
		- 개념적 설계는 업무 중심, 논리적 설계는 데이터베이스 논리 구조 중심

- 물리적 데이터베이스 설계의 개념과 주요 고려 사항
	- 개념:
		- 논리적 설계를 기반으로, DBMS의 저장 구조 및 성능을 고려하여 실제 데이터 저장 구조를 설계하는 단계

	- 주요 고려 사항:
		- 테이블·인덱스 생성 방식
		- 데이터 타입과 저장 크기 최적화
		- I/O 분산과 파티셔닝 구조 설계
		- 쿼리 성능 향상을 위한 클러스터링, 뷰, 조인 방식 고려
		- 백업 및 복구 전략, 보안 정책 반영

	- 물리적 설계는 시스템 성능, 유지보수, 확장성 확보에 핵심적 역할을 한다.

- ERD(Entity-Relationship Diagram)의 개념과 주요 구성 요소
	- 개념:
		- 데이터베이스의 개체(Entity), 속성(Attribute), 관계(Relationship)를 시각적으로 표현한 다이어그램으로, 개념적 설계의 핵심 도구

	- 주요 구성 요소:
		- 엔터티(Entity): 사각형, 실제 개념(고객, 제품 등)
		- 속성(Attribute): 타원형, 엔터티의 특성
		- 관계(Relationship): 마름모형, 엔터티 간 연관성
		- 카디널리티(Cardinality): 관계의 수량적 특성(1:1, 1:N 등)

	- ERD는 요구사항을 데이터 구조로 구체화하는 도구이다.

- 정규화의 장점과 반정규화가 필요한 경우
	- 정규화 장점:
		- 데이터 중복 제거, 저장 공간 절약
		- 데이터 무결성 및 일관성 확보
		- 삽입/삭제/갱신 이상(Anomaly) 방지

	- 반정규화 필요 시점:
		- 조인 성능 저하
		- 과도한 테이블 분리로 인해 조회 효율 감소
		- 실시간 응답이 필요한 OLTP 시스템

	- 반정규화는 성능 향상을 위한 선택적 전략으로, 정규화와 균형 필요

- 정규형(Normal Form)의 개념과 주요 특징 (1NF~5NF)
	- 1NF: 반복 속성 제거, 원자값만 포함 (원자값)
	- 2NF: 부분 함수 종속 제거 (기본키 전체에만 종속)
	- 3NF: 이행적 함수 종속 제거 (비주요 속성 간 종속 제거)
	- BCNF: 모든 결정자가 후보키
	- 4NF: 다치 종속 제거
	- 5NF: 조인 종속 제거, 완전한 분해 유지

	- 정규형은 데이터 무결성과 구조의 단순성을 확보하기 위한 계층적 데이터 정제 기준이다.

- 데이터 무결성(Integrity Constraint)의 개념과 주요 제약 조건
	- 개념:
		- 데이터의 정확성, 일관성, 신뢰성을 보장하기 위한 DB 수준의 규칙 또는 제약 조건

	- 주요 제약 조건:
		- 기본키(Primary Key): 고유 식별자, NULL 불가
		- 외래키(Foreign Key): 다른 테이블과의 참조 관계 유지
		- 고유 제약(Unique): 중복 불가, NULL 허용
		- 도메인 제약(Check): 속성 값의 범위 제한

	- 무결성 제약은 데이터 오류를 사전에 차단하는 역할을 수행한다.

- 관계형 모델에서 이상(Anomaly)의 개념과 발생 원인
	- 이상(Anomaly):
		- 비정규화된 데이터 구조에서 발생하는 데이터 중복 또는 불일치로 인한 부작용

	- 종류 및 원인:
		- 삽입 이상: 일부 정보만으로는 삽입 불가
		- 삭제 이상: 한 정보 삭제 시 다른 정보도 함께 삭제됨
		- 갱신 이상: 중복 데이터로 인해 일부만 갱신 시 불일치 발생
		- 원인: 정규화 미비, 중복된 속성, 비식별 관계

	- 정규화는 이러한 이상 현상을 구조적으로 제거하는 핵심 기법이다.

- ER 모델에서 관계의 차수(Cardinality)와 참여도(Participation)의 개념
	- 차수(Cardinality):
		- 두 개체(Entity) 간의 관계에서 각 개체가 참여할 수 있는 수량적 범위를 의미한다. 예를 들어 1:1, 1:N, N:M 등이 있다.
		- 종류
			- 1:1: 각 엔터티가 한 번만 관계에 참여
			- 1:N: 하나의 엔터티가 여러 개체와 관계
			- M:N: 다대다 관계

	- 참여도(Participation):
		- 엔터티가 관계에 반드시 참여해야 하는지 여부를 나타냄
		- 종류
			- 전참여(Total Participation): 모든 인스턴스가 관계에 반드시 참여 (굵은 선)
			- 부분참여(Partial Participation): 일부만 참여 (얇은 선)

	- 요약: 차수는 수량, 참여도는 필수 여부를 나타낸다.

- 데이터 모델링에서 속성(Attribute)과 엔티티(Entity)의 차이
	- 엔티티(Entity):
		- 실세계에서 독립적으로 존재하며 정보를 저장할 필요가 있는 개체
		- 예: 고객, 주문, 상품 등
	- 속성(Attribute):
		- 엔티티가 가지는 특성이나 정보 항목
		- 예: 고객 이름, 주문일자, 상품가격 등

	- 차이점:
		- 엔티티는 정보의 주체, 속성은 정보의 내용

- 서브타입/슈퍼타입(Subtype/Supertype) 관계의 개념과 사용 사례
	- 개념:
		- 하나의 상위 개체(Supertype)가 공통 속성을 가지며, 하위 개체(Subtype)는 세부 특성 또는 추가 속성을 가진 관계
	- 특징:
		- 상속(Inheritance) 구조
		- ISA 관계로 표현
		- Disjoint(서브타입 상호 배타) 또는 Overlap(중복 가능) 가능
	- 사용 사례:
		- 직원(Employee) → 정규직(Full-Time), 계약직(Contract)
		- 탈것(Vehicle) → 자동차(Car), 오토바이(Bike)

	- 이는 개념적 데이터 모델에서 일반화/특수화 표현에 사용된다.

- 데이터베이스 성능 튜닝의 개념과 주요 기법
	- 개념:
		- DB 시스템의 성능 병목을 찾아 응답속도 향상 및 리소스 사용 최적화를 수행하는 기술

	- 주요 기법:
		- 인덱스 설계 최적화
		- 정규화/반정규화 조정
		- 통계 정보 갱신
		- 실행 계획 분석 및 SQL 개선
		- 연결 수, Buffer, Pool 등 파라미터 조정
		- 파티셔닝, 병렬 처리 적용

	- 성능 튜닝은 데이터 구조, 쿼리, 시스템 자원 전반에 걸쳐 수행되어야 한다.

- 데이터베이스에서 실행 계획(Execution Plan)의 개념과 주요 분석 방법
	- 개념:
		- DBMS가 SQL 쿼리를 실행하기 위해 선택한 최적화된 연산 순서와 접근 방법을 설명하는 계획

	- 분석 방법:
		- 인덱스 사용 여부 확인
		- 풀 스캔 vs 인덱스 스캔 구분
		- 조인 순서 및 조인 방식 확인(Nested Loop, Hash Join 등)
		- 비용(Cost), 추정 행 수(Estimated Rows), 필터 조건 등 확인

	- 실행 계획은 SQL 튜닝의 핵심 도구로, 성능 병목을 진단하는 데 필수이다.

- 데이터베이스 I/O 성능 최적화를 위한 주요 기법
	- I/O 병목 원인:
		- 디스크 접근, 인덱스 미사용, 불필요한 정렬, 조인 등
	- 최적화 기법:
		- 인덱스 활용 극대화
		- Clustered Index 구성
		- 쿼리 재작성으로 풀 스캔 제거
		- 파티셔닝으로 범위 제한
		- I/O 분산을 위한 테이블스페이스/디스크 설계
		- Buffer Pool 설정 조정

	- I/O 최적화는 전체 DB 성능 개선에서 가장 큰 영향 요소 중 하나이다.

- 데이터베이스 확장성에서 수직 확장과 수평 확장의 차이
	- 수직 확장(Vertical Scaling):
		- 더 강력한 CPU, 메모리, 스토리지를 갖춘 서버로 업그레이드
		- 기존 시스템에 대한 리소스 증설 방식
		- 한계 도달 시 확장 어려움
		- 관리 간단, 즉시 효과 있음
		- 예: 단일 Oracle 서버에서 메모리 증가

	- 수평 확장(Horizontal Scaling):
		- 노드를 여러 대로 분산 운영하여 부하 분산
		- 샤딩, 클러스터링 기반 확장
		- 확장성과 가용성 뛰어남
		- 분산 처리 구조 필요
		- 예: NoSQL 기반 분산 저장소

- 데이터베이스 클러스터링의 개념과 주요 유형
	- 개념:
		- 두 개 이상의 DB 서버를 묶어 고가용성, 부하 분산, 성능 향상을 도모하는 구성 방식
	- 주요 유형:
	- Active-Active: 모든 노드가 동시에 읽기/쓰기 처리
		- 부하 분산 효과 우수
		- 충돌 해결 필요
	- Active-Passive: 하나는 서비스, 나머지는 대기 상태
		- 장애 시 빠른 전환(Failover)
		- 구현 단순, 성능은 제한적

- 데이터베이스 샤딩의 개념과 주요 구현 방식
	- 개념:
		- 데이터베이스를 샤드(Shard)라는 작은 단위로 수평 분할하여 여러 서버에 분산 저장하는 확장 기법
	- 구현 방식:
		- Range-Based Sharding: 특정 범위(예: ID 범위)로 나눔
		- Hash-Based Sharding: 해시 함수로 균등 분산
		- Directory-Based Sharding: 샤드 맵을 별도 관리 시스템이 유지

	- 샤딩은 성능과 확장성을 확보하면서도 복잡도 증가를 감수하는 구조

- 데이터베이스 부하 분산(Load Balancing) 기법
	- 기법:
		- 쿼리 라우팅: 읽기/쓰기 구분, 읽기는 슬레이브로 분산
		- Connection Pool 분산: 요청을 라운드로빈, 가중치 기반 등으로 분배
		- 프록시 서버 활용: 중계 서버에서 동적으로 분산 처리

	- 부하 분산은 가용성과 성능을 함께 확보하는 데 효과적

- 인덱스 튜닝의 개념과 주요 기법
	- 개념:
		- 인덱스를 통해 데이터 접근을 최적화하여 쿼리 성능을 향상시키는 작업

	- 기법:
		- 사용 빈도 높은 컬럼에 인덱스 추가
		- 복합 인덱스 구성
		- 불필요한 인덱스 제거
		- 쿼리 패턴에 맞는 인덱스 정렬

	- 인덱스는 과도하면 오히려 DML 성능 저하 유발 가능성 있으므로 균형이 중요

- 파티셔닝의 개념과 주요 유형
	- 개념:
		- 대형 테이블을 논리적으로 나누어 물리적으로 여러 파티션에 저장하여 성능, 관리 효율을 높이는 기법
	- 유형:
		- Range Partitioning: 범위 기반 분할 (날짜, 숫자 등)
		- List Partitioning: 특정 값의 목록에 따라 분할 (지역, 카테고리 등)
		- Hash Partitioning: 해시 함수로 균등 분산
		- Composite Partitioning: 위 방법들을 혼합

	- 파티셔닝은 대용량 테이블에 대한 조회 및 유지보수 최적화에 효과적

- 데이터베이스 장애 처리 및 복구 전략
	- 장애 유형별 대응 전략:
		- 논리적 장애: 트랜잭션 Rollback, Undo 로그
		- 시스템 장애: 체크포인트 이후 Redo 로그 활용
		- 미디어 장애: 백업에서 복원 + Redo 로그 재적용

	- 복구 기법:
		- WAL(Write-Ahead Logging) 기반 복구
		- Redo/Undo 전략
		- Point-in-Time Recovery
		- Failover 시스템 및 복제 활용

	- 핵심은 무중단 서비스를 위한 사전 대응 체계 구축과 정기적인 검증

- 분산 데이터베이스 시스템의 개념과 주요 특징
	- 개념:
		- 물리적으로 분산된 데이터베이스들이 논리적으로 하나의 시스템처럼 작동하도록 구성한 DB 시스템

	- 주요 특징:
		- 분산 투명성: 사용자는 물리적 위치를 인식하지 않음
		- 중앙 제어 또는 분산 제어 가능
		- 로컬 자율성: 각 노드는 독립적 운영 가능
		- 확장성 및 신뢰성 우수

	- 분산 DB는 확장성과 지역 분산 운영에 적합한 아키텍처이다.

- 데이터 연합(Federated Database System)의 개념과 활용 사례
	- 개념:
		- 다양한 DBMS, 스키마, 위치를 가진 독립적인 DB 시스템들을 논리적으로 통합하여 하나의 DB처럼 접근할 수 있는 시스템

	- 활용 사례:
		- 공공기관 이기종 시스템 통합
		- 병원 간 의료 기록 공유
		- 다국적 기업의 지역별 DB 통합

	- 특징:
		- 물리적 통합 없이 연합
		- 각 DB의 자율성과 보안 유지
		- 데이터 일관성 확보가 관건

- CAP 이론과 분산 데이터베이스와의 관계
	- CAP 이론:
		- 분산 시스템에서 Consistency(일관성), Availability(가용성), Partition Tolerance(분할 허용성) 중 동시에 세 가지를 모두 만족할 수 없음
		- C: 모든 노드가 같은 데이터를 보여줌
		- A: 모든 요청에 대해 응답이 항상 가능
		- P: 네트워크 분할 시에도 시스템 동작 유지

	- 선택 예시:
		- CP: HBase (정합성 + 분할 허용)
		- AP: Cassandra (가용성 + 분할 허용)

- BASE 이론과 CAP 이론과의 관계
	- BASE 이론:
		- NoSQL 시스템에서 CAP의 Consistency를 희생하고 가용성과 확장성을 추구하는 접근 방식
		- Basically Available: 항상 가용한 시스템
		- Soft state: 일시적 불일치 허용
		- Eventual consistency: 결국 일관성 도달

	- 관계:
		- CAP 이론의 AP 조합에서 Consistency를 완화하고, 확장성과 유연성을 확보한 모델

- 분산 트랜잭션과 2PC의 개념
	- 분산 트랜잭션:
		- 여러 노드의 DB에 걸쳐 수행되는 트랜잭션. ACID 보장이 어려움

	- 2PC(2단계 커밋):
		- 1단계(Prepare): 각 노드에 트랜잭션 준비 요청
		- 2단계(Commit/Rollback): 모두 OK → 커밋 / 일부 실패 → 롤백

	- 문제점: Coordinator 장애 시 트랜잭션 교착 또는 지연 발생

- 데이터 레플리케이션의 개념과 주요 유형
	- 개념:
		- 하나의 DB 데이터를 다른 장소 또는 노드로 복제하여 가용성·성능 향상을 꾀하는 기술
	- 유형:
		- Synchronous Replication: 쓰기 시 동시 복제, 일관성 강함
		- Asynchronous Replication: 나중에 복제, 속도 빠름, 약한 일관성
	- 활용:
		- 장애 대비, 읽기 성능 향상, 지역 분산 처리

- 데이터 동기화의 개념과 주요 기법
	- 개념:
		- 여러 데이터 저장소 간의 데이터 일관성을 맞추기 위한 처리 과정

	- 주요 기법:
		- Change Data Capture(CDC): 변경 로그 기반 실시간 반영
		- Polling: 주기적 상태 확인 후 동기화
		- Event 기반 트리거 동기화: INSERT/UPDATE 시 실시간 전파
		- Conflict Resolution: 충돌 발생 시 정책 기반 해결

	- 데이터 동기화는 멀티 DB, 하이브리드 클라우드, 모바일 환경에서 핵심 요소

- NoSQL과 분산 데이터 저장 기술의 차이
	- NoSQL:
		- 비정형·반정형 데이터를 위한 비관계형 DBMS
		- 다양한 모델 지원 (Key-Value, Document, Graph 등)
		- 수평 확장에 용이, BASE 모델 기반
		- 예: MongoDB, Cassandra, Redis

	- 분산 데이터 저장 기술:
		- 데이터를 여러 노드에 분산 저장하여 확장성과 내결함성 확보
		- 분산 파일 시스템(HDFS), 분산 블록 스토리지, 오브젝트 스토리지 포함
		- 데이터 정합성 유지 및 분산 트랜잭션 처리 기술 필요

	- 차이점:
		- NoSQL은 데이터 모델과 API 관점, 분산 저장 기술은 저장 아키텍처 관점에서 구분

- 분산 데이터베이스의 데이터 일관성을 유지하기 위한 주요 기법
	- 기법:
		- Quorum Protocol: 최소 읽기/쓰기 노드 수를 설정하여 일관성 확보
		- Vector Clock: 버전 관리 기반의 일관성 조정
		- Conflict-Free Replicated Data Type (CRDT): 자동 충돌 해결을 위한 데이터 구조
		- Timestamp Ordering: 시간순 정렬로 일관성 확보
		- Eventual Consistency 모델에서 Read Repair, Hinted Handoff 등 보완 기법

	- 일관성 확보는 성능과 가용성의 균형점 조절이 핵심

- 블록체인 기반 데이터 저장 기술과 기존 분산 데이터베이스의 차이
	- 블록체인:
		- 트랜잭션을 블록 단위로 저장, 체인 형태로 연결
		- 불변성, 투명성, 탈중앙성 중심
		- 합의 알고리즘(PoW, PoS 등) 필요

	- 기존 분산 DB:
		- 중앙 제어 구조, CRUD 중심
		- 트랜잭션 처리와 정합성 우선
		- 복제와 샤딩, 동기화 기술 중심

	- 차이점:
		- 블록체인은 신뢰 기반 공유 저장소, 분산 DB는 성능 중심의 트랜잭션 시스템

- 데이터베이스 보안의 개념과 주요 보안 위협
	- 개념:
		- DB에 저장된 데이터를 무단 접근, 유출, 변조, 파괴로부터 보호하기 위한 기술·관리·물리적 대책

	- 주요 보안 위협:
		- SQL Injection
		- 계정 탈취 및 권한 상승
		- 데이터 유출(내부자 포함)
		- 취약한 암호화 및 인증 구조
		- 취약한 백업 데이터 보안

	- 보안은 기술적 조치 외에도 정책, 감사, 교육이 병행되어야 한다.

- 데이터베이스 접근 제어의 주요 기법 (RBAC, MAC, DAC)
	- RBAC(Role-Based Access Control): 역할 기반 접근 제어, 권한 관리 효율성 우수
	- MAC(Mandatory Access Control): 보안 등급 기반 강제적 접근 제어 (군사적 보안 환경 등)
	- DAC(Discretionary Access Control): 소유자가 접근 권한을 직접 제어, 유연성 높음

	- 접근 제어는 업무 목적, 보안 수준, 감사 필요성에 따라 혼합 적용 가능

- 데이터베이스 암호화의 개념과 주요 기법
	- 개념:
		- 데이터를 비인가자가 해독할 수 없도록 암호화하여 기밀성과 무결성을 확보하는 보안 기술

	- 주요 기법:
		- 컬럼 암호화: 특정 컬럼 단위 암호화, 세밀한 보안
		- TDE(Transparent Data Encryption): 전체 DB 파일 수준 암호화
		- 파일/디스크 암호화: 저장 장치 전체에 적용, DB 외부 접근 방지

	- 암호화는 접근 제어와 함께 핵심적인 데이터 보호 수단

- SQL Injection 공격의 개념과 주요 대응 기법
	- 개념:
		- 입력값에 악의적 SQL 구문을 삽입해, DB에 의도치 않은 명령을 실행시키는 공격 기법

	- 주요 대응 방안:
		- Prepared Statement/Parameterized Query 사용
		- 입력값 검증 및 필터링
		- 최소 권한 원칙 적용(DB 계정 권한 제한)
		- Web Application Firewall(WAF) 연동
		- 에러 메시지 노출 방지

	- SQL Injection은 기본 중의 기본이면서 가장 위험한 공격 중 하나로, 반드시 예방 코드를 구현해야 한다.

- 개인정보 보호법(GDPR, CCPA 등)의 주요 요구 사항
	- GDPR(유럽 일반 개인정보 보호법):
		- 데이터 최소화 및 목적 제한
		- 명시적 동의 및 투명한 처리
		- 정보 주체의 권리 보장(열람·정정·삭제·이동)
		- 72시간 내 유출 통보 의무
		- Privacy by Design, by Default 원칙 적용

	- CCPA(캘리포니아 소비자 개인정보 보호법):
		- 수집 목적 공개 및 동의 철회 권한
		- 개인정보 판매 금지 요청 권리
		- 13세 미만 아동 데이터 보호 강화

	- 공통점:
		- 데이터 처리의 투명성, 통제권, 보안을 보장하는 데 초점

- 데이터 마스킹(Data Masking)의 개념과 주요 활용 사례
	- 개념:
		- 실제 데이터를 유사한 형태로 치환하거나 가려서 노출을 제한하는 기법
	- 유형:
		- Static Masking: 정적 테스트용 DB 생성 시 적용
		- Dynamic Masking: 실시간 조회 시 마스킹된 데이터 제공
		- 부분 마스킹: 일부만 노출 (예: 주민번호 뒷자리 *)

	- 활용 사례:
		- 개발/테스트 환경에서의 개인정보 보호
		- 고객센터, 외주 개발자에게 제공되는 DB
		- 보안 점검 및 감사를 위한 데이터 샘플링

- 보안 감사 로그(Audit Log)의 개념과 주요 활용 방안
	- 개념:
		- DB 시스템 내에서 발생한 접근, 변경, 트랜잭션 등 행위 이력을 기록하여 추적 가능하게 하는 로그

	- 활용 방안:
		- 이상 행위 탐지 (비정상 접근, 대량 조회 등)
		- 사용자별 작업 내역 추적
		- 데이터 유출 사고 발생 시 원인 분석
		- 법적 감사 대응 자료 제공

	- Audit Log는 데이터 보안 정책의 핵심 요소로, 무결성과 보존 주기 관리가 중요

- 데이터 무결성을 보장하기 위한 보안 기법
	- 주요 기법:
		- 체크섬 및 해시(Hash Function): 데이터 위·변조 탐지
		- 디지털 서명: 트랜잭션의 무결성과 부인 방지 보장
		- 암호화와 접근 제어: 비인가 변경 방지
		- 무결성 제약 조건(Primary/Foreign Key 등): DB 내부 논리 무결성 확보
		- 이중화 및 복제: 장애 대비와 동기화 상태 점검

	- 무결성 보장은 보안성과 신뢰성의 근간

- 데이터 유출 방지(DLP) 기술을 활용한 데이터 보호 방법
	- DLP(Data Loss Prevention):
		- 내·외부 유출 경로에서의 민감 데이터 감지, 차단, 알림을 제공하는 보안 기술

	- 적용 방법:
		- 네트워크 DLP: 이메일, 웹, FTP 등 경로 감시
		- 엔드포인트 DLP: PC·모바일의 문서 복사/출력 차단
		- Storage DLP: DB, 파일서버에서의 민감 정보 검색 및 마스킹
		- 콘텐츠 인식 정책: 키워드, 정규식, ML 기반 민감정보 식별

	- DLP는 개인정보보호법 준수, 내부자 위협 방어에 핵심 역할

- 데이터 거버넌스와 데이터 보안 정책의 관계
	- 데이터 거버넌스(Data Governance):
		- 조직 내 데이터의 품질, 보안, 활용, 책임 등을 체계적으로 관리하는 프레임워크

	- 데이터 보안 정책과의 관계:
		- 거버넌스는 보안 정책의 방향성과 체계 수립을 포함
		- 데이터 분류, 접근 통제, 암호화 정책 등 보안 요소와 연계
		- 역할 기반 보안, DLP, 감사 등 보안 실행 전략을 포괄

	- 즉, 거버넌스는 데이터 보안을 포함한 통합적 관리 체계의 상위 개념

- 클라우드 데이터베이스의 개념과 주요 클라우드 서비스 비교
	- 개념:
		- 클라우드 환경에서 제공되는 완전 관리형 DB 서비스(DBaaS)로, 서버 유지 관리 없이 사용 가능

	- 주요 서비스 비교:
		- AWS RDS: 다양한 엔진 지원(MySQL, PostgreSQL, Oracle 등), 자동 백업, Multi-AZ 복제
		- Google BigQuery: 컬럼 기반 분석용 DB, 고속 쿼리, 무제한 확장
		- Azure Cosmos DB: 글로벌 분산 DB, 다양한 API(Cassandra, MongoDB 등), 자동 인덱싱

	- 선택 기준: 데이터 유형, 분석 목적, 지연 시간, 지역 분산 등

- Serverless Database의 개념과 주요 활용 사례
	- 개념:
		- 서버 관리가 필요 없는 형태의 데이터베이스로, 자동 확장·축소, 과금 자동화, 무중단 관리 기능을 제공하는 완전 관리형 서비스(DBaaS)
	- 특징:
		- 프로비저닝 불필요
		- 초당 과금(Pay-per-use)
		- 무중단 유지보수
		- 이벤트 기반 트리거 활용 가능
	- 활용 사례:
		- 이벤트 기반 웹/모바일 백엔드
		- 스타트업의 MVP 개발
		- IoT 및 센서 기반 실시간 서비스
		- 간헐적 사용량이 있는 애플리케이션

	- 예시: Amazon Aurora Serverless, Google Firebase Realtime DB, PlanetScale 등

- AI 및 머신러닝을 활용한 자동화 데이터베이스 관리 기법
	- 개념:
		- AI/ML 알고리즘을 적용해 DB 운영의 자동화·최적화·예측 분석을 수행하는 기술

	- 주요 적용 영역:
		- 쿼리 성능 분석 및 튜닝 자동화
		- 인덱스 추천 및 재구성
		- 장애 예측 및 리소스 사용량 예측
		- 스케일링 자동 조정 및 워크로드 최적화
		- 자율운영 DB(Autonomous Database) 구현

	- 대표 사례: Oracle Autonomous DB, Azure SQL Intelligent Tuning, AWS DevOps Guru for RDS

- 멀티 클라우드 데이터베이스의 개념과 주요 장단점
	- 개념:
		- 두 개 이상의 클라우드 플랫폼(AWS, GCP, Azure 등)에서 동시에 데이터베이스를 구성·운영하여 고가용성, 유연성, 벤더 종속 방지 등을 실현하는 전략
	- 장점:
		- 장애 대비 (Failover, DR)
		- 규제 대응 및 지역 이중화
		- 비용·성능 최적화를 위한 클라우드 선택 가능
	- 단점:
		- 복잡한 운영 및 관리 체계
		- 동기화 지연, 데이터 정합성 문제
		- 벤더 간 호환성 제한
	- 멀티 클라우드는 탄력성, 비즈니스 연속성 확보를 위한 전략적 선택

- NewSQL 데이터베이스의 개념과 기존 RDBMS 및 NoSQL과의 차이
	- NewSQL:
		- 관계형 모델 기반의 SQL 문법과 ACID 트랜잭션을 지원하면서도 NoSQL 수준의 확장성과 성능을 제공하는 차세대 DBMS
	- 차이점:
		- RDBMS: 전통적 SQL, 수직 확장, 단일 노드 중심
		- NoSQL: 유연한 스키마, 수평 확장, BASE 특성
		- NewSQL: SQL + 수평 확장 + ACID 보장
	- 대표 제품: Google Spanner, CockroachDB, TiDB, VoltDB
	- NewSQL은 트랜잭션 중심의 고성능 분산 시스템에 적합

- Edge Computing에서 데이터베이스의 역할
	- 개념:
		- 데이터 생성 지점 가까이(엣지)에서 저장·처리·분석을 수행하는 컴퓨팅 아키텍처
	- DB 역할:
		- 실시간 데이터 수집 및 처리
		- 센서/디바이스 로컬 저장
		- 네트워크 장애 시에도 독립 작동
		- 중앙 시스템과 동기화 수행
	- 예시: InfluxDB, SQLite, Realm, AWS IoT Greengrass DB
	- Edge DB는 지연 최소화와 독립적 운영을 보장하는 핵심 요소

- 데이터 스트리밍 플랫폼(Kafka, Flink)과 데이터베이스의 관계
	- Kafka:
		- 메시지 브로커로 실시간 이벤트 스트림 전송
		- 데이터베이스에 이벤트 로그 기록 또는 CDC 수행
	- Flink:
		- 고속 스트림 처리 엔진으로 복잡 이벤트 처리 및 분석 수행
		- 처리된 결과를 데이터베이스에 저장
	- 관계:
		- Kafka → 실시간 수집 → Flink → 실시간 분석 → DB 저장 및 연동
		- 스트리밍 파이프라인은 데이터 기반 실시간 의사결정의 핵심 구조

- 양자 데이터베이스(Quantum Database)의 개념과 기존 DB와의 차이
	- 개념:
		- 양자 컴퓨팅의 병렬성과 계산 성능을 활용하여 고차원 데이터의 검색, 조합, 최적화 문제를 처리하는 데이터베이스 개념
	- 차이점:
		- 기존 DB는 선형적 접근 기반
		- 양자 DB는 양자 상태를 활용한 초고속 탐색 가능 (Grover’s 알고리즘 등)
		- 아직은 이론적 또는 실험적 수준
	- 활용 가능성: 암호 해독, 빅데이터 탐색, 최적화 문제 처리

- 데이터베이스와 IoT 데이터 처리 방식의 차이
	- IoT 데이터 처리:
		- 고빈도, 소량, 실시간 데이터 수집
		- 비정형 또는 시계열 데이터 중심
		- 엣지, 게이트웨이, 클라우드 계층으로 구성
		- MQTT, CoAP 등 경량 프로토콜 사용
	- DB 관점 차이:
		- 기존 RDBMS는 트랜잭션 중심 구조
		- IoT는 시계열 DB(TimescaleDB, InfluxDB 등) 또는 NoSQL 기반이 적합
		- 데이터 처리 방식은 중앙 집중형 vs 분산 스트리밍 기반

	- IoT 환경에선 경량성, 실시간성, 확장성 있는 DB 구조가 요구된다.

- IT 및 데이터베이스 관리에서 ESG(Environmental, Social, Governance) 트렌드의 영향
	- ESG 트렌드 영향:
		- Environmental(환경):
			- 데이터센터의 에너지 효율화 요구 증가 (친환경 스토리지, 저전력 서버)
			- 탄소배출 저감 위한 클라우드 전환 가속화
		- Social(사회):
			- 개인정보 보호와 데이터 윤리 요구 강화
			- 데이터 접근성과 공정성 확보 중요성 증가
		- Governance(지배구조):
			- 데이터 사용·보안에 대한 내부통제 강화
			- IT 거버넌스 및 데이터 감사 체계 필요

	- ESG는 데이터 관리에 있어 책임성과 지속가능성 확보를 요구하는 방향으로 진화 중이다.

- DBMS의 주요 기능과 필요성
	- 주요 기능:
		- 데이터 정의: 스키마 정의 및 관리 (DDL)
		- 데이터 조작: 삽입·조회·수정·삭제 기능 (DML)
		- 동시성 제어: 다중 사용자 트랜잭션의 정합성 유지
		- 복구 및 보안: 장애 대응 및 접근 제어 기능
		- 성능 최적화: 쿼리 최적화, 인덱싱, 캐시 등

	- 필요성:
		- DBMS는 데이터의 통합 관리, 일관성 유지, 보안 강화, 무결성 확보를 가능하게 하며, 대규모 데이터 환경에서 필수적이다.

- 데이터베이스 백업과 복구의 주요 방법
	- 백업 방법:
		- 전체 백업: 전체 데이터 복사
		- 증분 백업: 변경된 데이터만 백업
		- 차등 백업: 마지막 전체 백업 이후 변경된 모든 데이터 백업
		- 스냅샷: 시점 기준의 정지 이미지

	- 복구 방법:
		- Redo/Undo 로그 기반 복구
		- Point-in-Time 복구
		- 스토리지 미러링 복구

	- 전략 수립 시 RTO(복구 시간 목표), RPO(복구 시점 목표) 기준이 중요하다.

- 데이터베이스 장애 유형
	- 소프트웨어 장애: DBMS 또는 애플리케이션 오류로 인한 논리적 손상
	- 하드웨어 장애: 디스크, 메모리, CPU 등 물리 장비의 고장
	- 논리적 장애: 잘못된 트랜잭션 실행, 운영 실수, 무결성 위반 등

	- 장애 유형에 따라 복구 방법과 대응 전략이 달라진다.

- 데이터베이스 장애 발생 시 복구 전략
	- 복구 전략:
		- 로그 회복(Log-based Recovery): 트랜잭션 로그 활용해 Undo/Redo 수행
		- 체크포인트(Checkpoint): 일정 시점까지 상태 저장 후 복구 속도 향상
		- 미러링(Mirroring): 실시간 복제본 사용하여 장애 시 전환
		- Replication + Failover: 이중화된 노드 자동 전환 구조

	- 핵심: 무중단 서비스 유지와 데이터 무결성 보장

- 데이터베이스 성능 모니터링 도구
	- 도구 유형 및 활용:
		- DBMS 내장 도구: Oracle AWR/ASH, SQL Server Profiler 등 → 실시간 쿼리 추적, 병목 식별
		- APM(Application Performance Management): New Relic, AppDynamics 등 → DB와 애플리케이션 연계 성능 추적
		- 로그 분석: Slow Query Log, 실행 계획 로그 등 → 쿼리 성능 개선

	- 활용: 병목 구간 파악, 튜닝 대상 식별, 예측 기반 리소스 최적화

- 대용량 데이터 처리를 위한 스토리지 아키텍처의 개념과 차이 (SSD, RAID, NAS, SAN)
	- SSD (Solid State Drive):
		- 반도체 기반 저장장치로 속도, 내구성, 발열 측면에서 HDD 대비 우수
		- 데이터베이스에서 고속 읽기/쓰기 및 낮은 지연시간 확보에 유리

	- RAID (Redundant Array of Independent Disks):
		- 다수의 디스크를 조합하여 성능 향상, 데이터 중복, 장애 복구 기능 제공
		- RAID 0~6까지 다양한 레벨 (성능, 안정성 조합에 따라 선택)

	- NAS (Network Attached Storage):
		- 파일 단위 접근 방식의 스토리지
		- TCP/IP 네트워크를 통해 공유 디스크 제공
		- 파일 기반 DB에는 비적합할 수 있음

	- SAN (Storage Area Network):
		- 블록 단위 접근 방식, 전용 네트워크 사용
		- 고성능 DB, 대용량 트랜잭션 처리에 적합

	- 각 아키텍처는 성능·확장성·복원력 요구에 따라 선택되어야 한다.

- 고가용성(HA) 데이터베이스 아키텍처와 이중화(Failover) 전략
	- 고가용성 아키텍처:
		- 장애 발생 시 즉시 대체 시스템으로 전환 가능한 구조
		- 클러스터링, 복제, 로드 밸런싱, 재해 복구 설계 포함

	- 이중화 전략:
		- Active-Passive: 주노드 장애 시 대기노드 전환
		- Active-Active: 양 노드 동시에 처리, 부하 분산
		- Failover: 자동 전환 시스템, RTO 최소화
		- Replication + Backup: 물리/논리 복제 기반의 백업 노드 운용

	- 고가용성은 서비스 중단 방지와 비즈니스 연속성을 위한 핵심 요건

- 데이터베이스 배포(Database Deployment) 방식과 주요 고려 사항
	- 배포 방식:
		- 단일 노드 배포: 소규모, 개발·테스트용
		- 클러스터 배포: 고가용성 및 부하 분산
		- 컨테이너 기반 배포(Kubernetes): 자동 확장 및 무중단 배포 가능
		- 멀티 클라우드/하이브리드 배포: 탄력성과 재해복구 강화

	- 고려 사항:
		- 데이터 정합성, 보안 정책, 성능 테스트
		- 배포 자동화(CI/CD 파이프라인)
		- 롤백 전략 및 장애 복구 시나리오 마련

- 온프레미스(On-Premise)와 클라우드 데이터베이스의 차이
	- 온프레미스:
		- 자체 서버와 인프라 관리
		- 보안성과 통제력 높지만 비용과 유지보수 부담 큼

	- 클라우드 DB:
		- 클라우드 제공자가 관리하는 완전 관리형 DB
		- 확장성, 탄력성, 자동화된 유지보수 장점
		- 벤더 종속성과 규제 이슈 고려 필요

	- 선택 기준: 규제 환경, 성능 요구, 예산, 유연성

- 데이터베이스 유지보수 시 고려 사항
	- 유지보수 항목:
		- 인덱스 재구성 및 통계 갱신
		- 백업 및 복구 전략 점검
		- DB 패치 및 보안 업데이트
		- 로그 정리, 테이블 정규화/반정규화 재검토
		- 장애 발생 이력 분석 및 사후 조치

	- 주기적 유지보수는 성능과 보안, 가용성 유지의 핵심 요소

- 데이터 표준화의 개념과 주요 원칙
	- 개념:
		- 데이터 속성명, 형식, 단위, 코드값 등에 대한 기준을 정하여 전사적 일관성을 확보하는 활동

	- 주요 원칙:
		- 동일 개념에는 동일 명칭 사용
		- 데이터 정의의 명확성 확보
		- 형식과 단위의 통일
		- 관리 체계와 변경 통제 절차 수립

	- 표준화는 데이터 품질 향상과 시스템 간 연계 효율성 향상에 핵심적

- 메타데이터의 개념과 주요 유형
	- 개념:
		- 데이터를 설명하는 데이터로, 데이터의 구조, 의미, 출처, 품질 등을 정의하는 정보

	- 주요 유형:
		- 구조적 메타데이터: 테이블, 컬럼, 데이터 타입 등 스키마 정보
		- 기술적 메타데이터: 저장 위치, 포맷, 접근 방법 등 시스템 속성
		- 비즈니스 메타데이터: 업무 정의, 책임자, 데이터 사용 목적 등

	- 메타데이터는 데이터 거버넌스와 카탈로그 시스템의 핵심 자원

1. 데이터 품질(Data Quality)의 개념과 주요 평가 지표

개념:
데이터 품질은 데이터가 정확하고 일관되며, 적시에 필요한 형태로 제공될 수 있는 상태를 의미한다.

주요 평가 지표:
	- 정확성(Accuracy): 실제 값과 일치하는 정도
	- 일관성(Consistency): 여러 시스템 간의 데이터 불일치 여부
	- 무결성(Integrity): 참조 및 제약 조건의 위배 여부
	- 적시성(Timeliness): 최신성 및 사용 시점의 유효성
	- 완전성(Completeness): 필수 값의 누락 여부
	- 유효성(Validity): 정의된 형식, 규칙, 도메인에 부합하는지 여부

데이터 품질은 업무 의사결정의 정확성과 신뢰성 확보에 핵심적

⸻

2. 데이터 일관성과 무결성을 유지하는 주요 방법

일관성 유지 방법:
	- 트랜잭션 격리 수준 설정 (ACID의 C)
	- 정규화된 데이터 모델 사용
	- 동기화 시스템, CDC(Change Data Capture) 활용
	- 마스터-슬레이브 구조에서 동기 복제 설정

무결성 유지 방법:
	- 기본키/외래키 제약조건 설정
	- Check 제약 및 Unique 제약 사용
	- 트리거 및 저장 프로시저로 비즈니스 룰 강제
	- 백엔드 시스템에서 유효성 검사 로직 구현

핵심: 논리적 제약과 시스템 제어의 병행 적용

⸻

3. 데이터 프로파일링(Data Profiling)의 개념과 주요 기법

개념:
데이터셋에 대해 통계적 특성이나 패턴을 분석하여 품질과 구조를 이해하고 문제를 사전 파악하는 기법

주요 기법:
	- 컬럼 분석: Null 비율, 평균, 최소/최대값
	- 패턴 분석: 데이터 형식, 정규식 기반 검출
	- 범위 분석: 도메인 범위 벗어남 여부
	- 유일성 분석: 키 후보 확인
	- 데이터 분포 분석: 이상치, 편향 파악

프로파일링은 정제 및 통합 이전 단계에서 선제적 진단 도구로 활용됨

⸻

4. 데이터 검증 및 정제 기법

데이터 검증(Validation):
	- 형식 검사(정규식, 날짜 형식 등)
	- 범위 검사(도메인 값, 숫자 범위)
	- 참조 무결성 검사(외래키 체크 등)

데이터 정제(Cleansing):
	- 오류값 수정 또는 제거
	- 중복 제거(Deduplication)
	- 표준화된 단위·형식 적용
	- Null 처리 및 기본값 보완
	- 이상치 처리 및 추정치 보간

검증과 정제는 데이터 신뢰성 확보 및 분석 정확성의 필수 과정

⸻

5. 마스터 데이터 관리(MDM)의 개념과 주요 기법

개념:
기업 내 분산된 핵심 엔터티(고객, 상품, 조직 등)의 정보를 일관되고 정확하게 통합·관리하는 활동

주요 기법:
	- 중앙 집중형 관리(Hub 방식): 단일 MDM 저장소 운영
	- 레지스트리 방식: 분산 저장, 링크 중심 통합
	- 동기화 및 매핑 룰 관리
	- 데이터 통합 및 정합성 검증 정책 수립

MDM은 전사 시스템 간 데이터 일관성과 정확성을 확보하기 위한 핵심 거버넌스 도구

⸻

6. 데이터베이스 변경 관리(Change Management)의 개념과 프로세스

개념:
DB 구조, 데이터, 권한 등 변경 시 시스템 안정성, 일관성, 이력 관리를 보장하는 절차

프로세스:
	1.	변경 요청 수집 (요구사항 정의)
	2.	영향도 분석 (의존성, 성능 영향 등)
	3.	변경 계획 수립 (백업, 롤백 계획 포함)
	4.	테스트 환경에서 사전 검증
	5.	운영 환경 반영 (무중단 적용 시 롤링 방식)
	6.	변경 이력 및 승인 기록 관리

변경 관리는 운영 안정성과 품질 보장을 위한 DevOps 핵심 활동 중 하나

1. 데이터 감사(Data Audit)와 데이터 거버넌스(Data Governance)의 관계

데이터 감사:
시스템 내 데이터 생성, 변경, 접근, 삭제 등의 행위 기록을 추적·분석하여 보안 및 책임성을 확보하는 활동

데이터 거버넌스와의 관계:
	- 데이터 거버넌스는 정책, 기준, 책임, 품질 관리의 전체 체계
	- 데이터 감사는 정책이 실제로 잘 이행되는지를 검증하는 도구
	- 거버넌스의 투명성과 신뢰성 확보 수단으로 감사가 필수

감사 로그는 내부통제, 규제 대응, 사고 원인 분석의 핵심 자료로 활용된다.

2. 데이터 웨어하우스에서 데이터 품질을 보장하기 위한 주요 전략

전략:
	- ETL 단계의 정제 및 오류 검증 강화
	- 메타데이터 기반 품질 모니터링 체계 구축
	- 데이터 소스 간 일관성 검증 규칙 마련
	- 품질 대시보드 구축 및 지표(정확성, 완전성 등) 시각화
	- 품질 기준 위반 시 경고 및 자동 알림 시스템 적용

DW의 품질 확보는 분석의 정확도와 신뢰성 확보에 직결된다.

3. 데이터베이스와 AI/머신러닝 연계 기술의 개념과 주요 활용 사례

개념:
데이터베이스에 AI/ML 알고리즘을 통합하거나, 학습 데이터를 관리하는 역할을 수행함으로써 지능형 데이터 처리 및 자동화 지원

활용 사례:
	- AutoML 학습용 데이터 관리
	- 예측 기반 쿼리 튜닝 (AI 기반 실행계획 개선)
	- AI 기반 이상 탐지 및 자동 복구
	- AI 추천 시스템을 위한 실시간 데이터 공급

DB와 AI 연계는 데이터 사이언스, 자율운영, 실시간 인사이트 제공의 핵심 축

4. 데이터베이스 자동 튜닝(Auto-Tuning)의 개념과 주요 알고리즘

개념:
DB 시스템이 사용자의 개입 없이도 성능 최적화를 스스로 수행하는 기술

주요 알고리즘 및 기법:
	- 강화학습 기반 튜닝: 보상을 기반으로 인덱스/쿼리 최적화
	- 인공지능 기반 인덱스 자동 생성/삭제
	- Cost-based Optimizer 개선
	- 통계 기반 실행 계획 추천 및 변경

대표 사례: Oracle Autonomous DB, Azure SQL Intelligent Tuning

자동 튜닝은 운영 자동화와 성능 최적화의 미래형 방향성

⸻

5. 데이터 스트리밍과 실시간 데이터 처리 기술의 개념

개념:
데이터가 생성되자마자 중단 없이 지속적으로 처리되는 방식으로, 배치 처리와 대조되는 흐름 기반 처리

기술 요소:
	- Kafka: 메시지 브로커
	- Flink / Spark Streaming: 실시간 연산 처리 엔진
	- CDC(Change Data Capture): DB 변경사항 실시간 감지 및 반영
	- CEP(Complex Event Processing): 다중 이벤트 흐름 분석

실시간 처리 기술은 IoT, 금융, 제조, 물류 등 빠른 의사결정이 필요한 분야에서 필수

⸻

6. 데이터베이스에서 In-Memory Computing의 개념과 주요 활용 사례

개념:
데이터를 디스크가 아닌 메모리에 저장하여 초고속 처리 성능을 제공하는 컴퓨팅 방식

활용 사례:
	- SAP HANA: 모든 데이터를 메모리에 올려 OLTP/OLAP 통합 처리
	- Redis/Memcached: 캐시 기반 In-Memory Key-Value Store
	- 실시간 금융 트랜잭션 처리, 게임 서버 세션 유지, AI 피드백 저장소

In-Memory DB는 지연 최소화와 분석 성능 향상이 요구되는 시스템에 최적화되어 있다.

1. Digital Twin과 데이터베이스의 연관성

Digital Twin 개념:
현실 세계의 사물, 공정, 시스템 등을 가상공간에 실시간으로 모사하여 상태 모니터링, 예측 분석, 최적화 등을 수행하는 기술

데이터베이스와의 연관성:
	- 센서, IoT 장비 등에서 발생하는 시계열 데이터 저장
	- 물리 세계와 가상 객체 간 상태 동기화 및 이벤트 기록 관리
	- 실시간 분석, AI 예측을 위한 정형·비정형 데이터 통합 저장소 역할
	- 시뮬레이션 이력, 진단 결과, 경고 로그 등을 효율적으로 저장·조회

Digital Twin은 DB의 고성능, 실시간성, 확장성 요구를 수반하며, 클라우드 기반 또는 In-Memory DB와 자주 연계된다.

2. 클라우드 네이티브 데이터베이스(Cloud-Native Database)의 개념과 주요 특징

개념:
컨테이너, 오케스트레이션, 마이크로서비스 기반 환경에 최적화된 클라우드 환경 전용 설계의 DBMS

주요 특징:
	- 탄력적 확장성과 자동 복구 기능 내장
	- Kubernetes 기반 오케스트레이션에 최적화
	- 스토리지와 컴퓨팅 분리 구조
	- 인프라 불투명성에도 높은 가용성 보장
	- DevOps 및 CI/CD 환경과 연동 용이

예: CockroachDB, YugabyteDB, Amazon Aurora, Vitess

⸻

3. 데이터베이스 가상화(Database Virtualization)의 개념과 활용 방안

개념:
물리적 DB 인프라와 무관하게 논리적 데이터 뷰를 제공함으로써 다양한 사용자/시스템에 맞는 가상 DB 환경을 생성하는 기술

활용 방안:
	- 개발·테스트 환경의 데이터 복제 없이 가상 DB 제공
	- 다중 부서 또는 파트너사 간 데이터 공유 시 보안 강화
	- 데이터 통합 환경에서 이기종 DB에 대한 통합 뷰 제공
	- 비용 절감 및 운영 유연성 확보

대표 솔루션: Delphix, Redgate Clone, IBM Cloud Pak for Data

⸻

4. 데이터 프라이버시 보호 기술 (Differential Privacy, SMPC)

Differential Privacy:
개별 데이터가 결과에 영향을 거의 미치지 않도록 수학적으로 보장하는 기술.
	- 통계 분석 시 노이즈 추가를 통한 프라이버시 보호
	- 대표 사례: Apple, Google의 사용자 데이터 보호

Secure Multi-Party Computation(SMPC):
여러 참여자가 자신의 데이터를 공개하지 않고도 연산 결과를 공동 계산하는 암호 기술
	- 민감 정보가 외부에 유출되지 않고도 협업 가능
	- 활용 예: 금융 간 정보 분석, 의료 데이터 공동 연구

두 기술은 AI 및 데이터 분석 시대의 개인정보 보호 핵심 수단

⸻

5. 양자 컴퓨팅이 데이터베이스에 미치는 영향과 대응 방안

영향:
	- 양자 알고리즘은 기존 암호화 기법(RSA, ECC 등)을 무력화할 수 있음
	- Grover 알고리즘 등으로 인해 검색, 최적화 연산의 속도 향상 기대
	- 데이터 저장 및 질의 처리 방식의 근본적 변화 가능

대응 방안:
	- Post-Quantum Cryptography(PQC): 양자 내성 암호 기술 도입
	- 하이브리드 암호체계 운영으로 이행 준비
	- 장기 보존 데이터를 위한 양자 안전성 검토

양자 컴퓨팅은 보안성과 계산 모델을 모두 재정립해야 하는 패러다임 변화 요소

⸻

6. 데이터베이스 관리에서 IT 거버넌스와 보안 규제 준수의 중요성

IT 거버넌스의 역할:
	- 데이터 자산에 대한 역할과 책임, 통제 기준 정립
	- DB 변경, 접근, 감사, 품질에 대한 정책·표준화·모니터링 체계 수립

보안 규제 준수 필요성:
	- 개인정보보호법, GDPR, PCI-DSS, SOX 등 국제·국내 기준 대응
	- 위반 시 법적 책임, 신뢰도 하락, 금전적 손실 발생
	- 시스템 로그, 감사이력, 암호화, 권한관리 체계 필수

IT 거버넌스와 규제 준수는 책임 있는 데이터 활용과 리스크 최소화의 핵심 축

1. 개인정보 보호법(GDPR, CCPA)의 데이터 저장 및 처리 요구 사항

GDPR(General Data Protection Regulation):
	- 목적 제한: 수집한 목적 외 사용 금지
	- 최소 수집: 필요한 정보만 수집
	- 투명성: 처리 목적, 저장 위치, 제3자 제공 여부 공개
	- 데이터 주체 권리 보장: 열람·정정·삭제(잊힐 권리), 이동 권리
	- 보안 조치: 암호화, 접근 제어, 침해 시 72시간 내 통지

CCPA(California Consumer Privacy Act):
	- 판매 거부 권리 제공
	- 개인정보 범주 및 사용 목적 사전 고지
	- 14세 미만 아동의 사전 동의 의무화
	- 삭제 요청 시 즉시 대응 요구

두 법 모두 데이터 주체 중심의 정보통제권 강화가 핵심이다.


2. 데이터 주권(Data Sovereignty)의 개념과 클라우드 환경에서의 영향력

개념:
데이터는 생성된 국가의 법과 규제의 지배를 받으며, 국가 주권이 해당 데이터에 미친다는 원칙

클라우드 환경 영향:
	- 데이터가 해외 서버에 저장될 경우 관할권 충돌, 규제 회피 우려 발생
	- 특정 국가(예: 유럽)는 자국 내 저장을 요구함 → 데이터 지역성(Region) 고려 필요
	- 글로벌 기업은 멀티 리전, 로컬 스토리지, 암호화 기반 통제 체계 마련 필요

데이터 주권은 법적 책임과 데이터 활용 전략을 좌우하는 핵심 요소

⸻

3. 데이터 보존 정책(Data Retention Policy)의 개념과 주요 고려 사항

개념:
데이터를 얼마 동안, 어떤 방식으로 저장·보관할지 명시한 조직의 정책

주요 고려 사항:
	- 법적 요구사항 준수: 세법, 금융 규제에 따른 최소 보관 기간
	- 업무 목적: 통계 분석, 고객 관리 등의 필요성
	- 보안 및 폐기 정책: 보존 기한 만료 시 안전한 삭제 또는 파기
	- 비용 고려: 스토리지 비용과 관리 비용 간의 균형 유지

보존 정책은 책임 있는 데이터 운영과 리스크 최소화에 필수

⸻

4. 전자문서 및 전자거래법에서 데이터베이스 관련 규제

전자문서법:
	- 전자 문서도 종이문서와 동일한 법적 효력 인정
	- 무결성 보장, 위변조 방지 기술 적용 필요 (디지털 서명, 해시 등)

전자거래법:
	- 거래 기록의 신뢰성과 추적성 확보 의무
	- 일정 기간 거래 내역 보관 의무(5년 등)
	- 소비자 정보 보호와 결제 보안 요건 강화

DB 관리자는 해당 법령에 따라 기록 보관, 접근통제, 감사 로그 체계를 갖춰야 한다.

⸻

5. 금융 보안 규제(PCI-DSS, SOX 등)의 개념과 DB 운영 시 고려 사항

PCI-DSS(Payment Card Industry Data Security Standard):
	- 신용카드 데이터 보호를 위한 글로벌 보안 표준
	- 암호화, 접근 제한, 감사 로그, 취약점 관리 의무화
	- DB에서는 PAN(Primary Account Number) 마스킹, 키 관리 시스템 적용 필요

SOX(Sarbanes-Oxley Act):
	- 미국 상장 기업 대상 재무 보고 투명성 확보 목적
	- 재무 관련 데이터의 변경 이력, 접근 기록 보관 필수
	- 감사 및 통제 문서화 필수

금융 분야 DB는 법적 책임 회피 및 고객 정보 보호를 위한 고도 보안 관리가 필수

⸻

6. 데이터 감사(Data Auditing)의 개념과 주요 법적 요구 사항

개념:
DB 내 데이터의 접근, 수정, 삭제 등의 이력을 기록·분석하여 위법, 이상 행위를 탐지·추적하는 활동

주요 법적 요구 사항:
	- GDPR/CCPA: 정보 접근 주체와 목적의 기록 필요
	- 전자금융거래법: 금융거래 기록 5년 이상 보관
	- 정보보호 관리체계(ISMS, ISO 27001): 감사 로그 생성 및 보호 항목 포함
	- 내부통제 기준: 변경 이력, 권한 변경 기록 필수

감사는 사고 대응, 법적 소명, 내부통제의 핵심 요소로 법률과 기술을 동시에 반영해야 한다.


1. 국가 간 데이터 이전(Cross-Border Data Transfer)의 보안 및 법적 문제

보안 문제:
	- 데이터가 해외 서버로 이동되면서 암호화되지 않거나, 전송 중 탈취 위험 증가
	- 데이터 처리국의 보안 수준이 원국보다 낮을 경우 민감정보 유출 가능성

법적 문제:
	- GDPR, CCPA 등 개인정보 보호법 충돌
	- 데이터 주권 문제로 인해 일부 국가는 자국 내 저장 의무 부과
	- 표준 계약 조항(SCC), 적정성 평가 없이 이전 시 위법 가능성

해결 방안:
	- 데이터 암호화 및 익명화
	- 데이터 지역화(Geo-fencing)
	- 법적 이행 동의 확보 및 계약 조항 마련

⸻

2. IT 및 보안 산업에서 ESG 트렌드가 데이터 관리에 미치는 영향

환경(E):
	- 탄소 발자국을 줄이기 위한 그린 데이터센터 운영, 에너지 효율적 DB 인프라 채택
	- 스토리지 최적화, 클라우드 전환을 통한 자원 절약

사회(S):
	- 개인정보 보호 강화, 데이터 윤리 준수 요구 증대
	- 고객 신뢰 기반 데이터 정책 수립

지배구조(G):
	- 데이터 거버넌스를 통한 책임성, 투명성 확보
	- 내부통제, 감사 로그, 권한 관리 강화

⸻

3. 전자서명 및 블록체인 기반 인증의 개념과 활용

전자서명:
	- 문서의 무결성과 당사자 인증을 위해 암호화 기반 디지털 서명 사용

블록체인 기반 인증:
	- 변조 불가한 트랜잭션 기록을 통해 신원, 문서, 행위의 진위 검증
	- 분산 신뢰 구조, 중앙기관 없이도 인증 가능

활용:
	- 계약서 저장 및 서명
	- 의료정보 및 공공 기록 인증
	- 블록체인 기반 DID(Decentralized ID) 시스템

⸻

4. 데이터 거버넌스 정책 수립 시 법적·윤리적 고려사항

법적 고려사항:
	- GDPR, 정보보호법, 산업별 보안 규제 준수
	- 데이터 보관 기간, 제3자 제공, 정보 주체 권리 보장 포함

윤리적 고려사항:
	- 데이터 편향 방지, 알고리즘 책임성 확보
	- 고객 동의 없는 과도한 데이터 활용 금지
	- 민감정보 및 개인 정보 비식별화 조치

거버넌스는 단순 규제 준수 외에 조직의 신뢰와 사회적 책임 이행의 근간

⸻

5. 데이터베이스와 IoT 데이터 관리의 차이

DB 데이터 관리:
	- 정형 데이터 중심, 스키마 기반
	- 안정적 트랜잭션 처리에 최적화 (ACID)

IoT 데이터 관리:
	- 비정형, 시계열 중심, 실시간 대량 데이터
	- 이벤트 기반 처리, NoSQL 및 시계열 DB 활용
	- 고속 수집, 처리, 저장 요구 (MQTT, Edge DB 등)

IoT 환경은 실시간성과 분산성을 중심으로 최적화된 DB 구조 필요

⸻

6. AI 기반 예측 분석(Predictive Analytics)의 개념과 DB 활용 사례

개념:
기존 데이터를 학습해 미래 결과를 예측하는 분석 기법
→ 머신러닝/딥러닝 기반 예측 모델 활용

DB 활용 사례:
	- 고객 이탈 예측, 추천 시스템
	- 제조 장비 고장 예지
	- 금융 이상 거래 탐지
	- 물류 수요 예측

DB는 모델 학습을 위한 데이터 저장소이자 예측 결과 저장·활용의 중심

⸻

7. 데이터베이스와 메타버스 기술의 연계 방안

연계 요소:
	- 3D 객체 정보, 사용자 아바타, 자산 정보 등 대규모 데이터 저장
	- 실시간 상호작용 및 상태 동기화를 위한 In-Memory, 분산 DB, NoSQL 활용
	- 이벤트, 거래, 위치 기반 정보 처리
	- 블록체인 기반 메타버스 자산 관리 가능

메타버스는 초실시간, 고대역폭, 대규모 동시 사용자 처리에 적합한 DB 아키텍처 요구

1. 강화 학습(Reinforcement Learning)을 활용한 DB 성능 최적화 방안

개념:
강화 학습은 행위(쿼리, 튜닝 등)에 대한 보상 신호를 기반으로 최적의 정책을 학습하는 AI 기술로, DB 튜닝에 자율성을 부여함.

활용 방안:
	- 인덱스 생성 및 삭제 전략 자동 결정
	- 실행 계획 선택 최적화
	- 쿼리 리라이트(Query Rewrite) 자동화
	- 워크로드 변화에 따른 동적 캐시 조절 및 파라미터 설정

강화 학습 기반 DB 튜닝은 복잡한 연산 환경에서 반복적 최적화를 가능하게 함.

⸻

2. 블록체인과 데이터베이스의 차이 및 보안 강화 방안

차이점:
	- DBMS: CRUD 기반, 중앙 집중형, 빠른 성능, ACID 보장
	- 블록체인: 추가 전용(Append-only), 탈중앙형, 불변성, 보안성 우위

보안 강화 방안:
	- 블록체인 연계로 이력 추적, 위변조 방지 강화
	- 하이브리드 구조: 핵심 데이터는 DB, 감사 이력은 블록체인 기록
	- DID(분산 신원)와 연동한 접근 통제 강화

⸻

3. 자율 운영 시스템(Autonomous Database)의 개념과 주요 기술

개념:
AI 및 머신러닝 기술을 활용해 인간 개입 없이 스스로 설치, 최적화, 보안, 복구 등을 수행하는 DB 시스템

주요 기술:
	- 자동 스케일링 및 리소스 최적화
	- 자동 백업 및 장애 복구
	- 실시간 성능 분석 및 튜닝
	- 보안 취약점 자동 패치

대표 사례: Oracle Autonomous DB, Snowflake, Microsoft Azure SQL Autopilot

⸻

4. AR/VR 애플리케이션에서 데이터베이스의 역할

역할:
	- 3D 객체 및 위치 정보 관리
	- 사용자 프로필, 동작 로그 등 세션 기반 데이터 처리
	- 실시간 상호작용 데이터를 위한 저지연 DB 처리 요구
	- 인메모리 DB 및 분산 DB 활용 필수

AR/VR은 고속 렌더링을 위한 실시간 데이터 접근이 관건이며, 시계열 및 공간 데이터 관리가 중요하다.

⸻

5. 데이터베이스와 분산 원장 기술(DLT)의 차이

DLT(Distributed Ledger Technology):
	- 복수의 노드에 동기화된 장부를 유지
	- 블록체인도 DLT의 한 유형
	- 변조 불가, 탈중앙성, 합의 알고리즘 필요

DB와의 차이점:
	- DB는 중앙 집중 구조 / DLT는 탈중앙
	- DB는 실시간 수정 가능 / DLT는 Append-only
	- DLT는 신뢰 없는 환경에서 유리

연계 활용:
DLT로 감사 추적, 투명성 강화, DB는 빠른 CRUD 처리를 맡는 하이브리드 모델 가능

⸻

6. 디지털 ID(Digital Identity) 시스템에서 DB의 역할

역할:
	- 사용자 계정, 생체 정보, 인증 이력 등 디지털 신원정보 저장
	- OAuth, SSO, MFA 기반 인증 과정의 기록 관리
	- DID(Decentralized ID)와 연계된 블록체인 데이터 관리
	- 개인정보 보호와 인증 정확성을 동시에 만족하는 보안 설계 필수

DB는 디지털 신원의 신뢰성, 지속성, 감사 가능성 확보를 위한 핵심 인프라

1. 엣지 컴퓨팅(Edge Computing) 환경에서 데이터베이스 활용 방안

활용 방안:
	- 현장에서 수집된 데이터를 현지에서 실시간으로 처리 및 저장
	- 네트워크 지연 없이 즉각적인 분석·제어 가능 (예: 스마트팩토리, 자율주행 등)
	- 오프라인 환경에서도 작동 가능한 경량형 DB 탑재 (SQLite, InfluxDB, TimescaleDB 등)
	- 필요 시 클라우드와 연동하여 동기화 및 백업 수행

엣지 DB는 속도, 분산성, 자원 효율성이 중요한 환경에서 최적의 선택이다.

⸻

2. 데이터베이스 자동화(Database Automation)의 개념과 미래 전망

개념:
데이터베이스의 관리, 유지보수, 보안, 튜닝 등을 스크립트 또는 AI 기반으로 자동화하는 기술

적용 분야:
	- 자동 백업 및 복구
	- 인덱스 관리 및 쿼리 최적화
	- 사용자 권한 관리
	- 보안 패치 적용 자동화

미래 전망:
	- 자율 운영 DB로 진화 (Autonomous DB)
	- AI와 연계된 지능형 자동화
	- DevOps 및 MLOps 환경에 완전 통합

자동화는 DBA의 단순 작업을 줄이고 전략적 의사결정에 집중할 수 있게 함

⸻

3. AI가 데이터베이스 관리자(DBA)의 역할에 미치는 영향

변화 요인:
	- AI 기반 자동 튜닝, 문제 감지, 자율 운영 기능의 확대
	- 정형화된 유지보수 작업 감소
	- DBA는 운영자 → 데이터 전략가로 진화

새로운 역할:
	- AI가 제안한 설정에 대한 검토 및 승인
	- 데이터 아키텍처 설계, 보안 정책 수립
	- 데이터 거버넌스, 품질 관리, 규제 대응 전문가 역할 확대

AI는 DBA를 없애는 것이 아니라 고도화된 방향으로 변화시킴

⸻

4. 데이터베이스의 지속 가능한 성장(Sustainable Database)의 개념과 필요성

개념:
에너지 효율성과 자원 최적화를 고려하여 장기적으로 안정적이고 환경친화적인 DB 시스템을 구축·운영하는 것

필요성:
	- 데이터 폭증에 따른 저장소, 전력, 비용 증가 문제 대응
	- ESG 경영 실현을 위한 IT 인프라 친환경 전환
	- 지속적인 DB 성능 확보와 비용 효율적인 구조 설계

실천 방안:
	- 스토리지 압축, 데이터 정제, 불필요한 데이터 제거
	- 탄소 효율 고려한 클라우드 인프라 활용
	- 서버리스, In-Memory 구조의 최적 활용

⸻

5. 데이터베이스 환경에서 자율 운영 시스템의 발전 방향

진화 단계:
	1.	자동화(Auto-Tuning, Auto-Backup)
	2.	자율 운영(Autonomous DB): AI 기반 예측과 판단
	3.	AI-First Database: 지속 학습 기반 완전 무인 운영

기술 기반:
	- 강화학습 기반 리소스 조정
	- 실시간 모니터링 및 이상 감지
	- 클라우드 네이티브 아키텍처 연계

자율 시스템은 운영 효율화, 장애 대응 속도, 비용 절감 측면에서 필연적이다.

⸻

6. 데이터베이스와 스마트 시티(Smart City)의 연관성

스마트 시티 특성:
	- 교통, 환경, 에너지, 공공안전 등 다양한 도메인의 실시간 데이터 통합 관리

DB 연계:
	- IoT 센서, CCTV, 교통 데이터 등 다양한 소스 저장 및 분석
	- 시계열 DB, NoSQL, 분산 DB 구조 필요
	- 실시간 분석 기반으로 AI 예측, 대시보드 시각화, 자동 제어 수행

DB는 스마트 시티의 정보 흐름의 허브이자 인공지능의 지식 창고 역할을 수행한다.

1. 미래의 데이터 보안 위협(Next-Generation Cyber Threats)과 DB 보호 전략

위협:
	- AI 기반 자동화 공격, 데이터 포이즈닝(Data Poisoning)
	- 양자 컴퓨팅으로 인한 기존 암호 체계 무력화
	- 랜섬웨어의 정교화 및 데이터 탈취 후 협박 방식 변화
	- 클라우드·멀티테넌트 환경의 보안 경계 모호화

DB 보호 전략:
	- Post-Quantum Cryptography 도입 준비
	- Zero Trust 아키텍처 적용
	- 데이터 암호화, 마스킹, 접근 통제 강화
	- 이상행위 탐지를 위한 AI 기반 보안 솔루션 연동

⸻

2. 데이터 중심 의사결정(Data-Driven Decision Making)을 위한 DB의 역할

역할:
	- 실시간 데이터 수집·정제·통합을 통해 의사결정의 기반 데이터 제공
	- 대시보드 및 BI 도구와 연계해 시각화된 인사이트 제공
	- 예측 분석 및 시뮬레이션 기반 전략적 판단 지원
	- 머신러닝 연계로 자동 의사결정 시스템 구축 가능

DB는 데이터 신뢰성, 적시성, 분석 가능성을 통해 기업 경쟁력의 중심이 된다.

⸻

3. 양자 컴퓨팅 환경에서 DB 기술의 변화와 대응 방안

변화:
	- Grover 알고리즘 등으로 인해 검색 및 최적화 연산 속도 향상
	- 기존 DB 암호화 기법(RSA, ECC 등)의 보안 위협 증가

대응 방안:
	- Post-Quantum 암호 알고리즘 적용 (NIST 표준화 진행 중)
	- 양자 난수 생성기(QRNG)를 이용한 키 보안 강화
	- 양자 네트워크 기반 DB 동기화, 보안 통신 구현

양자 환경은 DB의 보안·연산 방식 모두를 재설계하게 만들 미래 기술 전환점이다.

⸻

4. 데이터베이스와 인간 중심 AI(Human-Centered AI)의 관계

Human-Centered AI:
	- 사용자 경험, 윤리, 투명성을 중심으로 한 AI 설계 철학

DB 연계:
	- 학습 데이터의 편향 방지, 다양성 확보, 책임성 있는 수집이 필수
	- 설명 가능한 AI(XAI) 구현을 위한 정형·비정형 데이터 추적 가능
	- 개인정보 보호와 데이터 프라이버시 기술(Differential Privacy, SMPC) 연계

DB는 인간 중심 AI의 윤리적 데이터 기반 구축과 운영의 핵심 축

⸻

5. 향후 10년간 DB 기술의 발전 전망

주요 트렌드:
	- Autonomous DB 확산: 무인 운영, AI 기반 최적화
	- 멀티 모델 DB: Graph, Time-Series, Document 통합형 구조
	- Serverless & Edge DB: 분산·경량화 방향으로 진화
	- Post-Quantum DB 보안 체계 표준화
	- 데이터 중심 인프라로의 전환 (Data Mesh, Data Fabric)

향후 DB는 지능화, 자동화, 분산화, 안전성 중심으로 진화하며 모든 산업의 근간이 될 것이다.

⸻

6. 빅데이터 분석에서 DB의 역할과 활용 방안

역할:
	- 다양한 소스에서 발생하는 정형·비정형 데이터를 수집·저장·분석하는 허브 역할
	- Hadoop, Spark, NoSQL 등과 연계해 대규모 병렬처리 기반 분석 지원
	- 실시간 스트리밍 분석을 위한 Kafka + DB 통합 환경 구성
	- AI/ML 분석을 위한 모델 학습용 데이터셋 저장 및 피드백 루프 구축

활용 방안은 예측 마케팅, 수요 예측, 위험 탐지, 고객 행동 분석 등 전 산업에 걸쳐 광범위

1. 스마트 팩토리(Smart Factory)에서 데이터베이스의 역할과 활용 사례

역할:
	- 설비·센서·로봇 등에서 수집되는 실시간 데이터 저장
	- 설비 가동률, 불량률, 생산 일정 등을 분석해 생산 최적화
	- AI 기반 예지보전(Predictive Maintenance)을 위한 기반 데이터 제공
	- MES, SCADA, ERP 시스템과 연동되어 통합 제조 정보 흐름을 관리

활용 사례:
	- 생산 실적 및 품질 이력 관리
	- 자동화 설비의 로그 기록 및 오류 추적
	- 에너지 소비량 분석을 통한 탄소 절감

⸻

2. 금융 산업에서 데이터베이스 활용 사례와 주요 고려 사항

활용 사례:
	- 계좌, 거래 내역, 신용정보 등 정형 데이터의 대량 처리
	- 리스크 분석, 신용 평가, 이상 거래 탐지 등 고속 분석
	- 금융 상품 추천, 자동화 투자 시스템 등 AI 기반 서비스 지원

고려 사항:
	- 고가용성, 실시간성, 무결성 확보 필수
	- 금융 보안 규제(PCI-DSS, ISMS 등) 준수
	- 이중화, 감사 로그, 접근 통제 강화 필요

⸻

3. 헬스케어 산업에서 데이터베이스 활용 사례와 보안 요구 사항

활용 사례:
	- 전자 건강기록(EHR), 진단 정보, 처방 이력 등 저장
	- 의료 AI 진단 모델의 학습 데이터로 활용
	- 웨어러블 디바이스와 연계된 실시간 건강 모니터링

보안 요구:
	- HIPAA, 개인정보보호법 등 의료정보 보안 규제 준수
	- 암호화 저장, 비식별화 처리, 접근 권한 최소화 필요
	- 의료기기 연동 시 Edge DB 및 IoT 보안 고려

⸻

4. 공공 기관에서의 데이터베이스 활용과 주요 데이터 관리 전략

활용 분야:
	- 주민등록, 국세, 부동산, 복지, 교통 등 국민 생활 데이터 관리
	- 스마트 행정, 민원 처리, 공공 통계 분석

데이터 관리 전략:
	- 데이터 표준화 및 메타데이터 체계 구축
	- 정보 공유 플랫폼 구축 (e.g. 공공데이터포털)
	- 보안 및 투명성 확보 위한 감사 체계 구축

⸻

5. 전자상거래(E-Commerce) 시스템에서 DB 설계 시 고려 요소

고려 요소:
	- 상품, 사용자, 주문, 배송, 결제, 리뷰 등 다양한 엔터티 구조
	- 정합성(재고 동기화), 확장성(트래픽 폭증 대응), 보안성
	- 쿠폰, 포인트, 추천 등 비즈니스 로직 유연성 고려
	- 실시간 주문 처리와 배치 분석 병행 가능한 구조 필요

⸻

6. 소셜 미디어 플랫폼에서 대용량 DB 처리 전략

전략:
	- 분산 DB 또는 NoSQL(DB + Redis + Cassandra + Elasticsearch 등)
	- 유저 피드, 댓글, 좋아요, 해시태그 등 다양한 관계형/비관계형 데이터 혼합
	- CDN, 캐시 시스템, GraphDB 활용
	- 빅데이터 분석을 위한 로그 기반 파이프라인 구축

⸻

7. 온라인 게임에서 실시간 DB 처리를 위한 주요 기술

기술:
	- In-Memory DB(Redis, Memcached)로 실시간 게임 상태 관리
	- 플레이어 활동 로그, 랭킹, 아이템 상태 등 빠른 CRUD 처리
	- 샤딩 및 파티셔닝으로 글로벌 유저 동시 접속 분산 처리
	- 실시간 채팅, 매칭 시스템에는 NoSQL과 메시지 큐(Kafka, RabbitMQ) 연동

1. 자율주행차(Autonomous Vehicle) 시스템에서 데이터베이스의 역할

역할:
	- 센서·카메라·레이더 등에서 수집되는 실시간 환경 정보 저장
	- 차량 위치, 주행 이력, 경로 정보 등 지속적 기록 및 분석
	- AI 주행 판단 알고리즘 학습용 데이터 관리
	- OTA(Over-the-Air) 업데이트 관리용 메타데이터 저장

요구 특성:
	- 초고속 In-Memory DB 활용
	- 엣지 컴퓨팅 기반 분산 저장
	- 위치 기반 DB(GIS, 시계열 DB) 연계

⸻

2. 항공 및 물류 산업에서 데이터베이스 활용 및 최적화 기법

활용:
	- 예약 시스템, 항공편 정보, 탑승객 데이터 관리
	- 물류 흐름 추적, 화물 정보, 운송 스케줄 관리
	- 실시간 재고 및 위치 추적 시스템 구현

최적화 기법:
	- 파티셔닝을 통한 대용량 이력 데이터 효율적 관리
	- 비정상 이벤트 감지를 위한 실시간 스트리밍 처리
	- 경로 예측을 위한 AI 연계형 분석 DB 구조 활용

⸻

3. 데이터베이스 관리자의 역할과 주요 업무

핵심 역할:
	- 데이터베이스의 설계, 구축, 운영, 유지보수
	- 백업/복구, 성능 튜닝, 보안 관리, 사용자 권한 설정
	- 장애 대응, 시스템 로그 분석, 버전 업그레이드
	- 개발자와 협업하여 데이터 모델 설계 및 테스트 지원

현대 DBA 트렌드:
	- DevOps 및 AI 기반 자동화 도입
	- 클라우드 환경, NoSQL, 빅데이터 플랫폼으로 업무 확장

⸻

4. 데이터 거버넌스(Data Governance) 프레임워크의 개념과 주요 요소

개념:
조직 내 데이터를 정책적으로 관리하고 통제하여 일관성과 책임성을 확보하는 체계

주요 구성 요소:
	- 데이터 정책 및 표준화
	- 책임 및 권한 구조 (Data Owner, Steward 등)
	- 품질 관리와 메타데이터 관리
	- 감사, 보안, 규제 대응 체계

⸻

5. 데이터 아키텍처(Data Architecture)의 개념과 주요 구성 요소

개념:
조직의 데이터 자산을 어떻게 수집, 저장, 처리, 분배할지에 대한 구조적 설계 체계

주요 구성 요소:
	- 데이터 모델(개념/논리/물리)
	- 데이터 흐름 및 파이프라인
	- 데이터 저장소 구조(DBMS, Data Lake 등)
	- 보안 및 거버넌스 연계 구조

⸻

6. 데이터 중심 의사결정을 위한 DB 관리 전략

전략:
	- 고품질 데이터 확보 위한 ETL/정제/검증 체계 수립
	- 실시간 BI 도구, 대시보드 연동을 위한 OLAP 구조 구축
	- AI 분석용 학습 데이터 저장소 운영
	- 조직 내 데이터 카탈로그와 활용 가이드 제공

결과:
	- 데이터 기반 경영 전략 수립과 신속한 의사결정 지원

⸻

7. 조직 내 데이터 전략 수립 시 고려 사항

고려 사항:
	- 데이터 비전 및 활용 목적 명확화
	- 인프라 및 데이터 플랫폼 기술 스택 선택
	- 보안, 프라이버시, 규제 준수 요건
	- 사용자 권한, 품질, 표준화 정책
	- 조직 문화와 협업 체계(데이터 리터러시 교육 포함)

데이터 전략은 기술 중심이 아닌 비즈니스 가치 기반의 계획이 되어야 한다.

1. 데이터 기반 조직(Data-Driven Organization) 전환을 위한 DB 구축 전략

전략:
	- 전사적 데이터 통합 플랫폼 구축 (Data Lake, Data Warehouse)
	- 실시간 분석 가능한 OLAP + 스트리밍 DB 아키텍처 구성
	- 데이터 거버넌스 체계 수립: 품질, 표준화, 보안 정책 명확화
	- 데이터 카탈로그/메타데이터 관리 시스템 운영
	- 데이터 분석 역량을 강화할 인력 및 조직 문화 개선 포함

성공적 전환을 위해선 기술 + 정책 + 사람 3요소가 균형을 이뤄야 한다.

⸻

2. 데이터 과학(Data Science)과 데이터베이스의 관계

관계:
	- 데이터 과학은 DB에서 수집한 데이터를 기반으로 분석, 모델링, 시각화 수행
	- DB는 정형 데이터 저장, NoSQL은 비정형·대규모 데이터 저장에 적합
	- ETL 파이프라인을 통해 DB → 분석 → 결과 저장의 흐름 구성
	- 학습된 모델을 다시 DB와 연동하여 예측 결과 저장/활용 가능

DB는 데이터 과학을 위한 기초 자원 및 운영 인프라의 역할을 수행한다.

⸻

3. IT 서비스 관리(ITSM)에서 데이터베이스의 역할과 중요성

역할:
	- 구성 관리 데이터베이스(CMDB)로 시스템 자산 정보 관리
	- 서비스 요청, 장애 이력, 변경 관리, SLA 등 IT 운영 이력 저장소
	- 문제 및 변경 이력 추적을 통한 지속적 개선 기반 제공
	- ITSM 툴(BMC, ServiceNow 등)과 DB 연동 필수

DB는 안정적인 IT 운영과 사고 대응을 위한 핵심 기반이다.

⸻

4. 데이터베이스를 활용한 지속 가능한 IT 운영 전략

전략:
	- 데이터 정제 및 중복 제거를 통한 저장소 최적화
	- 자원 사용량 모니터링을 통한 스토리지·서버 효율성 제고
	- 탄소 저감을 위한 저전력 DB 아키텍처 설계 (Serverless, In-Memory)
	- 자동화 백업 및 스케일링 기능 도입으로 운영 비용 절감
	- 데이터 라이프사이클 관리 → 보존 정책 기반 자동 폐기

지속 가능성은 에너지 절감, 비용 절약, 친환경 IT 인프라로의 전환을 포함한다.

⸻

5. DB 시스템의 미래 발전 방향과 향후 10년 변화 트렌드

예상 변화 트렌드:
	- 자율 운영 DB 확산 (Autonomous DB)
	- Serverless, 멀티 클라우드 네이티브 구조 대중화
	- AI 튜닝, 예측 분석 내장형 DBMS 확대
	- NoSQL, Graph, 시계열 등 멀티모델 DB 확산
	- Post-Quantum 보안 체계 도입

향후 DB는 운영에서 지능으로, 구조화에서 통합 플랫폼으로 진화할 것이다.

⸻

6. 정규화와 반정규화가 성능에 미치는 영향

정규화:
	- 데이터 중복 제거, 무결성 보장
	- JOIN이 많아져 조회 성능 저하 가능

반정규화:
	- 성능 개선, 쿼리 단순화
	- 데이터 중복·무결성 이슈 발생 가능

적절한 균형 필요:
읽기 중심 → 반정규화 / 쓰기 중심 → 정규화 유지

⸻

7. NoSQL 데이터 모델링과 RDBMS 모델링의 차이

RDBMS:
	- 정형 데이터, 관계 중심
	- 정규화 기반 구조화된 스키마 설계

NoSQL:
	- 비정형 데이터, 스키마 유연성, 도큐먼트/키-값 기반
	- 정규화보다 데이터 중복과 읽기 속도 우선
	- 설계 시 쿼리 패턴과 데이터 액세스 방식 우선 고려

NoSQL은 스키마보다 사용 용도와 성능 최적화를 중심으로 설계된다.

1. OLAP과 OLTP 데이터 모델링의 차이점

OLTP (Online Transaction Processing):
	- 실시간 트랜잭션 처리 중심
	- 정규화 중심 모델링으로 데이터 중복 최소화 및 무결성 확보
	- INSERT/UPDATE가 빈번하며, 소규모 다건 처리

OLAP (Online Analytical Processing):
	- 분석, 리포팅, 데이터 마이닝 중심
	- 반정규화 또는 다차원 모델(Star, Snowflake Schema)
	- 대용량 SELECT 쿼리 중심, 집계 및 조인 최적화 우선

⸻

2. 데이터 모델에서 ERD와 UML의 차이점

ERD(Entity-Relationship Diagram):
	- 데이터 중심 모델링 도구
	- 엔티티, 속성, 관계, 키 등을 통해 데이터 구조를 표현

UML(Unified Modeling Language):
	- 객체지향 중심의 시스템 설계 도구
	- 클래스 다이어그램 등은 데이터뿐 아니라 행동, 상태 등도 표현 가능
	- 소프트웨어 전반 구조 표현 가능

차이:
ERD는 DB 설계에 특화, UML은 시스템 아키텍처 전반 표현에 활용

⸻

3. 대용량 데이터 처리 시 인덱스 설계 전략

전략:
	- 자주 사용하는 컬럼에는 B-Tree 인덱스 적용
	- 복합 인덱스는 WHERE 절 조건 순서 고려
	- 범위 검색 많을 땐 비트맵 인덱스는 비효율적
	- 파티셔닝 키 + 인덱스 결합 전략
	- 읽기 성능 향상 위한 커버링 인덱스 적용

주의: 너무 많은 인덱스는 INSERT/UPDATE 성능 저하 유발

⸻

4. 관계형 데이터 모델에서 데이터 이상(Anomaly)의 원인과 해결 방안

원인:
	- 테이블에 여러 개념을 섞어 설계
	- 중복된 데이터로 인해 삽입, 삭제, 갱신 시 불일치 발생

해결 방안:
	- 정규화를 통해 엔티티 분리
	- 도메인, 참조 무결성 제약조건 설정
	- 적절한 키 설계를 통해 중복 방지

⸻

5. Materialized View(물리화 뷰)의 개념과 활용 사례

개념:
	- 쿼리 결과를 실제 테이블처럼 저장해 빠른 조회 가능하게 하는 구조
	- 주기적 또는 조건부로 리프레시(Refresh) 가능

활용 사례:
	- 복잡한 조인 또는 집계 쿼리의 결과 캐싱
	- 리포팅, 대시보드 등 반복 분석에 최적화
	- 분산 시스템 간 요약 데이터 공유용

⸻

6. 테이블 파티셔닝과 샤딩의 차이점

파티셔닝(Partitioning):
	- 하나의 테이블을 내부적으로 논리 분할
	- 동일 DB 내에서 관리, SQL로 투명하게 접근 가능
	- Range, List, Hash, Composite 방식

샤딩(Sharding):
	- 데이터를 여러 DB 서버에 수평 분산 저장
	- 애플리케이션에서 분산 처리 로직 필요
	- 수평 확장성과 장애 격리에 유리

⸻

7. 인덱스 과사용 시 발생할 수 있는 문제점과 해결 방안

문제점:
	- 데이터 변경 시 인덱스 동기화로 INSERT/UPDATE/DELETE 성능 저하
	- 인덱스 스캔 비용으로 인해 쿼리 오히려 느려질 수 있음
	- 불필요한 인덱스는 디스크 공간 낭비

해결 방안:
	- 실행 계획(Explain Plan) 분석 후 불필요한 인덱스 제거
	- 자주 사용되는 쿼리 기준으로 최소 인덱스 설계 유지
	- 정기적으로 인덱스 재구성(Rebuild) 수행

1. 데이터 스키마 변경 시 고려해야 할 요소와 최적화 방안

고려 요소:
	- 기존 데이터와의 호환성 및 무결성 유지
	- 변경에 따른 인덱스 재구성 및 성능 영향
	- 의존 객체(뷰, 트리거, 프로시저)에 대한 영향 분석
	- 애플리케이션 코드, 쿼리, API 변경 필요성 확인

최적화 방안:
	- 변경 전 테스트 환경에서 시뮬레이션
	- 점진적 마이그레이션 전략 (Online DDL, Shadow Table)
	- DDL Lock 최소화를 위한 비차단(non-blocking) 스키마 변경 기능 사용

⸻

2. 대용량 DB 운영 시 성능 튜닝 고려 사항

주요 고려 사항:
	- I/O 병목 제거 (스토리지, 디스크 캐시, RAID 구성)
	- SQL 실행 계획 분석 및 인덱스 최적화
	- 파티셔닝, 샤딩, 압축, 캐싱 등 물리적 구조 튜닝
	- 리소스 관리: 메모리, CPU, 동시 접속 제한 설정
	- 워크로드 기반 모니터링 지표(Throughput, Latency 등) 활용

⸻

3. 장애 발생 시 DB 복구 전략과 절차

절차:
	1.	장애 유형 진단 (소프트웨어, 하드웨어, 논리적, 미디어 등)
	2.	최근 백업과 로그 활용하여 데이터 복원
	3.	Redo/Undo 적용 및 무결성 검사 수행
	4.	장애 원인 분석 후 재발 방지 조치

전략:
	- 백업 체계(전체, 증분, 트랜잭션 로그) 구성
	- PITR, Hot Standby, 클러스터링 기반 이중화 구성

⸻

4. 성능 병목(Bottleneck) 원인과 해결 방법

주요 원인:
	- 불량 SQL, 부적절한 인덱스
	- I/O 포화, 메모리 부족, 과도한 동시 접속
	- 애플리케이션과의 연결 병목

해결 방법:
	- 쿼리 리팩토링 및 실행 계획 최적화
	- 캐싱, 파티셔닝, 분산 처리 도입
	- Connection Pool, DB 리소스 조절 설정

⸻

5. 온라인 vs 오프라인 백업의 차이

온라인 백업:
	- DB 운영 중 백업 수행 가능, 무중단
	- 트랜잭션 로그 동기화 필요
	- 고가용성 환경에 적합

오프라인 백업:
	- 서비스 중단 후 백업
	- 간단하고 무결성 확보 쉬움
	- 실시간 운영 시스템에는 부적합

⸻

6. Point-in-Time Recovery(PITR)의 개념과 활용

개념:
트랜잭션 로그를 활용해 특정 시점까지 DB 상태 복원하는 기술

활용:
	- 논리적 오류(예: 잘못된 DELETE) 복구
	- 전체 백업 + 로그 기반 복원 구조
	- 시간 지정 또는 로그 위치(Log Sequence Number) 기준

⸻

7. 장애 최소화를 위한 DB 모니터링 기법

기법:
	- DB 성능 지표 모니터링 (CPU, I/O, 세션, 쿼리 등)
	- 실시간 알람 시스템 구축
	- APM, 로그 분석 도구 활용 (Prometheus, Grafana, ELK 등)
	- 장애 징후 탐지를 위한 AI 기반 예측 분석
	- 트랜잭션 대기 시간, Deadlock 탐지 자동화


1. 애플리케이션과의 연결 풀(Connection Pooling) 최적화 기법

개념:
연결 풀은 DB 연결을 미리 생성해 재사용함으로써 커넥션 생성/해제 비용을 절감하는 기술

최적화 기법:
	- 최대/최소 커넥션 수 조정으로 리소스 낭비 방지
	- 커넥션 유휴 시간 설정 및 커넥션 leak 탐지 활성화
	- 연결 풀 모니터링 도구(HikariCP, c3p0 등) 사용
	- 트랜잭션 종료 후 커넥션 반환 보장 코딩 필수

⸻

2. NoSQL vs RDBMS의 장애 복구 방식 차이

RDBMS:
	- 트랜잭션 로그 기반 복구 (Undo/Redo)
	- ACID 보장, 강력한 무결성 체크
	- WAL, PITR 등 활용

NoSQL:
	- 장애 허용(Fault Tolerant) 중심
	- 다수 노드 복제 기반 복구
	- Eventual Consistency, 일부는 Write-Ahead 없이 복구 복잡

NoSQL은 가용성 우선, RDBMS는 무결성 우선 전략

⸻

3. 장애 후 데이터 손실 최소화를 위한 백업·복원 전략

전략:
	- 정기적 전체 + 증분 백업 구성
	- 트랜잭션 로그 보관으로 PITR 가능
	- 이중화 구성 (Replication, Hot Standby)
	- 백업 주기와 보존 기간 정책 수립

복원 시 고려:
	- 백업 유효성 검증, 복원 시점 확인
	- 최소 다운타임을 위한 복원 자동화 스크립트 구성

⸻

4. 무중단 유지보수(Rolling Upgrade, Hot Standby) 기법

Rolling Upgrade:
	- 노드를 순차적으로 업데이트
	- 클러스터 구성 시 서비스 중단 없이 버전 교체 가능

Hot Standby:
	- 이중화된 대기 서버로 즉시 전환 가능
	- Active-Standby 구성으로 장애 대응 및 유지보수 지원
	- 로그 전송 및 동기화 메커니즘 필요

⸻

5. 성능 튜닝 시 주요 메트릭

Throughput: 단위 시간당 처리량 (TPS, QPS 등)
Latency: 작업 완료까지 걸리는 시간
Response Time: 요청 → 응답 소요 시간
Wait Time: 리소스 대기 시간 (Lock, IO 등)
Cache Hit Ratio, Buffer Pool Usage, Disk IO Rate 등도 중요

이 메트릭들은 병목 원인 식별 및 튜닝 우선순위 결정에 활용됨

⸻

6. SQL 실행 계획(Execution Plan) 분석을 통한 성능 개선

분석 항목:
	- Access Path (Full Scan, Index Scan 등)
	- 조인 방식(Nested Loop, Hash Join 등)
	- 필터 조건의 실행 순서
	- Row Count, Cost 예측

개선 방법:
	- 인덱스 재설계, 힌트 적용
	- 불필요한 조인 제거, 서브쿼리 개선
	- 통계 갱신(ANALYZE, UPDATE STATISTICS)

⸻

7. Query Rewriting을 통한 SQL 성능 최적화 기법

기법:
	- IN → EXISTS / JOIN으로 변경
	- 중첩된 서브쿼리를 조인으로 변경
	- 불필요한 컬럼 제거, 와일드카드(*) 지양
	- 조건 절 내 계산식을 사전 변수 처리로 이동

효과:
	- 실행 계획 개선
	- CPU, IO, 메모리 자원 절약
	- 캐시 활용률 향상

1. 데이터베이스 캐싱(Caching) 전략과 주요 유형

전략 목적:
	- 데이터 접근 속도 향상 및 DB 부하 감소를 위한 중간 저장소 활용

주요 유형:
	- Read-Through: 캐시에 데이터 없을 경우 DB에서 읽고 캐시에 저장
	- Write-Through: 쓰기 시 캐시와 DB에 동시 기록
	- Write-Back: 먼저 캐시에만 저장 후 일정 시간 또는 조건 충족 시 DB에 반영 (속도 빠르나 장애 위험 존재)

활용 사례:
	- Redis, Memcached 등 In-Memory 캐시 시스템 사용

⸻

2. Parallel Query Processing(병렬 쿼리 처리)의 개념과 활용

개념:
	- 단일 쿼리를 여러 스레드나 노드에서 병렬로 처리하여 실행 속도 향상

활용 방안:
	- 대용량 집계, 분석 쿼리 (OLAP 환경)
	- 테이블 파티셔닝 기반 쿼리 병렬화
	- 병렬 정렬, 조인, 집계 연산에 사용

주요 기술:
	- Oracle Parallel Query, PostgreSQL Parallel Worker, Spark SQL 등

⸻

3. Materialized View를 활용한 성능 최적화 방안

활용 목적:
	- 복잡한 조인, 집계를 사전 계산해 저장함으로써 조회 성능 극대화

최적화 방안:
	- 자주 사용하는 대시보드/리포트 쿼리의 결과 캐싱
	- 자동 Refresh 또는 수동 업데이트 방식 선택
	- 쿼리 Rewrite 기능과 연동하면 일반 쿼리도 물리화 뷰 참조 가능

⸻

4. 인덱스 설계 시 고려 사항과 과다 인덱싱 문제

고려 사항:
	- 자주 사용하는 WHERE 조건, 조인 조건, 정렬 기준 중심
	- 인덱스 컬럼 순서 중요(선두 컬럼 우선 접근)
	- 업데이트가 많은 컬럼은 인덱스 최소화

과다 인덱싱 문제:
	- DML 성능 저하 (INSERT/UPDATE/DELETE 시 인덱스 재구성)
	- 디스크 공간 낭비
	- 옵티마이저가 잘못된 계획 선택 가능

⸻

5. NoSQL 데이터베이스 성능 최적화를 위한 모델링 기법

기법:
	- 정규화 대신 중복 허용 설계
	- 쿼리 기반 모델링: 사용 패턴에 최적화된 구조 설계
	- 문서형(NoSQL)에서는 Nested 구조 또는 Embedded Document 활용
	- Key-Value 모델에서는 복잡한 연산을 애플리케이션에 위임

⸻

6. 데이터 압축(Compression)이 DB 성능에 미치는 영향

장점:
	- 저장 공간 절약
	- 디스크 I/O 감소 → 읽기 성능 개선 가능
	- 백업 및 네트워크 전송 속도 향상

단점:
	- 압축/해제 시 CPU 사용량 증가
	- 실시간 쓰기/읽기 성능 요구가 높은 시스템에선 신중히 사용

적용 예:
	- Oracle Advanced Compression, PostgreSQL TOAST, columnar storage DB

⸻

7. 워크로드 기반 자동 튜닝(Auto-Tuning)의 개념과 활용

개념:
	- DB가 실행 쿼리 및 시스템 부하를 분석해 튜닝 요소를 자동 조정하는 기법

활용 사례:
	- 자동 인덱스 생성/삭제
	- 쿼리 리라이터 및 힌트 자동 적용
	- 캐시 크기, 병렬 처리 수준 조정

대표 기술:
	- Oracle AutoML, SQL Server 자동 인덱싱, Cloud Spanner Auto-Tune 등

1. 객체 저장소(Object Storage)와 블록 저장소(Block Storage)의 차이

객체 저장소:
	- 파일을 메타데이터와 함께 하나의 오브젝트 단위로 저장
	- 확장성 우수, 비정형 데이터(이미지, 로그 등)에 적합
	- 예: Amazon S3, Google Cloud Storage

블록 저장소:
	- 데이터를 고정 크기의 블록 단위로 나누어 저장
	- 성능 중심, RDBMS와 같은 고속 입출력 시스템에 적합
	- 예: EBS, Azure Disk

⸻

2. 데이터 레이크와 데이터 웨어하우스의 차이

데이터 레이크:
	- 정형, 반정형, 비정형 데이터를 원시 형태로 저장
	- Schema-on-Read 구조
	- 머신러닝, 빅데이터 분석 등에 적합

데이터 웨어하우스:
	- 정제된 정형 데이터 중심
	- Schema-on-Write 구조
	- OLAP 및 비즈니스 인텔리전스에 적합

⸻

3. NewSQL 데이터베이스의 개념과 RDBMS 및 NoSQL과의 차이

NewSQL:
	- RDBMS의 ACID 보장 + NoSQL의 수평 확장성 결합
	- 분산처리 기반이면서도 SQL 지원

차이점:
	- RDBMS: ACID 보장, 수직 확장
	- NoSQL: 유연한 스키마, 수평 확장, 낮은 일관성
	- NewSQL: SQL 사용 + 수평 확장 + 높은 일관성

예: CockroachDB, Google Spanner, TiDB

⸻

4. 블록체인 기반 데이터 저장소와 기존 DB의 차이

블록체인:
	- 변조 불가, 분산 저장, 신뢰 기반 데이터 기록
	- 데이터는 블록 단위로 암호화되어 연결됨
	- 트랜잭션 중심 저장소

기존 DB:
	- CRUD 자유로움
	- 중앙 관리 구조
	- 빠른 쿼리 및 실시간 처리에 유리

차이점 요약: 블록체인은 신뢰성과 추적성 중심, 기존 DB는 속도와 유연성 중심

⸻

5. 데이터 스트리밍 플랫폼과 DB의 관계

플랫폼:
	- Kafka, Flink, Spark Streaming 등
	- 실시간 이벤트/로그/센서 데이터를 스트림 형태로 처리

DB 연계:
	- 스트리밍 데이터를 Ingestion하여 실시간 분석 저장소(DB)에 적재
	- 스트림 처리 후 NoSQL, Time-Series DB, Data Lake 등에 저장
	- CDC(Change Data Capture)를 통해 스트림화 가능

⸻

6. 분산 저장 및 복제에서 CAP 이론 적용 사례

CAP 이론:
	- Consistency, Availability, Partition Tolerance 중 두 가지를 보장
	- 예시:
	- Cassandra: AP 우선 (일관성 낮고 가용성 우선)
	- HBase: CP 우선 (가용성보다 일관성 우선)
	- MongoDB: 설정에 따라 조정 가능

설계 시 서비스 목적에 따라 CAP 우선순위 선택 필요

⸻

7. 데이터 동기화 기법(Async, Sync, Hybrid)의 개념과 활용

동기(Synchronous):
	- 데이터 변경이 모든 노드에 동시에 반영됨
	- 일관성 높음, 성능 저하 가능

비동기(Asynchronous):
	- 변경이 일정 시간 후 반영됨
	- 속도 빠르나 일시적인 불일치 존재

하이브리드(Hybrid Sync):
	- 중요 트랜잭션은 Sync, 일반 데이터는 Async 처리
	- 속도와 일관성의 균형 확보

1. ETL과 ELT의 차이

ETL(Extract, Transform, Load):
	- 데이터를 추출 → 변환 → 로드 순서로 처리
	- 변환을 중간 서버에서 수행 후 DW나 DB에 적재
	- 전통적인 DWH 방식, 데이터 품질 관리에 적합

ELT(Extract, Load, Transform):
	- 데이터를 추출 → 로드 → 변환 순서로 처리
	- 변환은 대상 DB 또는 DWH 내부에서 수행
	- 클라우드 기반 DW(예: BigQuery, Snowflake)에 적합
	- 대용량 처리에 유리

⸻

2. 멀티 클라우드 환경에서 데이터 저장 전략

전략:
	- 이기종 클라우드 간 데이터 일관성 유지 및 통합 처리 설계
	- 분산 저장 + 지역별 복제(Geo-Replication) 구성
	- 데이터 이동성 확보: 공통 포맷 및 API 기반 통신
	- 비용 최적화 및 규제 준수(데이터 주권) 고려 필요
	- 클라우드 간 Failover 및 DR(재해 복구) 체계 확보

⸻

3. 클라우드 네이티브 데이터베이스의 개념과 특징

개념:
	- 클라우드 환경에 최적화되어 자동 확장, 탄력적 리소스 할당, 마이크로서비스와 연동 가능한 DB

주요 특징:
	- Serverless 구조 (무중단 자동 확장)
	- Kubernetes 기반 오케스트레이션 지원
	- API 중심 관리 및 자동화
	- 고가용성, 지역 복제, 글로벌 서비스 용이

예: Google Spanner, Aurora Serverless, CockroachDB

⸻

4. 데이터베이스 감사(Auditing) 및 로그 관리(Log Management)의 개념과 기법

Auditing:
	- 사용자, 쿼리, 테이블 접근 등의 이력 기록 및 이상 행위 추적

로그 관리 기법:
	- 트랜잭션 로그, 에러 로그, 액세스 로그 등 구분
	- 중앙 로그 수집 도구(ELK, Fluentd, Graylog) 연동
	- 보안, 감사, 분석을 위한 로그 보존 정책 수립

⸻

5. RBAC vs ABAC의 차이

RBAC(Role-Based Access Control):
	- 역할(예: 관리자, 사용자)에 따라 권한 부여
	- 단순하고 관리 용이하나 세부 상황 반영 어려움

ABAC(Attribute-Based Access Control):
	- 사용자 속성, 리소스 속성, 환경 정보 등으로 권한 결정
	- 복잡하지만 정책 기반 세밀한 제어 가능

⸻

6. 동형 암호화(Homomorphic Encryption)의 개념과 활용

개념:
	- 암호화된 상태에서도 산술 연산이 가능한 암호 기법
	- 복호화 없이 연산 수행 → 개인정보 보호와 분석 동시 가능

활용 사례:
	- 민감 데이터 분석(의료, 금융)
	- 클라우드 기반 암호화된 데이터 처리
	- AI 모델 학습 데이터 보호

단점은 계산 복잡도로 인한 성능 저하


1. Privacy Enhancing Technologies(PETs)의 개념과 주요 기술

개념:
개인정보 보호를 위해 데이터를 안전하게 처리·분석하는 기술군으로, 프라이버시와 데이터 활용의 균형을 추구

주요 기술:
	- Differential Privacy: 통계적 노이즈를 추가해 개인 식별 방지
	- Federated Learning: 데이터를 중앙에 모으지 않고 분산된 환경에서 모델 학습
	- Homomorphic Encryption, SMPC, Zero-Knowledge Proof 등도 PET에 포함됨

⸻

2. 자동화 보안 도구(SQLMap, SonarQube 등)의 개념과 활용

SQLMap:
	- SQL Injection 자동 탐지 및 익스플로잇 도구
	- 웹 애플리케이션의 DB 취약점을 탐색하고 구조 확인 가능

SonarQube:
	- 코드 품질 및 보안 취약점 정적 분석 도구
	- SQL 인젝션, XSS, 하드코딩 암호 등 코드 레벨 위협 탐지

활용:
	- DevSecOps에서 CI/CD 파이프라인과 연계해 자동 보안 테스트 수행 가능

⸻

3. 금융 데이터 보호를 위한 암호화 및 인증 기법

암호화 기법:
	- TDE(Transparent Data Encryption): 저장소 수준 데이터 암호화
	- 컬럼 암호화: 민감 컬럼만 선택적으로 암호화
	- TLS/SSL: 전송 중 데이터 보호

인증 기법:
	- 다중 인증(MFA), 디지털 서명, 인증서 기반 접근 제어
	- 금융보안 규제에 따른 접근 통제 정책 구현 필요

⸻

4. Secure Multi-Party Computation(SMPC)의 개념과 활용 사례

개념:
	- 다수의 참여자가 데이터를 노출하지 않고 공동 연산 수행 가능한 암호화 기술

활용 사례:
	- 의료 기관 간 환자 데이터 공동 분석
	- 경쟁사 간 통합 고객 분석 (e.g. 카드사 간 마케팅 협업)
	- 정부 통계 생성 시 프라이버시 보호 기반 처리

⸻

5. 보안 규제 준수와 데이터 거버넌스의 관계

보안 규제:
	- ISO 27001, GDPR, CCPA, HIPAA 등
	- 데이터 저장, 처리, 접근, 보존, 파기 절차 준수 요구

데이터 거버넌스 연계:
	- 보안 정책, 역할 정의, 모니터링, 감사 기록 등 관리 체계 필요
	- 거버넌스는 규제 대응의 기반 프레임워크

⸻

6. 익명화 vs 가명화의 차이

익명화(Anonymization):
	- 데이터를 영구적으로 식별 불가하게 변경
	- 복원이 불가능하며 분석용 공개 데이터셋에 적합

가명화(Pseudonymization):
	- 데이터를 가명으로 치환하여 식별자 분리
	- 복원 가능 (추가 정보 보관) → 내부 처리, 통계 분석에 유리

⸻

7. 양자 컴퓨팅이 DB 보안 모델에 미치는 영향

위협:
	- 양자 알고리즘(Shor’s Algorithm 등)이 기존 공개키 암호(RSA, ECC)를 무력화
	- 데이터 전송 및 저장 보안 체계의 재설계 필요

대응 방안:
	- Post-Quantum Cryptography(PQC) 채택
	- 양자 난수 생성(QRNG), 양자 키 분배(QKD) 기반 보안 채널 도입
	- 암호 알고리즘 및 인증 체계의 표준화 대응 필요 (NIST PQC)

1. 트랜잭션의 격리 수준(ANSI SQL Isolation Levels)별 특징과 적용 사례

Read Uncommitted:
	- 다른 트랜잭션의 커밋되지 않은 데이터도 읽을 수 있음
	- Dirty Read 허용, 가장 낮은 격리 수준
	- 빠르지만 신뢰성 낮음 (모니터링, 로그 등에서 제한적 활용)

Read Committed:
	- 커밋된 데이터만 읽음, Dirty Read 방지
	- Non-Repeatable Read, Phantom Read 발생 가능

Repeatable Read:
	- 동일 트랜잭션 내 같은 쿼리 결과 일관성 유지
	- Non-Repeatable Read 방지, Phantom Read는 발생 가능

Serializable:
	- 가장 높은 격리 수준, 트랜잭션을 직렬 실행처럼 처리
	- 모든 현상 방지, 성능 비용 큼
	- 재고 관리, 금융 이체 등 정합성 우선 시스템에 적합

⸻

2. 트랜잭션 성능 최적화를 위한 MVCC 개념과 장단점

MVCC (Multi-Version Concurrency Control):
	- 트랜잭션마다 데이터를 스냅샷으로 분리 관리
	- 읽기는 읽기 전용 버전, 쓰기는 새로운 버전 생성

장점:
	- 읽기/쓰기 간 충돌 최소화, 비차단 읽기 가능
	- 읽기 트랜잭션이 많을수록 성능 향상

단점:
	- 버전 관리로 인한 저장 공간 증가
	- Garbage Collection 처리 필요

PostgreSQL, Oracle, MySQL(InnoDB) 등에서 활용

⸻

3. 2단계 로킹 프로토콜(2PL)의 개념과 특징

개념:
	- 트랜잭션 수행 시 잠금 획득 단계 → 해제 단계로 구분
	- 모든 락을 얻은 후에만 해제 가능
	- 트랜잭션 간 일관성 확보 및 Serializability 보장

특징:
	- Strict 2PL: 트랜잭션 종료 전까지 Exclusive Lock 유지 (Recovery 용이)
	- Deadlock 발생 가능성 존재
	- 자원 효율보다 정합성 우선 상황에 적합

⸻

4. 비관적 vs 낙관적 동시성 제어의 차이

비관적(Pessimistic):
	- 트랜잭션 간 충돌 가능성 높다고 가정
	- Lock 기반 제어, 충돌 예방
	- 성능 저하 가능성 있지만 정합성 우선

낙관적(Optimistic):
	- 충돌 가능성 낮다고 가정
	- 변경 시점에만 충돌 여부 검사(Validation)
	- Lock 사용 최소화, 성능 향상 기대

⸻

5. Timestamp Ordering 기법의 개념과 특징

개념:
	- 트랜잭션에 타임스탬프 부여 → 수행 순서를 시간 기반으로 결정
	- 쓰기·읽기 시점 비교로 충돌 판단

특징:
	- Lock-free 동시성 제어 방식
	- 정합성은 보장하나, Abort 빈도 증가
	- 쓰기 중심 시스템에는 부담

⸻

6. 트랜잭션 충돌 해결 기법

Deadlock Detection:
	- Wait-For Graph 분석으로 교착 상태 탐지 후 강제 Abort

Timeout:
	- 일정 시간 대기 후 자동 Abort

Wait-Die:
	- 먼저 시작한 트랜잭션만 대기, 늦은 트랜잭션은 Abort

Wound-Wait:
	- 먼저 시작한 트랜잭션이 후발 트랜잭션을 중단시키고 선점

각 기법은 트랜잭션 우선순위와 시스템 성격에 따라 선택적으로 적용

⸻

7. WAL(Write-Ahead Logging)의 개념과 무결성 보장 방식

개념:
	- 변경 내용은 DB 반영 전에 로그에 먼저 기록
	- 시스템 장애 발생 시 로그 기반으로 복구 가능 (Redo, Undo)

무결성 보장:
	- 로그를 활용해 트랜잭션 원자성과 지속성(ACID 중 A, D) 확보
	- WAL은 DB 복구, Rollback, PITR의 기반

PostgreSQL, Oracle, MySQL 등 대부분의 DBMS에서 사용

1. ARIES 복구 알고리즘의 개념과 주요 단계

개념:
ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)는 DBMS의 장애 복구를 위한 로그 기반의 고신뢰 회복 알고리즘으로, WAL(Write-Ahead Logging)을 기반으로 함.

주요 단계:
	- Analysis: 장애 시점까지의 로그 분석, 트랜잭션 및 페이지 상태 파악
	- Redo: 로그를 이용해 변경 사항 재적용 (손실 방지)
	- Undo: 완료되지 않은 트랜잭션 롤백 (무결성 보장)
→ LSN(Log Sequence Number)을 통해 순서를 유지

⸻

2. 트랜잭션 로그의 개념과 롤백 방식

개념:
트랜잭션 실행 시 발생한 모든 변경사항을 로그 파일에 기록하여 복구 및 감사에 사용

롤백 수행 방식:
	- Undo 로그 기록 → 역순으로 복원
	- Undo와 Redo를 통해 원자성(Atomicity) 보장
	- WAL 정책: 로그가 디스크에 기록되기 전에는 실제 데이터 변경 금지

⸻

3. 2PC vs 3PC

2PC (Two-Phase Commit):
	- Prepare → Commit 단계로 구성
	- Coordinator가 참여 노드에게 Commit 여부 질의 후, 응답에 따라 결정
	- 단점: Coordinator 장애 시 블로킹 발생

3PC (Three-Phase Commit):
	- CanCommit → PreCommit → Commit 단계
	- 중간에 Timeout 기반 Abort 가능 → Non-Blocking 보장
	- 더 복잡하지만 신뢰성 향상

⸻

4. Graph Database의 특징과 RDBMS/NoSQL과의 차이점

주요 특징:
	- 노드-간의 관계(Edge)를 1차 시민으로 취급
	- 복잡한 관계형 데이터의 빠른 탐색 및 그래프 알고리즘 수행 가능

차별점:
	- RDBMS: 정형 테이블 기반, JOIN으로 관계 표현
	- NoSQL: 유연한 구조, 관계 표현은 약함
	- Graph DB: 관계 탐색 최적화, 비정형 관계 표현에 강점

예: Neo4j, ArangoDB

⸻

5. AI 기반 자동 튜닝의 개념과 활용

개념:
AI가 쿼리, 인덱스, 워크로드, 시스템 상태 등을 학습하여 자동으로 DB 성능을 최적화하는 기술

활용 사례:
	- 인덱스 자동 생성/제거
	- 쿼리 재작성 및 실행계획 개선
	- 리소스 자동 조정 (Buffer Pool, Cache 등)

예: Oracle AutoML, SQL Server Intelligent Tuning

⸻

6. HTAP의 개념과 적용 방안

HTAP (Hybrid Transactional and Analytical Processing):
	- OLTP + OLAP을 단일 시스템에서 통합 처리하는 아키텍처

적용 방안:
	- In-Memory 기반 Dual Storage Engine 설계
	- 실시간 데이터 분석 및 트랜잭션 처리 가능
	- 대표 DB: SAP HANA, TiDB, SingleStore

HTAP은 실시간 마케팅, IoT, 금융 분석 등에서 유용


1. 머신러닝 기반 이상 탐지 시스템에서 데이터베이스의 역할

데이터 수집 및 저장:
	- 센서, 로그, 트랜잭션 등 다양한 시계열/이벤트 데이터를 실시간 저장

모델 학습 및 피드백 루프:
	- 이상 탐지 결과와 함께 정상/이상 레이블 데이터 저장 → 지속적 재학습에 활용

시각화 및 분석:
	- 이상 탐지 결과를 대시보드 및 리포트로 제공하기 위한 질의 최적화 필요

기타:
	- Materialized View, Stream Processing, Partitioning을 통해 성능 최적화

⸻

2. AI 기반 예측 분석(Predictive Analytics)의 개념과 활용 사례

개념:
	- 과거 데이터로부터 패턴을 학습하여 미래를 예측하는 분석 방식
	- 회귀, 시계열 예측, 분류 모델 등 사용

활용 사례:
	- 수요 예측, 고장 예지, 사용자 이탈 예측, 금융 사기 탐지
	- DB는 대용량 학습 데이터를 안정적으로 저장하고 서빙하는 역할 수행

⸻

3. Edge AI와 데이터베이스의 관계 및 실시간 데이터 처리 방안

Edge AI와 DB 관계:
	- 엣지 디바이스에서 로컬 데이터 수집 → 경량 DB 저장 (예: SQLite, InfluxDB)
	- 필요 시 클라우드 DB로 동기화

실시간 처리 방안:
	- In-Memory DB, Stream DB, Time-Series DB 도입
	- Kafka/Flink 등을 통해 실시간 이벤트 분석
	- DB 내에서도 Trigger, Stored Procedure로 반응형 처리 구성

⸻

4. 양자 컴퓨팅이 데이터베이스 기술에 미치는 영향

긍정적 측면:
	- 고속 병렬 연산을 통한 대규모 데이터 처리 가능
	- NP-Hard 최적화 문제에 대한 솔루션 가능성
	- 새로운 양자 알고리즘 기반 인덱싱, 검색 기술 등장 예상

부정적 측면:
	- 기존 암호화 기술 붕괴 → 보안 아키텍처 재설계 필요
	- 트랜잭션 정합성, 동시성 제어 등도 새로운 모델 필요

⸻

5. 자동화된 데이터 분류 및 거버넌스를 위한 AI 기반 데이터 라벨링

개념:
	- 머신러닝 기반으로 데이터의 의미, 민감도, 유형 등을 자동 분류하고 메타데이터로 관리

활용:
	- 민감 정보 자동 식별 및 암호화 적용
	- 데이터 카탈로그 자동 구성
	- AI 모델 학습용 라벨링 자동화

도구:
	- Amazon Macie, Google DLP, open-source Data Discovery 플랫폼

⸻

6. ESG 트렌드가 데이터베이스 설계·운영에 미치는 영향

Environmental:
	- 에너지 효율 높은 DBMS 도입, Idle 자원 최소화
	- 그린 데이터센터, 탄소 배출 감축 로그 추적

Social:
	- 개인정보 보호와 투명한 데이터 관리
	- AI 윤리와 데이터 편향 방지를 위한 데이터 관리 전략 필요

Governance:
	- 데이터 감사 기록, 보안 정책, 데이터 책임자 지정
	- 데이터 보존 및 삭제 정책 강화

⸻

7. 향후 10년간 데이터베이스 기술 발전 방향과 변화 트렌드

예상 변화:
	- AI 기반 완전 자율 운영 DBMS 확산
	- HTAP, NewSQL 중심의 하이브리드 처리 아키텍처 보편화
	- 클라우드 네이티브 + 멀티 클라우드 최적화
	- 양자 보안 기반 DB 인프라, AI 기반 성능 튜닝, ESG 내재화 설계


1. Read Intensive와 Write Intensive 워크로드 최적화 전략

Read Intensive (읽기 집중형):
	- 인덱스 최적화, 캐시 활용 (Redis, Memcached)
	- Materialized View, Read Replica 구성
	- 쿼리 리팩토링과 파티셔닝을 통한 병렬 읽기 처리

Write Intensive (쓰기 집중형):
	- Batch Write, WAL(Write-Ahead Logging) 튜닝
	- 인덱스 수 최소화, 비동기 처리
	- 로그 기반 구조(DB 구조 자체를 Write-Friendly하게 설계)

⸻

2. SQL 실행 속도 최적화를 위한 Query Rewriting 기법

주요 기법:
	- 서브쿼리를 JOIN으로 변경
	- IN → EXISTS 또는 JOIN
	- OR 조건을 UNION으로 분리
	- 불필요한 SELECT * 제거
	- 조건절 내 함수 사용 피하기

이러한 방식으로 실행 계획 단순화, 인덱스 활용 극대화 가능

⸻

3. 데이터베이스 캐시(Cache) 기법과 주요 활용 사례

캐시 기법:
	- Query Result Cache: 쿼리 결과 자체를 캐시
	- Buffer Pool Cache: 블록 단위 캐싱 (DB 내부 메모리 구조)
	- Application Layer Cache: Redis, Memcached 등 외부 캐시 사용

활용 사례:
	- 실시간 뉴스, 쇼핑몰 제품 목록, 로그인 세션 등 읽기 빈도 높은 데이터 처리에 필수

⸻

4. 실행 계획(Execution Plan) 분석 시 주의할 사항

주의 포인트:
	- Access Path (Full Scan vs Index Scan)
	- Join 순서 및 방식 (Nested Loop, Merge, Hash)
	- Filter 조건 적용 위치
	- Cardinality 예측 오류 여부
	- 비용(Cost), Row 예측 값의 신뢰성 여부

분석 도구:
	- EXPLAIN, AUTOTRACE, Visual Explain Plan 등

⸻

5. 커서(Cursor)의 개념과 성능 영향

개념:
	- 쿼리 결과 집합을 한 행씩 순차적으로 처리하기 위한 제어 구조

성능 이슈:
	- 반복 처리로 인해 속도 저하 및 메모리 사용 증가
	- 특히 PL/SQL, Stored Procedure 내에서 과도한 사용 시 성능 저하 유발

대안:
	- Bulk Collect, Set-Based Processing로 대체

⸻

6. 병목 분석을 위한 주요 지표

Throughput:
	- 단위 시간당 처리 요청 수 (TPS, QPS)

Latency:
	- 응답 시간(지연 시간), 네트워크 및 DB 처리 속도에 영향

Response Time:
	- 사용자가 실제로 느끼는 전체 처리 시간

기타:
	- Wait Event, Lock Wait Time, IOPS, CPU Usage 등

⸻

7. Parallel Query Processing 개념과 활용 사례

개념:
	- 대형 쿼리를 여러 CPU나 노드에서 병렬로 나누어 실행

활용 사례:
	- 대용량 분석(OLAP), 데이터 마이그레이션, 통계 집계
	- Oracle Parallel Hint, PostgreSQL Parallel Worker 등

전제 조건:
	- 파티셔닝, 쿼리 분할 전략, I/O 최적화 병행 필요

⸻

8. 데이터베이스 부하 분산(Load Balancing) 기법과 사례

기법:
	- Read/Write 분리: 읽기는 복제본, 쓰기는 마스터 처리
	- Connection Pool + Proxy (예: HAProxy, PgPool)
	- DNS 라운드 로빈, 애플리케이션 레벨 라우팅

사례:
	- 대형 전자상거래, 스트리밍 서비스, 실시간 분석 시스템 등에서 적용
	- 장애 복구(HA)와 성능 향상을 동시에 달성

1. 테이블 조인 최적화: Nested Loop, Hash Join, Merge Join의 차이

Nested Loop Join:
	- 한 테이블의 각 행마다 다른 테이블 전체를 반복 탐색
	- 소량 데이터 또는 인덱스 활용 가능한 경우에 적합
	- 느리지만 간단, 소규모 쿼리에 사용

Hash Join:
	- 한 테이블을 해시 테이블로 변환 후 조인
	- 인덱스 없을 때 유리, 대량 데이터 처리에 적합
	- 내부 메모리 크기 의존 → Out-of-Memory 시 성능 저하

Merge Join:
	- 정렬된 두 테이블을 병합하며 조인
	- 사전 정렬 또는 인덱스 기반 조인에 최적
	- 대용량, 범위 기반 조인에서 성능 우수

⸻

2. AI 기반 자동 튜닝 개념과 활용 사례 (보완 설명)

개념:
	- 머신러닝 기반으로 워크로드 패턴을 학습하고 DB 설정, 쿼리 실행 계획, 인덱스 등을 자동 최적화

활용:
	- 자동 인덱스 추천 및 제거, 쿼리 리라이팅
	- SQL 성능 분석 후 힌트 자동 적용
	- Oracle Autonomous DB, Azure Intelligent Insights 등 상용 서비스 확대 중

⸻

3. 분산 데이터베이스의 개념과 장단점

개념:
	- 데이터가 여러 지리적 위치의 노드에 분산 저장되어 운영되는 DB 시스템

장점:
	- 확장성, 가용성, 지역 최적화된 서비스 가능
	- 장애 복구 용이

단점:
	- 일관성 유지 어려움, 네트워크 지연, 복잡한 관리

⸻

4. CAP 이론의 개념과 분산 DB와의 관계

CAP 이론:
	- 분산 시스템에서 Consistency(일관성), Availability(가용성), Partition Tolerance(분할 내성) 중 2가지만 보장 가능

적용:
	- CP: HBase (일관성 + 분할 내성)
	- AP: Cassandra (가용성 + 분할 내성)
	- CA: 이론적으로 가능하나 Partition 발생 시 불가능

분산 DB 설계 시 서비스 특성에 맞게 선택 필요

⸻

5. BASE 모델의 개념과 활용

BASE:
	- Basically Available, Soft State, Eventual Consistency
	- CAP 이론에서 일관성 대신 가용성 중심 선택한 모델

활용:
	- NoSQL, SNS, IoT 등 대규모 시스템
	- 즉각 반영보다 시간에 따른 일관성 확보 전략

⸻

6. 2PC와 3PC의 차이 (보완 설명)

2PC:
	- Prepare → Commit
	- Coordinator 장애 시 Blocking 발생

3PC:
	- CanCommit → PreCommit → Commit
	- Timeout 및 상태 확인을 통해 Non-Blocking 보장
	- 복잡하지만 안정성 향상

⸻

7. 샤딩과 레플리케이션의 차이

샤딩(Sharding):
	- 데이터를 범위 또는 해시로 분산 저장
	- 수평 확장, 처리량 증가
	- 예: 사용자 ID 기준 분산

레플리케이션(Replication):
	- 데이터를 여러 노드에 동일하게 복제
	- 고가용성, 장애 대비
	- 예: Master-Slave, Multi-Master

⸻

8. 분산 DB에서 데이터 일관성 유지 기법

기법:
	- Quorum Protocol: 과반수 노드 동의로 읽기/쓰기 처리
	- Conflict-Free Replicated Data Type(CRDT)
	- Vector Clock, Versioning
	- Strong vs Eventual Consistency 선택 전략


1. 글로벌 데이터 동기화(Global Data Synchronization)의 개념과 구현 방식

개념:
지리적으로 분산된 서버 간 데이터를 일관성 있게 동기화하는 기술로, 글로벌 사용자 대상 서비스에서 핵심

구현 방식:
	- Async (비동기): 성능 우수, 일시적 불일치 허용
	- Sync (동기): 즉시 반영, 일관성 우수하나 지연 발생
	- Hybrid Sync: 중요 데이터는 동기, 일반 데이터는 비동기 처리로 절충

⸻

2. 멀티 마스터 복제 vs 싱글 마스터 복제

싱글 마스터(Single-Master):
	- 한 노드만 쓰기 가능, 나머지는 읽기 전용
	- 구조 간단, 일관성 우수, 확장성 제한

멀티 마스터(Multi-Master):
	- 여러 노드에서 쓰기 가능, 지역별 분산 쓰기 지원
	- 충돌 해결 필요, 복잡성 증가
	- 예: Conflict-Free Replication, Vector Clock 기반 충돌 조정

⸻

3. Apache Kafka와 DB 연동 방식 및 스트리밍 활용 사례

연동 방식:
	- CDC(Change Data Capture) 도구로 DB 변경을 Kafka Topic에 발행
	- Kafka Connect, Debezium, Flink 연동
	- DB → Kafka → 실시간 분석 or DB 적재 구조

활용 사례:
	- 실시간 주문 처리, 모니터링, 로그 분석, IoT 데이터 처리

⸻

4. 블록체인 기반 데이터 저장 기술 vs 기존 분산 DB

블록체인:
	- 변조 불가, 모든 트랜잭션을 체인으로 기록
	- 탈중앙화, 신뢰 기반
	- 속도 및 질의 기능 제한

기존 분산 DB:
	- CRUD 중심, 빠른 질의 응답 가능
	- 중앙화된 관리
	- 속도 및 유연성 우위

차이점 요약:
블록체인은 투명성과 무결성, 분산 DB는 성능과 유연성 중심

⸻

5. 데이터베이스와 AI/머신러닝 연계 기술 및 활용 사례

연계 기술:
	- DB에 저장된 데이터를 ML 파이프라인에 직접 연동
	- AutoML, AI 쿼리 최적화, 예측형 질의처리, 스마트 인덱싱

활용 사례:
	- AI 기반 추천 시스템, 사기 탐지, 트렌드 분석, 튜닝 자동화

예: BigQuery ML, SQL Server Machine Learning Services

⸻

6. 엣지 컴퓨팅 환경에서 데이터베이스의 역할과 실시간 처리 방안

역할:
	- 디바이스 근처에서 데이터 수집·저장·처리
	- 경량 DB 사용(SQLite, InfluxDB 등)

실시간 처리 방안:
	- Local DB + Stream 분석 + 비동기 동기화 → 중앙 서버
	- MQTT, Kafka, Flink 등과 연계

⸻

7. 양자 데이터베이스의 개념과 기존 DB와의 차이

양자 데이터베이스:
	- 양자 컴퓨팅 기반으로 데이터 검색, 인덱싱, 트랜잭션 등 수행
	- Grover’s Algorithm 기반 빠른 탐색 가능

기존 DB와 차이점:
	- 기존은 순차 또는 병렬 처리, 양자는 양자 병렬성 기반 처리
	- 보안, 구조 설계, 튜닝 방식 모두 재정립 필요


1. IT 및 데이터베이스 관리에서 ESG 트렌드가 미치는 영향

Environmental:
	- 데이터센터의 에너지 효율 최적화 요구 증가
	- 탄소배출 모니터링을 위한 친환경 로깅 및 추적 기능 내재화

Social:
	- 개인정보 보호, 데이터 접근의 윤리성과 투명성 강화
	- 사용자 권리 중심의 데이터 프라이버시 설계

Governance:
	- 감사 추적(Audit), 규제 준수(Compliance), 데이터 보존 정책의 체계적 관리 필요
	- ESG 보고용 데이터 모델 및 추적 체계 강화

⸻

2. IoT 데이터 관리 및 실시간 분석을 위한 DB 최적화 전략

특징:
	- 고빈도 데이터 발생, 센서 기반 실시간 스트림

전략:
	- Time-Series DB 사용 (예: InfluxDB, TimescaleDB)
	- 파티셔닝, TTL(보존 기간 설정), 압축 저장
	- 엣지 DB 활용 → 실시간 처리 후 클라우드에 전송
	- 스트리밍 플랫폼(Kafka, Spark Streaming)과의 연계 필수

⸻

3. NewSQL 개념과 RDBMS, NoSQL과의 차이

NewSQL:
	- RDBMS의 ACID 보장, NoSQL의 수평 확장성 결합한 차세대 DB

특징:
	- SQL 지원, 트랜잭션 무결성, 분산 처리, 고가용성 제공

차이점:
	- RDBMS: 수직 확장, 안정성 우위
	- NoSQL: 유연한 스키마, 성능/확장성 중심
	- NewSQL: 둘의 장점 융합

예: CockroachDB, Google Spanner, TiDB

⸻

4. DB에서 AR/VR 기술과의 연계 가능성

연계 방안:
	- 사용자 위치, 행동 로그, 객체 상태 등 실시간 상태 데이터를 DB에서 관리
	- 3D 모델 정보, 환경 변수 등 복합 데이터 관리 필요

요구사항:
	- 실시간 응답속도, 고속 질의, Spatial/Graph DB 활용
	- 쿼리 최적화 및 고성능 스트리밍 구조 필수

⸻

5. 데이터베이스와 메타버스 기술의 관계 및 융합 가능성

역할:
	- 디지털 자산, 사용자 상태, 경제 활동, 관계망 등 메타데이터 관리
	- 대규모 사용자 동시 접속을 위한 수평 확장형 DB 구조 필수

기술 적용:
	- Graph DB로 관계/이벤트 표현
	- Time-Series DB로 실시간 로그 처리
	- Blockchain DB로 디지털 자산 기록 가능

⸻

6. AI 기반 데이터 거버넌스의 개념과 활용 사례

개념:
	- AI를 활용해 데이터 분류, 보안 정책 적용, 품질 평가, 메타데이터 자동화 수행

활용:
	- 민감 정보 자동 식별 및 마스킹 적용
	- 비정형 데이터 자동 태깅 및 분류
	- 정책 위반 탐지, 감사 로그 분석 자동화

도구:
	- Informatica CLAIRE, Microsoft Purview, IBM Watson Knowledge Catalog

⸻

7. 향후 10년간 데이터베이스 기술 발전 방향

예상 트렌드:
	- 자율 운영 DBMS 확대 (AI + ML 기반 튜닝)
	- HTAP, NewSQL 확산 → 실시간 분석 + 트랜잭션 통합
	- ESG 대응 DB 기능 강화 (감사, 보존, 친환경 운영)
	- 양자 내성 암호, 프라이버시 강화 기술(PETs) 내재화
	- 분산 처리 + 실시간 연산 + 멀티 클라우드 최적화 구조 정착


1. 계층형 데이터 모델과 네트워크 데이터 모델의 차이

계층형 모델 (Hierarchical Model):
	- 트리 구조로 구성된 데이터 모델
	- 부모-자식 관계가 명확, 1:N 관계만 표현 가능
	- 예: IMS(IBM)

네트워크 모델 (Network Model):
	- 그래프 구조로, 레코드 간 M:N 관계 표현 가능
	- 다중 경로, 다중 관계 지원 → 복잡한 관계 표현에 적합
	- 예: CODASYL

차이점 요약:
계층형은 단순하고 빠르나 유연성 부족,
네트워크 모델은 유연하나 복잡성과 관리 비용이 높음

⸻

2. 데이터 정규화 과정에서 발생하는 이상(Anomaly)의 종류와 해결 방안

삽입 이상 (Insertion Anomaly):
	- 불완전한 정보로는 삽입 불가
	- 예: 고객 정보 없이 주문 삽입 불가

삭제 이상 (Deletion Anomaly):
	- 하나의 정보 삭제가 다른 의미 있는 데이터 손실로 이어짐
	- 예: 주문 삭제 시 고객 정보도 삭제됨

갱신 이상 (Update Anomaly):
	- 중복된 데이터 변경 시 일부만 수정되어 불일치 발생
	- 예: 고객 전화번호 변경이 일부 행에만 반영됨

해결 방안:
	- 정규화(1NF~3NF 이상)를 통해 데이터 중복을 제거하고 종속성 분리

⸻

3. 실시간 데이터 처리를 위한 OLAP과 OLTP의 차이

OLTP (Online Transaction Processing):
	- 실시간 트랜잭션 처리, 빠른 삽입/갱신/삭제
	- 정규화된 스키마, 성능 위주
	- 예: 은행, 쇼핑몰

OLAP (Online Analytical Processing):
	- 대용량 데이터를 기반으로 분석/집계 중심 질의 처리
	- 비정규화 또는 스타 스키마, 조회 최적화
	- 예: BI, 경영 분석

⸻

4. E-R 다이어그램에서 약한 엔티티와 강한 엔티티의 차이

강한 엔티티(Strong Entity):
	- 고유한 기본키(Primary Key)를 가지고 독립적으로 존재 가능
	- 예: 학생(Student)

약한 엔티티(Weak Entity):
	- 고유 식별자가 없고, 다른 엔티티에 의존(외래키)
	- 식별 관계(Identifying Relationship)를 통해 구분
	- 예: 보험가입자(Dependent)

⸻

5. 데이터 스키마의 개념과 주요 유형

개념:
	- 데이터베이스의 구조와 정의를 기술한 청사진

주요 유형:
	- 개념적 스키마: 전체 구조, 엔터티 간 관계 (ERD 수준)
	- 논리적 스키마: 테이블, 컬럼, 관계 등의 논리 모델
	- 물리적 스키마: 저장 방식, 인덱스, 파티셔닝 등 물리 구현 정보

⸻

6. 서브쿼리와 조인의 차이 및 성능 최적화 방안

서브쿼리:
	- 쿼리 내에 포함된 하위 쿼리
	- 중첩 수행, 인라인 뷰 등 다양한 방식
	- 단점: 비효율적 반복 실행 가능성 있음

JOIN:
	- 두 개 이상의 테이블을 공통 컬럼 기준으로 병합
	- 일반적으로 서브쿼리보다 빠름

최적화 팁:
	- 서브쿼리를 JOIN으로 변환
	- 인덱스 활용 가능한 형태로 재작성
	- EXISTS, IN 조건 적절히 선택

⸻

7. B-Tree와 Hash Index의 차이

B-Tree Index:
	- 정렬된 트리 구조, 범위 질의(RANGE), 정렬 질의에 유리
	- 일반적인 인덱스 방식, 대부분의 DB에서 기본 사용

Hash Index:
	- 해시 함수를 이용한 위치 계산 → 동일 값 검색에 최적
	- 범위 질의, 정렬 질의에는 부적합

⸻

8. 데이터 파티셔닝 전략과 성능 개선

전략:
	- Range, List, Hash, Composite 파티셔닝 방식 활용
	- 테이블을 물리적으로 분할해 I/O 분산과 병렬 처리 가능

성능 개선:
	- 쿼리 성능 향상 (Partition Pruning)
	- 백업/복구, 유지보수 단위 최소화
	- 대용량 테이블 관리 편의성 증가


1. 컬럼 기반 저장 방식(Column-Oriented Storage)의 개념과 활용 방안

개념:
	- 데이터를 행(Row) 단위가 아닌 열(Column) 단위로 저장하는 방식
	- 특정 열만 접근 시 I/O를 최소화할 수 있어 분석 작업에 효율적

활용 방안:
	- OLAP, 데이터 웨어하우스, BI 시스템에 적합
	- 컬럼별 압축 효율이 높아 저장 공간 절감 가능
	- 대표 시스템: Amazon Redshift, Google BigQuery, Apache Parquet

⸻

2. 이벤트 소싱(Event Sourcing)의 개념과 CRUD 모델과의 차이

개념:
	- 상태 변경을 직접 저장하지 않고, 모든 변경 이벤트를 저장
	- 최종 상태는 이벤트 로그를 재구성(Replay)해서 생성

CRUD 모델과의 차이:
	- CRUD는 데이터의 최종 상태만 저장, 변경 이력 손실
	- Event Sourcing은 모든 변경을 기록하므로 감사 추적, 복원, 분석에 유리

활용 사례:
	- 금융 거래 시스템, IoT, CQRS 패턴 기반 시스템

⸻

3. 데이터 품질의 핵심 요소
	- 정확성(Accuracy): 데이터 값이 현실과 일치
	- 일관성(Consistency): 데이터 간 논리적 정합성 유지
	- 무결성(Integrity): 제약조건 및 참조 관계 보장
	- 적시성(Timeliness): 최신 정보가 반영되어 있는가
	- 완전성(Completeness): 누락 없이 모든 데이터가 존재하는가

이 모든 요소는 비즈니스 신뢰성과 분석 정확도에 직접 영향

⸻

4. 무결성 보장을 위한 주요 기법과 사례

기법:
	- 기본키/외래키/유니크 제약조건, 도메인 제약
	- 트리거(Trigger), 저장 프로시저를 통한 자동 검증
	- 애플리케이션 레벨 검증 로직 강화

사례:
	- 외래키로 주문에 없는 고객 ID 입력 방지
	- 도메인 제약으로 나이 필드 음수 입력 차단

⸻

5. 데이터 레지스트리 vs 데이터 레퍼지토리

데이터 레지스트리(Data Registry):
	- 데이터 정의 중심, 메타데이터 및 표준 관리
	- 어떤 데이터가 존재하는지의 카탈로그 역할

데이터 레퍼지토리(Data Repository):
	- 실제 데이터가 저장되는 물리적/논리적 저장소
	- 백업, 아카이브, 운영 DB 등을 포함

차이점:
레지스트리는 관리 체계, 레퍼지토리는 보관 위치

⸻

6. 메타데이터 관리의 중요성 (데이터 거버넌스 관점)

중요성:
	- 데이터 이해도 향상, 재사용성 확보
	- 데이터 흐름 추적(Data Lineage), 품질 관리 가능
	- 정책 기반 보안, 감사 로그와의 연계 가능

주요 구성 요소:
	- 기술 메타데이터: 스키마, 테이블 구조
	- 비즈니스 메타데이터: 정의, 목적, 담당 부서
	- 운영 메타데이터: 변경 이력, 접근 기록

⸻

7. MDM에서 발생할 수 있는 문제점과 해결 방안

문제점:
	- 중복 데이터, 소스 간 충돌, 정의 불일치
	- 부서 간 데이터 책임 불분명
	- MDM 시스템 구축 비용 및 복잡도

해결 방안:
	- 데이터 표준화와 통합 규칙 수립
	- 골든 레코드(Golden Record) 정의
	- 데이터 소유권과 책임 체계 명확화

⸻

8. 데이터 라인리지(Data Lineage)의 개념과 주요 활용 사례

개념:
	- 데이터가 어디서 생성되어, 어떻게 변환되고, 어디로 전달되었는지 추적하는 기록

활용 사례:
	- 규제 대응(예: GDPR, 금융감독원 감사)
	- ETL 오류 분석 및 근본 원인 분석(RCA)
	- 데이터 품질 추적 및 자동화된 영향 분석(Impact Analysis)


1. 기업 데이터 아키텍처의 주요 구성 요소

데이터 모델(Data Model)
기업의 정보 자산을 구조화하여 표현한 것으로, 개념적 모델(ERD), 논리적 모델, 물리적 모델로 구분된다. 이는 데이터 간 관계, 속성, 제약 조건을 정의하여 일관성 있게 데이터 구조를 유지하도록 돕는다.

데이터 저장소(Data Storage)
실제 데이터를 저장하는 공간으로, 관계형 데이터베이스, NoSQL, 데이터 웨어하우스, 데이터 레이크 등이 있다. 각 저장소는 목적과 용도에 따라 구조 및 접근 방식이 다르며, 신속한 데이터 접근과 보안이 고려된다.

데이터 흐름(Data Flow)
데이터가 생성, 전송, 처리, 저장되는 전 과정을 뜻한다. 데이터 파이프라인, ETL/ELT 과정, 메시징 시스템(Kafka 등)을 통해 실시간 또는 배치로 데이터가 이동하며, 흐름을 시각화하고 관리하기 위해 데이터 흐름 다이어그램(DFD)이 사용된다.

⸻

2. 데이터 감사 로그를 활용한 이상 탐지

감사 로그(Audit Log)
시스템 내에서 발생하는 사용자 활동, 데이터 접근, 변경 이벤트 등을 기록하는 로그이다. 비정상적인 패턴을 탐지하기 위해 활용된다.

이상 탐지 기법
	- 시계열 분석: 정상 범위의 패턴과 벗어난 로그를 구분
	- 규칙 기반 탐지: 사전에 정의된 규칙(예: 야간 접근, 대량 삭제 등)에 위배되는 로그 탐지
	- 머신러닝 기반 탐지: 지도/비지도 학습 알고리즘을 사용하여 이상 행위를 자동 분류

활용 예시
불법 접근, 데이터 유출, 권한 초과 사용 등의 보안 위협 감지 및 내부 통제 강화

⸻

3. CEP(Complex Event Processing)의 개념과 활용

CEP 개념
스트리밍 데이터에서 의미 있는 이벤트 패턴을 실시간으로 탐지하는 기술로, 다수의 이벤트를 조합하여 고차원의 이벤트를 추론한다.

활용 방안
	- 금융: 이상 거래 탐지
	- 제조: 센서 데이터를 통한 고장 예측
	- 유통: 고객 행동 분석
	- IoT: 복합 이벤트 기반 알림 시스템

주요 기술 요소
패턴 정의 언어, 윈도잉(Windowing), 이벤트 시간 관리, 상태 추적

⸻

4. 데이터 정제 vs 데이터 프로파일링

데이터 정제(Cleansing)
오류, 결측치, 이상값, 중복, 불일치 데이터를 제거하거나 수정하여 품질을 향상시키는 과정이다. 예: 전화번호 포맷 통일, null 값 대체, 오타 수정 등.

데이터 프로파일링(Profiling)
데이터의 통계적 특성과 품질 상태를 분석하는 과정이다. 예: 유효값 분포, 패턴 일관성, 유일성 체크 등을 통해 정제가 필요한 포인트를 사전 파악한다.

차이점
프로파일링은 데이터 상태를 진단하고, 정제는 실제로 데이터를 수정하는 단계다.

⸻

5. Lazy Loading vs Eager Loading

Lazy Loading
필요할 때 데이터를 불러오는 방식으로, 초기 로딩 속도는 빠르지만 추후 여러 번 데이터 요청이 발생할 수 있다. 예: 게시글 클릭 시 댓글을 불러옴.

Eager Loading
관련된 모든 데이터를 한 번에 불러오는 방식으로, 초기 로딩은 느릴 수 있으나 추가 쿼리 없이 모든 데이터를 사용할 수 있다. 예: 게시글과 댓글을 함께 조회.

비교 및 활용
Lazy는 리소스를 절약하되 성능 이슈가 있을 수 있고, Eager는 응답 속도는 빠르지만 메모리 사용이 많아질 수 있다. 상황에 따라 선택이 필요하다.

⸻

다음 블럭을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스에서 실행 계획(Execution Plan) 분석을 위한 주요 도구(예: EXPLAIN, SQL Trace 등)를 설명하시오.
- 인덱스 튜닝(Index Tuning) 과정에서 발생할 수 있는 성능 저하 문제와 해결 방안을 설명하시오.
- NoSQL 데이터베이스의 성능 최적화를 위한 주요 기법을 설명하시오.
- OLTP와 OLAP 시스템에서 데이터 모델링 최적화 전략의 차이를 설명하시오.
  - 좋습니다. 두 번째 블럭의 질문들에 대해 서술형으로 카테고리화하여 설명드릴게요.

⸻

6. 실행 계획(Execution Plan) 분석 도구

EXPLAIN / EXPLAIN PLAN
SQL 쿼리가 어떻게 실행될지를 미리 분석하여, 어떤 인덱스를 사용하는지, 테이블 스캔 여부, 조인 방식 등을 보여주는 도구이다. MySQL, PostgreSQL, Oracle 등에서 모두 제공하며, 실행 계획을 통해 병목 지점을 파악할 수 있다.

SQL Trace / TKPROF (Oracle)
쿼리 실행 시간, I/O, CPU 사용량 등을 로그로 기록해 상세한 성능 분석을 가능하게 하는 도구다. 실제 실행 시간 기반의 성능 문제 분석에 적합하다.

AUTOTRACE / AWR / SQL Monitor
Oracle 등에서는 자동 추적, 워크로드 리포트, 실시간 SQL 모니터링 기능을 통해 쿼리 성능을 진단할 수 있다.

⸻

7. 인덱스 튜닝 시 성능 저하 문제와 해결 방안

문제 발생 원인
	- 과도한 인덱스 생성으로 DML 성능 저하
	- 선택도 낮은 컬럼에 인덱스 생성으로 효과 없음
	- 인덱스 스캔 대신 테이블 스캔 발생
	- 인덱스 조합이 불적절하여 쿼리 조건과 일치하지 않음

해결 방안
	- 사용되지 않는 인덱스 제거
	- 선택도 높은 컬럼 기준 인덱스 설계
	- 복합 인덱스 최적화
	- 쿼리 리팩토링을 통한 인덱스 사용 유도
	- 통계 정보 최신화로 옵티마이저 성능 향상

⸻

8. NoSQL 데이터베이스 성능 최적화 기법

데이터 모델링 최적화
관계형 모델과 달리, NoSQL은 쿼리 패턴에 따라 설계되므로 중복 허용, 비정규화 구조로 설계하는 것이 일반적이다.

Sharding (수평 분할)
데이터를 여러 서버에 나눠 저장하여 읽기/쓰기 부하를 분산시킨다. MongoDB, Cassandra 등에서 많이 사용된다.

캐싱(Caching)
Redis, Memcached 등의 인메모리 캐시를 사용하여 반복되는 읽기 부하를 줄일 수 있다.

쓰기 최적화
Batch Write, TTL(Time-To-Live), Write Concern 설정 등을 통해 성능과 안정성의 균형을 조절한다.

⸻

9. OLTP vs OLAP 데이터 모델링 전략 차이

OLTP (Online Transaction Processing)
	- 목적: 빠른 트랜잭션 처리
	- 모델링: 정규화 중심
	- 구조: 많은 테이블과 조인
	- 데이터량: 적고 빈번한 읽기/쓰기

OLAP (Online Analytical Processing)
	- 목적: 대규모 분석, 통계
	- 모델링: 비정규화(Denormalization), 스타/스노우플레이크 스키마
	- 구조: Fact + Dimension 모델
	- 데이터량: 많고 주로 읽기 위주

차이점 요약
OLTP는 정합성 유지와 트랜잭션 속도에 집중하고, OLAP은 분석 효율성을 위해 비정규화 및 요약 중심 설계를 한다.

⸻

계속해서 다음 블럭을 보시려면 “다음”이라고 입력해 주세요.

- OLAP에서 MOLAP, ROLAP, HOLAP의 개념과 차이를 설명하시오.
- 데이터베이스 성능을 높이기 위한 Connection Pooling 기법의 개념과 활용 방안을 설명하시오.
- Materialized View와 일반 View의 차이점과 성능 최적화 방안을 설명하시오.
- 데이터베이스에서 비정규화(Denormalization)를 적용해야 하는 경우와 장단점을 설명하시오.
  - 좋습니다. 세 번째 블럭의 질문들에 대해 서술형으로 정리해서 설명드릴게요.

⸻

10. OLAP에서 MOLAP, ROLAP, HOLAP의 개념과 차이

MOLAP (Multidimensional OLAP)
	- 다차원 큐브 형태로 데이터를 저장
	- 성능이 매우 빠르며 응답 속도가 뛰어남
	- 데이터 전처리와 집계가 필수
	- 대용량 처리에 한계가 있음
	- 대표 솔루션: Microsoft SSAS, Cognos TM1

ROLAP (Relational OLAP)
	- 관계형 DB 위에서 OLAP 기능을 수행
	- 대용량 처리에 유리하며 실시간 데이터 반영 가능
	- 성능이 느릴 수 있음
	- SQL 기반 분석으로 유연성 높음

HOLAP (Hybrid OLAP)
	- MOLAP과 ROLAP의 장점을 결합
	- 집계 데이터는 큐브에 저장(MOLAP), 상세 데이터는 RDBMS에서 조회(ROLAP)
	- 성능과 확장성의 균형을 맞춤

⸻

11. Connection Pooling 기법의 개념과 활용 방안

개념
DB 연결을 미리 생성해 풀(Pool)에 보관하고, 클라이언트 요청 시 연결을 재사용하는 방식이다. 새로운 연결을 매번 생성하는 오버헤드를 줄여준다.

활용 방안
	- 웹 서버 또는 애플리케이션 서버에서 DB 접근이 빈번할 때 사용
	- Tomcat, HikariCP, c3p0 등에서 지원
	- 커넥션 최소/최대 수, 유휴 시간 설정을 통한 성능 조절
	- 잘못된 커넥션 반환 방지(Timeout, Validation Query 등)

장점
응답 시간 단축, 리소스 효율성, 연결 수 제한 가능

⸻

12. Materialized View vs 일반 View

일반 View
	- 실제 데이터를 저장하지 않고, 정의된 쿼리로 동작
	- 항상 최신 데이터를 조회
	- 성능이 느릴 수 있음 (특히 복잡한 조인 포함 시)

Materialized View
	- 쿼리 결과를 물리적으로 저장
	- 주기적으로 새로고침(Refresh) 가능
	- 빠른 조회가 가능하나, 데이터 정합성 유지에 주의 필요
	- 데이터 변경 발생 시 수동 또는 자동 갱신 필요

성능 최적화 활용
복잡한 분석 쿼리를 사전에 계산하여 저장함으로써 OLAP이나 리포팅에서 사용 시 응답 속도를 크게 향상시킴

⸻

13. 비정규화 적용 시점과 장단점

적용 시점
	- 조인이 많은 쿼리에서 성능이 저하될 때
	- 읽기 위주의 시스템에서 조회 속도 향상이 필요할 때
	- 분석 시스템(OLAP)이나 대시보드 구현 시
	- 캐시성 데이터가 자주 사용될 때

장점
	- 조회 성능 향상
	- 쿼리 단순화
	- 조인 최소화

단점
	- 데이터 중복으로 인한 저장 공간 증가
	- 데이터 정합성 유지 어려움
	- 변경 작업 시 여러 테이블 동시 갱신 필요


14. Dimensional Modeling과 Fact Table 설계 기법

Dimensional Modeling
데이터 웨어하우스에서 분석 성능을 높이기 위해 사용하는 모델링 방식으로, 데이터의 의미적 구조를 쉽게 파악하고 쿼리하기 위해 스타 스키마 또는 스노우플레이크 스키마 형태로 설계된다.

구성 요소
	- Fact Table(사실 테이블): 측정값(매출, 수량 등)을 저장하며, 수치적 데이터가 주로 포함된다. 각 Dimension Table의 키를 외래키로 가짐.
	- Dimension Table(차원 테이블): 분석 기준이 되는 속성 정보(날짜, 제품, 고객 등)를 저장.

설계 기법
	- 정규화보다는 조회 성능을 고려한 비정규화 중심
	- Fact Table은 가능한 숫자형, 집계 대상 중심
	- Dimension Table은 의미 있고 분석 가능한 속성 제공

⸻

15. Snapshot Isolation의 개념과 활용 사례

개념
트랜잭션이 시작된 시점의 데이터 스냅샷을 읽고, 그 상태를 기반으로 작업을 수행하도록 하는 격리 수준이다. 다른 트랜잭션의 변경 사항이 반영되지 않아 일관된 읽기를 보장한다.

특징
	- MVCC(Multi-Version Concurrency Control)를 기반으로 함
	- Dirty Read, Non-repeatable Read 방지
	- 갱신 충돌 시 커밋 단계에서 오류 발생

활용 사례
	- 읽기 일관성이 중요한 리포팅 시스템
	- 실시간 분석 시스템
	- PostgreSQL, Oracle, SQL Server 등에서 지원

⸻

16. 데이터베이스의 I/O 병목 현상 원인과 해결 방안

원인
	- 대량의 순차 또는 랜덤 디스크 접근
	- 인덱스 미사용으로 인한 풀 스캔
	- 비효율적인 쿼리 구조
	- 메모리 부족으로 인한 디스크 스와핑
	- 동시 접근 증가로 인한 경합

해결 방안
	- 인덱스 최적화 및 실행 계획 분석
	- 디스크 I/O를 줄이기 위한 캐싱 활용
	- SSD 도입 등 저장장치 성능 향상
	- 쿼리 튜닝 및 데이터 파티셔닝
	- 병렬 처리 및 백그라운드 작업 분리

⸻

17. 로그 기반 복구(Log-Based Recovery)의 개념과 장단점

개념
트랜잭션 처리 중 로그를 남기고, 시스템 장애 발생 시 로그를 기반으로 Rollback 또는 Rollforward를 수행하여 데이터의 일관성과 무결성을 복구하는 방식이다.

방식
	- Redo 로그: 커밋된 트랜잭션을 재실행
	- Undo 로그: 미커밋 트랜잭션을 취소

장점
	- 정전, 장애 발생 시 신속한 복구
	- 트랜잭션 단위의 일관성 유지
	- 병행성과 복구 기능의 조화

단점
	- 로그 기록으로 인한 성능 저하 가능
	- 로그 저장소의 손상 시 복구 어려움
	- 로그 크기 관리 필요


18. 대규모 데이터베이스 마이그레이션 시 고려 요소와 전략

고려 요소
	- 데이터 무결성 유지: 소스와 대상 간의 스키마/데이터 일치 여부 확인
	- 데이터 정합성 검증: 마이그레이션 후 검증 절차 필수
	- 다운타임 최소화: 시스템 가동 중 마이그레이션 고려 시 무중단 전략 필요
	- 성능 영향 최소화: 운영 중 시스템에 미치는 영향 고려
	- 보안 및 권한 이관: 사용자 계정, 접근 제어 정보도 함께 이관 필요
	- 이중화 전략: 복제 환경에서 점진적 전환(Blue-Green, Canary 등)

전략
	- ETL 도구 활용: Talend, Informatica, AWS DMS 등
	- 병렬 처리 및 증분 이관: 데이터 양이 많은 경우 단계별 이전
	- 사전 테스트 환경 구성: Dry-run을 통해 문제 사전 발견
	- 롤백 플랜 준비: 오류 발생 시 원복 가능한 구조 설계

⸻

19. 머신러닝 기반 이상 탐지를 활용한 DB 장애 예측

개념
과거 시스템 로그, 메트릭, 트랜잭션 이력 등으로부터 학습한 모델을 기반으로 장애 징후를 사전에 감지하고 알림을 제공하는 방식이다.

적용 기법
	- 지도 학습: 장애 로그 라벨링을 기반으로 정상/비정상 분류
	- 비지도 학습: 클러스터링(K-means)이나 밀도기반 탐지(DBSCAN)로 이상 탐지
	- 시계열 예측: LSTM, ARIMA 모델 등을 통해 성능 저하 징후 탐지

활용 예시
CPU 이상 사용, 쿼리 응답 시간 급증, I/O 병목 패턴 등을 학습하여 사전 조치 가능

⸻

20. Failover와 Switchover의 차이

Failover (장애 조치)
	- 비정상 상황(서버 장애 등)에서 자동 또는 수동으로 대기 시스템으로 전환
	- 고가용성(HA)을 위한 핵심 기술
	- 무중단 서비스를 위한 자동화된 복구 메커니즘 포함

Switchover (계획된 전환)
	- 유지보수, 점검, 업그레이드를 위해 정상적으로 주 시스템에서 보조 시스템으로 수동 전환
	- 다운타임이 짧고 통제된 환경에서 수행
	- 데이터 손실 없이 안전하게 서비스 전환 가능

차이점
Failover는 예기치 않은 장애 시 자동 수행되고, Switchover는 관리자가 의도적으로 수행한다는 점에서 구분된다.

⸻

21. Hot Backup vs Cold Backup

Hot Backup
	- 시스템이 운영 중일 때 백업
	- 실시간 서비스를 유지하면서 백업 가능
	- 데이터 일관성 확보를 위한 특별한 제어 필요
	- 데이터베이스 로그 기반 복구 기능이 필요함

Cold Backup
	- 시스템이 완전히 종료된 상태에서 백업
	- 데이터베이스 일관성이 자동 보장
	- 서비스 중단이 필요하며 다운타임 발생

비교
Hot Backup은 무중단이 장점이지만 복잡성이 높고, Cold Backup은 단순하지만 서비스 중단이 단점이다.


22. 고가용성(HA)을 위한 Active-Active와 Active-Passive 아키텍처의 차이

Active-Active 아키텍처
	- 모든 노드가 동시에 서비스를 제공
	- 부하 분산(Load Balancing) 구조로, 성능 향상과 장애 시 무중단 전환 가능
	- 데이터 동기화, 충돌 방지 로직이 복잡
	- 일반적으로 클러스터 환경에서 사용 (예: DB Cluster, Web Server Cluster)

Active-Passive 아키텍처
	- 하나의 노드는 서비스 제공(Active), 나머지는 대기(Passive)
	- 장애 발생 시 Passive 노드가 Active로 전환(Failover)
	- 관리 및 설정이 비교적 단순하지만 자원 활용률은 낮음
	- 금융, 제조 시스템 등 신뢰성과 일관성이 중요한 환경에 적합

차이점 요약
Active-Active는 성능과 확장성 중심, Active-Passive는 안정성과 관리 용이성 중심이다.

⸻

23. 분산 데이터베이스의 Split Brain 문제와 해결 방안

Split Brain 문제
네트워크 장애 등으로 인해 클러스터 노드 간 연결이 끊기고, 각 노드가 독립적으로 서비스를 계속 수행함으로써 데이터 불일치나 충돌이 발생하는 문제다.

해결 방안
	- Quorum 기반 구조: 과반수 노드의 동의가 있어야 동작하도록 제한
	- Stonith(Fencing): 문제가 있는 노드를 강제로 종료시켜 중복 처리 방지
	- Heartbeat 모니터링: 노드 상태를 주기적으로 체크하여 상태 판단
	- 리더 선출 알고리즘(Raft, Paxos 등): 일관성 있는 노드 결정 유지

⸻

24. 대규모 트랜잭션 시스템에서 데이터 정합성 유지 기법

ACID 보장
Atomicity, Consistency, Isolation, Durability 원칙을 통한 트랜잭션 정합성 확보

MVCC (Multi-Version Concurrency Control)
동시성 처리를 통해 읽기/쓰기 충돌을 방지하고, 정합성을 유지

분산 트랜잭션 관리 (2PC, 3PC)
여러 노드에 걸친 트랜잭션에서 Commit 여부를 조율하여 일관성 확보
단, 성능 저하와 장애 대응 복잡성이 존재

보상 트랜잭션(Saga 패턴)
장기 실행 트랜잭션이나 마이크로서비스 환경에서 정합성을 유지하기 위해 각 단계별 롤백 트랜잭션을 준비하는 방식

⸻

25. AutoML을 활용한 데이터베이스 자동 튜닝 개념과 활용

AutoML 기반 자동 튜닝
머신러닝을 통해 데이터베이스의 쿼리 성능, 인덱스 설정, 파라미터 최적화 등을 자동으로 추천하고 적용하는 기술이다.

활용 사례
	- 쿼리 실행 계획 자동 분석
	- 최적 인덱스 조합 자동 탐색
	- 리소스 사용 패턴 분석 및 파라미터 조정
	- Self-Tuning Database (예: Oracle Autonomous DB)

장점
DB 전문가의 개입 없이도 일정 수준의 성능 최적화 가능
지속적인 학습을 통해 시스템 환경 변화에 적응 가능

⸻

26. Federated Learning과 데이터베이스의 관계

Federated Learning(연합 학습)
각 장치나 서버가 로컬 데이터를 외부로 전송하지 않고 자체적으로 모델을 학습하고, 그 결과(모델 파라미터)만 중앙 서버에 전달하여 통합 학습을 수행하는 방식이다.

데이터베이스와의 연계
	- 개인정보 보호 기반 분석: 사용자 데이터를 중앙 DB에 모으지 않고도 머신러닝 모델을 구축
	- 분산 DB 환경: 여러 데이터 저장소에서 모델 학습을 분산하여 수행 가능
	- 의료, 금융 등 민감 데이터 처리 분야에서의 분석 수단

장점
데이터 프라이버시 보호, 네트워크 효율성 향상, 로컬 연산 최적화
기존 DB 시스템과 결합하여 개인정보 유출 없이 인사이트 추출 가능

1. Serverless Database의 개념과 기존 DB 운영 방식과의 차이

Serverless Database는 인프라 관리 없이 자동 확장되고, 사용량 기반으로 과금되는 데이터베이스 서비스입니다. 사용자는 스키마 설계와 쿼리에만 집중하며, 서버 프로비저닝, 유지보수, 스케일링 등은 클라우드 제공자가 자동으로 처리합니다.
대표 서비스: AWS Aurora Serverless, Google Cloud Spanner, Azure SQL Database Serverless

기존 운영 방식과의 차이점
	- 인프라 자동화: 기존에는 CPU, 메모리, 디스크 등을 직접 설정했지만, 서버리스는 필요에 따라 자동 확장/축소됨
	- 과금 구조: 기존은 고정 인스턴스 과금, 서버리스는 초 단위 사용량 기반
	- 운영 부담: 기존은 DBA가 패치, 백업, 확장 등을 수행, 서버리스는 대부분 자동 수행됨
	- 부하 적응성: 요청이 없을 경우 자동 일시 정지 기능으로 비용 최적화 가능

⸻

2. 데이터베이스에서 Zero Trust Security Model 개념과 적용 방안

Zero Trust는 “아무도 신뢰하지 않는다(Trust No One)“는 철학을 기반으로 한 보안 모델로, 내부 사용자나 시스템조차 인증과 권한 검증을 지속적으로 수행해야 한다는 원칙을 따릅니다.

적용 방안
	- 강력한 인증: MFA, SSO 도입
	- 세분화된 접근 제어: 최소 권한 원칙(Least Privilege), Row-Level Security
	- 접속 로그 분석: 실시간 모니터링 및 이상 탐지
	- 네트워크 보호: DB 접근은 VPN, 프록시, API Gateway 통해 제한
	- 데이터 암호화: 저장/전송 중 모두 암호화 적용

⸻

3. 데이터베이스와 강화 학습의 융합 가능성

강화 학습(Reinforcement Learning)은 에이전트가 환경과 상호작용하며 보상을 최대화하는 방향으로 학습하는 AI 기법입니다. 이를 데이터베이스 운영에 적용하면 다음과 같은 융합이 가능합니다.

융합 가능 분야
	- 자동 쿼리 최적화: 실행 계획 선택을 RL 기반으로 동적 학습
	- 리소스 할당: 메모리, 캐시, I/O 분배 정책 최적화
	- 인덱스 튜닝: RL로 생성/삭제할 인덱스를 자동 결정
	- 부하 예측 및 스케일링: 사용자 트래픽 패턴에 따라 사전 대응
	- 자율 운영 DB: Oracle Autonomous DB처럼 스스로 튜닝 및 최적화

⸻

4. Quantum-Safe Encryption(양자 내성 암호)의 개념과 활용 사례

양자 내성 암호는 양자 컴퓨터가 기존 공개키 암호(RSA, ECC 등)를 쉽게 깨는 문제에 대비하기 위한 암호 알고리즘입니다. 수학적으로 양자 알고리즘(Shor, Grover)에도 안전한 방식들이 연구되고 있습니다.

주요 알고리즘
	- 코드 기반 (McEliece)
	- 격자 기반 (Kyber, NTRU)
	- 해시 기반 (SPHINCS+)
	- 다변수 기반 (Rainbow)

활용 사례
	- 금융/공공기관의 장기 보존 데이터 보호
	- 클라우드 데이터 암호화
	- 암호화된 DB 컬럼 보호
	- 양자 대비 준비를 위한 하이브리드 암호 체계 적용

⸻

5. Data Lakehouse 아키텍처의 개념과 기존 Data Lake / Data Warehouse와의 차이

Data Lakehouse는 Data Lake의 확장성과 유연성, Data Warehouse의 정형 쿼리 성능과 트랜잭션 지원을 결합한 하이브리드 아키텍처입니다.

특징
	- 데이터는 Data Lake처럼 저장(S3, HDFS 등), 구조화된 접근은 Warehouse처럼 처리(Spark SQL, Delta Engine 등)
	- ACID 트랜잭션 지원
	- Metadata Layer (Hive Metastore, Delta Catalog 등)
	- BI/ML/Streaming 통합 분석 가능

차이점
	- Data Lake: 비정형 데이터 중심, 스키마 없음, 저렴하지만 느림
	- Data Warehouse: 정형 데이터 전용, 고속 분석 가능하지만 비싸고 유연성 부족
	- Lakehouse: 이 두 가지의 장점 결합, 범용 분석 플랫폼으로 진화 중

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- Web3 및 탈중앙화 데이터베이스(Decentralized Database)의 개념과 주요 특징을 설명하시오.
- 데이터베이스에서 API 기반 아키텍처(API-First Architecture)의 개념과 활용 방안을 설명하시오.
- 향후 데이터베이스 기술이 발전할 주요 트렌드와 예상되는 변화 사항을 설명하시오.
- ER 모델에서 일반화(Generalization)와 특수화(Specialization)의 차이를 설명하시오.
  - 좋습니다. 두 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

6. Web3 및 탈중앙화 데이터베이스(Decentralized Database)의 개념과 주요 특징

Web3 데이터베이스는 블록체인 기술 기반의 탈중앙화된 데이터 저장 및 관리 구조를 의미하며, 사용자 주권, 보안성, 투명성, 검열 저항성을 강조합니다.

탈중앙화 DB 개념
데이터가 중앙 서버가 아닌 여러 노드에 분산 저장되며, 각 노드는 독립적 권한을 가진다. 블록체인과 유사한 합의 알고리즘을 사용해 데이터 정합성을 확보한다.

주요 특징
	- 중앙 관리자 없음 (Trustless 구조)
	- IPFS, OrbitDB, BigchainDB 등 사용
	- 스마트 계약 기반의 접근 제어
	- 투명한 변경 이력 추적 및 검증 가능
	- DApp(분산 앱)과의 연계성 용이

⸻

7. 데이터베이스에서 API 기반 아키텍처(API-First Architecture)의 개념과 활용 방안

API-First Architecture는 시스템 또는 서비스 설계 시 API를 중심으로 구조화하고, 모든 데이터 접근을 API를 통해 수행하도록 설계하는 방식입니다.

개념 핵심
	- API 설계가 시스템 개발의 출발점
	- DB에 직접 접근하지 않고 API를 통해 간접 접근
	- API 문서 자동화(OpenAPI, Swagger 등)와 DevOps 연계 용이

활용 방안
	- 멀티 채널(웹/앱/IoT 등) 간 통합된 DB 접근 인터페이스 제공
	- 마이크로서비스 기반에서 DB 분리 및 경량화
	- API Gateway를 통한 보안 제어 및 로깅
	- 데이터 접근 감사, 권한 관리 유연화

⸻

8. 향후 데이터베이스 기술이 발전할 주요 트렌드와 변화

자율 운영 데이터베이스(Autonomous DB)
AI/ML 기반으로 자동 튜닝, 장애 복구, 보안 설정 등이 가능해지며 DBA의 역할이 점차 변화

Serverless + 분산 구조
리소스 관리에서 해방된 서버리스 기반 DB의 확산과 함께 글로벌 분산 환경을 자연스럽게 수용하는 구조로 전환 중

멀티모델 지원
관계형, 문서형, 그래프, 시계열 등 다양한 데이터 유형을 통합 처리하는 DBMS 등장

HTAP의 보편화
실시간 분석과 트랜잭션이 동시에 가능한 구조가 일반화되며, 분석-운영 간 경계가 사라짐

보안과 프라이버시 중심 DB
Zero Trust, Homomorphic Encryption, Secure Enclave, Differential Privacy 등이 데이터 저장계에 본격 도입됨

⸻

9. ER 모델에서 일반화(Generalization)와 특수화(Specialization)의 차이

일반화(Generalization)
여러 개의 하위 엔티티에서 공통 속성과 관계를 추출하여 상위 엔티티로 통합하는 과정이다.
예: 교수와 학생 → 사람(PERSON)이라는 상위 엔티티로 일반화

특수화(Specialization)
상위 엔티티를 속성이나 행동에 따라 하위 엔티티로 분리하는 과정이다.
예: 사람(PERSON) → 교수(PROFESSOR), 학생(STUDENT)으로 특수화

차이점 요약
	- 일반화는 상향식(bottom-up), 특수화는 하향식(top-down) 설계 방식
	- 모델링 목적에 따라 추상화(Generalization) 또는 세분화(Specialization)를 선택


10. EER(Enhanced Entity-Relationship) 모델과 기존 ER 모델의 차이

EER 모델은 기존 ER(Entity-Relationship) 모델을 확장한 개념으로, 복잡한 현실 세계를 더 정교하게 표현하기 위해 고급 데이터 모델링 개념을 도입한 모델입니다.

EER의 주요 확장 요소
	- Generalization / Specialization: 상위/하위 엔티티 개념 도입
	- Aggregation: 하나의 관계를 엔티티처럼 다시 관계에 참여시킬 수 있음
	- Category(Union Type): 서로 다른 엔티티를 통합하여 상위 엔티티 구성 가능

차이점 요약
기존 ER 모델은 단순 엔티티-관계 구조 중심, EER 모델은 상속, 추상화, 계층 구조 등 고급 개념을 포함하여 더 복잡한 데이터 구조를 설계할 수 있음

⸻

11. 정규화와 반정규화의 장단점 비교

정규화(Normalization)
	- 데이터 중복 제거, 무결성 유지, 이상(Anomaly) 방지
	- 변경·삽입·삭제 시 일관성 유지
	- 다수의 테이블 분할로 인한 조인 비용 증가 가능성 있음

반정규화(Denormalization)
	- 성능 향상, 조인 최소화
	- 읽기 중심 시스템에서 유리
	- 데이터 중복 및 정합성 유지 비용 발생
	- 쓰기 성능 저하나 데이터 이상 가능성 존재

요약
정규화는 무결성과 정합성, 반정규화는 성능 최적화에 초점을 두며, 시스템 성격(OLTP/OLAP)에 따라 선택

⸻

12. 도메인 무결성(Domain Integrity)의 개념과 적용 사례

도메인 무결성은 각 속성이 허용된 값 범위 내에서만 값을 가질 수 있도록 보장하는 제약 조건입니다. 즉, 컬럼의 데이터 형식, 길이, 허용값 등을 제한함으로써 데이터 품질을 확보합니다.

적용 사례
	- 숫자 범위 제한 (예: 나이 >= 0 AND 나이 <= 120)
	- 문자열 길이 제한 (예: 주민등록번호 13자리)
	- 열거형 제한 (예: 성별은 ‘M’ 또는 ‘F’)
	- NOT NULL, CHECK, DEFAULT 제약 조건 사용

⸻

13. Weak Entity(약한 엔티티)의 개념과 활용 방안

약한 엔티티(Weak Entity)는 자신만의 고유 식별자가 없고, 다른 엔티티(주 엔티티)의 식별자에 의존해야만 식별이 가능한 엔티티입니다.

특징
	- 주 엔티티의 기본키를 외래키로 가져오고, 이를 포함하여 자신의 복합키로 사용
	- 생명 주기가 주 엔티티에 종속됨
	- 식별 관계(Identifying Relationship)를 통해 연결됨

활용 예시
	- 주문 → 주문 항목
	- 계약 → 계약 조항
	- 환자 → 진료 기록 (진료 기록은 환자 ID와 일시가 함께 식별자 역할)

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 수평적 분할(Horizontal Partitioning)과 수직적 분할(Vertical Partitioning)의 차이를 설명하시오.
- 계층형 데이터베이스 설계와 네트워크형 데이터베이스 설계의 차이를 설명하시오.
- 데이터베이스에서 참조 무결성(Referential Integrity)의 개념과 적용 방안을 설명하시오.
- 6NF(Sixth Normal Form)의 개념과 기존 정규형(NF)과의 차이를 설명하시오.
  - 좋습니다. 네 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

14. 수평적 분할(Horizontal Partitioning)과 수직적 분할(Vertical Partitioning)의 차이

수평 분할(Horizontal Partitioning)
	- 데이터 행(Row) 단위로 분할
	- 예: 고객 테이블을 지역별로 분할 (서울 고객, 부산 고객 등)
	- 장점: 쿼리 대상 축소로 조회 성능 향상, 병렬 처리 용이
	- 단점: 전 범위 검색 시 모든 파티션 접근 필요

수직 분할(Vertical Partitioning)
	- 데이터 열(Column) 단위로 분할
	- 예: 고객 테이블에서 개인 정보와 로그인 정보 분리
	- 장점: I/O 최소화, 필요한 컬럼만 조회 가능
	- 단점: 여러 파티션을 조인해야 할 수 있음

요약
수평 분할은 데이터 양 분산, 수직 분할은 접근 빈도에 따른 속성 분리에 유리함

⸻

15. 계층형 DB 설계와 네트워크형 DB 설계의 차이

계층형 DB
	- 트리 구조(1:N 관계) 기반
	- 한 부모에 여러 자식 노드는 가능, 반대는 불가능
	- 예: IBM IMS
	- 장점: 빠른 접근, 단순한 구조
	- 단점: 유연성 부족, 복잡한 관계 표현 어려움

네트워크형 DB
	- 그래프 형태 구조로 M:N 관계 표현 가능
	- 복잡한 연결과 탐색 가능
	- 예: CODASYL DB
	- 장점: 유연한 관계 표현, 다대다 구조 처리 가능
	- 단점: 설계 및 관리 복잡, 구조 변경 어려움

요약
계층형은 단순/정형적 구조에 적합, 네트워크형은 복잡한 관계 모델링에 적합

⸻

16. 참조 무결성(Referential Integrity)의 개념과 적용 방안

참조 무결성은 외래키(Foreign Key)를 가진 테이블의 값이 반드시 참조되는 기본키(Primary Key)를 가진 테이블에 존재해야 한다는 규칙입니다.

적용 방안
	- 외래키 제약조건 설정 (FOREIGN KEY … REFERENCES)
	- 참조 대상 삭제/수정 시 동작 정의:
	- ON DELETE CASCADE: 참조 행도 함께 삭제
	- ON UPDATE SET NULL: 참조값이 변경되면 NULL 처리
	- DBMS 수준에서 위반 시 오류 발생

효과
데이터 정합성 유지, 잘못된 관계 데이터 방지, 무결성 보장

⸻

17. 6NF(Sixth Normal Form)의 개념과 기존 정규형과의 차이

6NF (제6정규형)는 데이터가 시간(Time), 버전, 상태와 같은 이력 관리가 필요한 속성에 따라 더 이상 분해할 수 없는 상태로 정규화된 형태입니다. Temporal Database 설계에서 주로 사용됩니다.

기존 NF와의 차이
	- 1NF ~ 5NF는 함수 종속성 및 조인 종속성 해소를 중심
	- 6NF는 비가변 속성 단위로 분리하여 변경 이력을 효율적으로 추적 가능하게 함
	- 관계의 원자성을 최대화한 형태

활용 사례
	- 금융거래, 의료기록 등 이력 데이터 처리
	- Temporal Database, Data Vault 모델 등에서 사용


18. 객체-관계형 데이터 모델(Object-Relational Model)의 개념과 활용 방안

객체-관계형 데이터 모델은 관계형 모델에 객체지향 개념(상속, 캡슐화, 사용자 정의 타입 등)을 결합한 데이터베이스 모델입니다. 관계형 DB의 성숙성과 객체지향의 유연성을 동시에 활용할 수 있도록 설계되었습니다.

주요 특징
	- 사용자 정의 타입(UDT) 지원
	- 테이블 안에 복합 타입 또는 컬렉션 저장 가능
	- 상속, 트리거, 메서드 등 객체 개념 내장
	- 관계형 질의 언어(SQL)에 객체 확장 기능 포함

활용 방안
	- 지리정보 시스템(GIS), CAD 시스템 등 복잡한 구조의 데이터 표현
	- Oracle, PostgreSQL 등의 ORDBMS에서 UDT 활용
	- 객체지향 프로그래밍 언어(Java, Python)와의 자연스러운 연계

⸻

19. Cardinality Estimation(기수 추정)의 개념과 성능 최적화에 미치는 영향

Cardinality Estimation은 SQL 실행 계획 수립 시, 조건절을 만족하는 데이터의 예상 행 수(카디널리티)를 예측하는 작업입니다.

중요성
	- 정확한 추정 → 적절한 인덱스 선택, 효율적 조인 순서 결정
	- 잘못된 추정 → 잘못된 실행 계획, 성능 저하 발생

영향 예시
	- 통계 정보가 오래되면 잘못된 추정 발생
	- 데이터 분포 불균형, NULL/중복값 많을 경우 부정확
	- 이를 보완하기 위해 히스토그램 통계나 실행 계획 피드백 기법 사용

⸻

20. 분산 데이터베이스에서 Load Balancing(부하 분산) 기법

개념
분산 환경에서 요청을 여러 노드에 고르게 분배하여 처리 성능을 향상시키고 병목을 방지하는 기술입니다.

기법 종류
	- Round Robin: 요청을 순서대로 분산
	- Least Connection: 가장 적은 연결을 가진 노드에 요청
	- Consistent Hashing: 샤드 키 기반으로 특정 노드에 요청 고정
	- Geo-aware Routing: 위치 기반 분산 처리

적용 사례
	- 클라우드 DB(Aurora, Cosmos DB)에서 읽기 Replica에 분산
	- Redis Cluster, Cassandra 등의 샤딩 기반 분산 처리

⸻

21. SCD(Slowly Changing Dimension)의 개념과 주요 유형

SCD는 데이터 웨어하우스에서 시간에 따라 값이 변경되는 차원 데이터를 관리하는 방식입니다. 고객 주소, 직책 등 변경 가능한 정보를 추적하는 데 사용됩니다.

주요 유형
	- Type 0: 변경 불가, 초기값 유지
	- Type 1: 변경 사항을 덮어쓰기 (히스토리 보존 안 함)
	- Type 2: 새로운 레코드 삽입하여 변경 이력 추적
	- Type 3: 이전 값과 현재 값만 저장 (컬럼으로 분리)
	- Hybrid Type: Type 1과 2를 혼합 사용

활용 예시
고객 주소 변경, 부서 이동, 제품 가격 변경 등 히스토리 관리 필요 시

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스에서 Sparse Index와 Dense Index의 차이를 설명하시오.
- 데이터베이스의 Query Execution Pipeline(쿼리 실행 파이프라인) 개념을 설명하시오.
- 데이터베이스에서 B+Tree와 LSM(Log-Structured Merge) Tree의 차이를 설명하시오.
- 데이터베이스에서 Query Optimizer가 수행하는 최적화 기법을 설명하시오.
  - 좋습니다. 여섯 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

22. Sparse Index와 Dense Index의 차이

Sparse Index
	- 데이터 파일의 일부 레코드에 대해서만 인덱스 항목을 보유
	- 일반적으로 블록당 첫 번째 레코드만 인덱싱
	- 장점: 인덱스 크기가 작아 저장 공간과 유지 비용이 적음
	- 단점: 정확한 위치 탐색 시 추가 검색 필요 (Block Scan)

Dense Index
	- 데이터 파일의 모든 레코드에 대해 인덱스 항목을 보유
	- 장점: 빠른 검색 속도, 바로 레코드 접근 가능
	- 단점: 인덱스 크기가 큼, 유지비용 높음

요약
Sparse는 공간 효율성, Dense는 검색 효율성에 중점이 있으며, 성능 요구에 따라 선택

⸻

23. Query Execution Pipeline(쿼리 실행 파이프라인)의 개념

쿼리 실행 파이프라인은 SQL 쿼리가 실행되기까지의 내부 단계들을 연속된 처리 흐름(Pipeline)으로 나타낸 것입니다. 각 단계는 다음 단계를 위해 데이터를 처리 및 전달합니다.

주요 단계
	1.	SQL 파싱: 문법 분석, 구문 트리 생성
	2.	옵티마이징(Optimizer): 실행 계획 생성
	3.	바인딩: 실제 테이블, 컬럼, 인덱스와 매핑
	4.	실행 계획 실행: 실제 데이터 처리 수행
	5.	결과 반환: 클라이언트에 응답

파이프라인 구조의 장점
	- 각 단계별 튜닝 가능
	- 병렬 처리 및 Lazy Evaluation 가능
	- 실행 계획 분석의 핵심

⸻

24. B+ Tree vs LSM Tree의 차이

B+ Tree
	- 전통적 인덱스 구조 (관계형 DB에서 주로 사용)
	- 균형 트리 구조, 디스크 I/O에 최적화
	- 읽기 성능 우수, 쓰기 시 노드 분할·병합 필요
	- 전체 키 정렬 유지

LSM Tree (Log-Structured Merge Tree)
	- 쓰기 성능 중심 구조 (NoSQL DB에 주로 사용)
	- 메모리에 쓰고 나중에 디스크에 병합(Flush, Compaction)
	- 쓰기 성능 우수, 읽기 성능은 보조 인덱스나 Bloom Filter 필요
	- Cassandra, RocksDB, LevelDB 등에서 사용

비교 요약
B+ Tree는 읽기 중심, LSM Tree는 쓰기 중심 시스템에 적합

⸻

25. Query Optimizer의 최적화 기법

쿼리 옵티마이저(Query Optimizer)는 SQL 문장을 다양한 실행 계획 중에서 가장 효율적인 것으로 변환하는 핵심 컴포넌트입니다.

주요 기법
	- 접근 경로 선택: 인덱스 스캔, 테이블 스캔 등 결정
	- 조인 순서 및 방식 결정: Nested Loop, Merge Join, Hash Join
	- Predicate Pushdown: 필터 조건을 최대한 빨리 적용
	- 서브쿼리 제거 및 변환: 서브쿼리를 조인으로 변환 등
	- 통계 기반 추정: Cardinality Estimation 기반으로 비용 계산

결과
잘 설계된 옵티마이저는 시스템 성능에 큰 영향을 미치며, 쿼리 튜닝 시 실행 계획 확인이 필수적


26. In-Memory 데이터베이스와 디스크 기반 DBMS의 차이점

In-Memory Database는 모든 데이터를 메모리(RAM)에 상주시켜 처리하는 데이터베이스로, 디스크 기반 DBMS에 비해 압도적인 속도를 제공합니다.

특징 및 차이점
	- 속도: In-Memory는 디스크 I/O 지연이 없어 초고속 처리 가능
	- 영속성: 디스크 DB는 기본적으로 영속성을 보장, In-Memory는 보조 저장소에 주기적 백업 필요
	- 복구: 디스크 기반은 복구 기능 내장, In-Memory는 장애 시 데이터 유실 우려
	- 사용 사례: Redis, SAP HANA는 실시간 분석 및 캐싱에 특화됨

요약
속도와 실시간 처리 중심이면 In-Memory, 안정성과 대용량 저장 위주면 디스크 기반이 유리함

⸻

27. Column-Oriented DBMS vs Row-Oriented DBMS

Column-Oriented DBMS (열 기반)
	- 데이터를 컬럼 단위로 저장
	- 특정 컬럼만 읽는 쿼리에 유리
	- 압축 효율이 높음
	- 예: Apache Cassandra, ClickHouse, Amazon Redshift

Row-Oriented DBMS (행 기반)
	- 데이터를 행 단위로 저장
	- 전체 행 단위 읽기/쓰기 작업에 유리
	- OLTP 시스템에 최적화
	- 예: MySQL, PostgreSQL, Oracle

요약
	- OLTP → Row-Oriented (트랜잭션 처리에 적합)
	- OLAP → Column-Oriented (분석 성능에 최적)

⸻

28. NoSQL, NewSQL, Graph DB의 성능 차이

NoSQL
	- 수평 확장성과 유연한 스키마 제공
	- 높은 쓰기 성능, 대규모 분산 처리에 강점
	- 예: MongoDB, Cassandra

NewSQL
	- NoSQL의 확장성과 RDBMS의 트랜잭션 지원(ACID)을 결합
	- OLTP + 확장성 동시 만족
	- 예: CockroachDB, Google Spanner

Graph DB
	- 노드와 간선으로 데이터 표현
	- 복잡한 관계 탐색 및 연산에 최적화
	- 예: Neo4j, Amazon Neptune

요약
	- 쓰기 성능: NoSQL > NewSQL > Graph
	- 관계 탐색 성능: Graph DB > RDBMS > NoSQL
	- 정합성 요구: NewSQL > RDBMS > NoSQL

⸻

29. 접근 제어 모델 – ACL, RBAC, ABAC의 차이

ACL (Access Control List)
	- 리소스 단위로 접근 가능한 사용자 목록을 관리
	- 단순하지만 대규모 환경에서 복잡성 증가
	- 예: 파일 시스템의 권한 설정

RBAC (Role-Based Access Control)
	- 역할(Role)에 따라 권한을 부여하고, 사용자는 역할을 할당받음
	- 조직 단위, 정책 중심 시스템에 적합
	- 예: 기업 내부 시스템의 직책 기반 접근 제어

ABAC (Attribute-Based Access Control)
	- 사용자, 리소스, 환경 등의 속성(Attribute) 기반으로 정책 적용
	- 세밀하고 동적인 제어 가능
	- 예: 시간대, 위치, 기기 상태에 따라 접근 제어

요약
	- ACL: 단순 자원-사용자 매핑
	- RBAC: 역할 중심의 계층적 권한
	- ABAC: 조건 기반의 유연한 정책 적용

⸻

계속해서 다음 블럭을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스에서 GDPR, CCPA와 같은 개인정보 보호법이 적용될 때 고려해야 할 사항을 설명하시오.
- 데이터베이스에서 Secure Enclave 기술을 활용한 보안 강화 방안을 설명하시오.
- 데이터베이스에서 Masking(마스킹)과 Tokenization(토큰화)의 차이를 설명하시오.
- 데이터 무결성을 보장하기 위한 체크섬(Checksum)과 해시(Hash) 기법을 설명하시오.
  - 좋습니다. 여덟 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

30. 개인정보 보호법(GDPR, CCPA) 적용 시 데이터베이스 고려 사항

GDPR(유럽)과 CCPA(캘리포니아)는 개인정보 수집, 처리, 저장, 삭제에 대한 엄격한 기준을 요구합니다. 데이터베이스는 이 법들을 준수하기 위해 다양한 기술적·관리적 조치를 갖춰야 합니다.

고려 사항
	- 데이터 최소 수집: 반드시 필요한 데이터만 저장
	- 익명화/가명화: 직접 식별이 불가능하도록 처리
	- 데이터 삭제 요청 대응: 데이터 삭제 및 추적 가능 구조 설계
	- 동의 기반 수집: 사용자 동의 여부 저장 및 증빙 가능
	- 로그 기록 및 감사 추적: 누가 언제 어떤 데이터에 접근했는지 기록
	- 전송 및 저장 시 암호화: 개인정보는 암호화 저장과 전송 필요

⸻

31. Secure Enclave 기술을 활용한 보안 강화 방안

Secure Enclave는 CPU 내부의 독립된 보안 공간에서 민감한 연산을 수행하는 기술로, 외부 접근이 원천 차단됩니다. Intel SGX, ARM TrustZone 등이 대표적입니다.

데이터베이스에서 활용 방안
	- 암호화 키의 안전한 저장 및 연산
	- 질의 시 민감 정보 필터링 및 연산 처리
	- 멀티테넌트 환경에서 데이터 보호 강화
	- 클라우드 환경에서 신뢰할 수 없는 OS/하이퍼바이저로부터 보호

장점
운영자조차 데이터를 볼 수 없으며, 클라우드에서도 높은 보안성 확보 가능

⸻

32. Masking과 Tokenization의 차이

Masking(마스킹)
	- 실제 데이터를 유사한 가짜 값으로 치환
	- 테스트용 DB, 분석 환경 등에서 활용
	- 원본 데이터와 매핑이 필요 없음
	- 예: 홍길동 → 김ㅇㅇ

Tokenization(토큰화)
	- 실제 데이터를 고유한 토큰 값으로 대체하고, 별도의 맵핑 테이블로 원본과 연결
	- 결제 정보, 주민번호 등 민감 정보 보호에 사용
	- 원복 가능성이 존재 (맵핑 DB 필요)
	- 예: 1234-5678-9012-3456 → TKN-8374-XY12

차이점 요약
	- 마스킹은 비복원형, 토큰화는 복원 가능
	- 마스킹은 테스트 목적, 토큰화는 실서비스 보호 목적

⸻

33. 무결성 보장을 위한 체크섬(Checksum)과 해시(Hash) 기법

Checksum
	- 데이터 블록의 값을 더하거나 계산하여 일정한 숫자를 만들어 전송 또는 저장
	- 주로 전송 중 데이터 손상 여부 검증
	- CRC, Adler-32 등이 대표

Hash
	- 데이터에 대해 고유한 해시 값을 생성하는 방식 (MD5, SHA-256 등)
	- 보안성, 변경 추적에 적합
	- 해시값 변경 → 데이터 위조 가능성 탐지

활용 예시
	- 로그 위변조 감지
	- 백업 데이터 정합성 확인
	- 파일 무결성 검증
	- 블록체인 트랜잭션 검증(Merkle Tree 기반 해시)

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스에서 보안 강화를 위한 암호화 키 관리(Key Management) 기법을 설명하시오.
- 데이터베이스에서 RASP(Runtime Application Self-Protection) 기술의 개념과 적용 방안을 설명하시오.
- 데이터 감사(Audit) 시스템의 개념과 데이터 변조 탐지 기술을 설명하시오.
- 데이터베이스에서 Zero Trust Security Model이 적용되는 방식을 설명하시오.
  - 좋습니다. 아홉 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

34. 암호화 키 관리(Key Management) 기법

암호화 키 관리는 데이터 보안의 핵심 요소로, 키의 생성, 저장, 분배, 폐기 등 생명주기를 안전하게 관리하는 체계를 의미합니다.

주요 기법
	- Key Rotation: 주기적으로 키를 변경해 보안 강화
	- Key Hierarchy: 마스터 키와 세션 키 분리, 상위 키로 하위 키 암호화
	- HSM(Hardware Security Module): 키를 하드웨어 기반 보안 장비에 저장
	- KMS(Key Management Service): AWS, Azure 등에서 제공하는 키 관리 서비스
	- Access Control: 키에 접근할 수 있는 사용자/시스템 제한

중요성
키 유출은 암호화 무력화와 직결되므로 철저한 보호 체계 필요

⸻

35. RASP(Runtime Application Self-Protection)의 개념과 적용 방안

RASP는 애플리케이션 내부에서 실시간으로 보안 위협을 감지하고, 스스로 방어하는 기술입니다. 일반적인 WAF보다 더 심층적으로 동작합니다.

특징 및 적용 방안
	- 실행 중 공격 코드, SQL Injection, XSS 등 탐지
	- 코드 삽입 없이 에이전트로 동작하거나, 런타임에 코드 수정
	- 탐지 후 차단, 알림, 세션 종료 등의 액션 수행
	- DB 접근, 쿼리 실행, 인젝션 시도 탐지 가능

활용 예시
	- 보안이 중요한 금융, 헬스케어 앱
	- 웹 애플리케이션에서 DB 접근 로직 보호

⸻

36. 데이터 감사(Audit) 시스템의 개념과 데이터 변조 탐지 기술

데이터 감사 시스템은 데이터 접근, 변경, 삭제 등 모든 활동을 기록하여 추적 가능성과 투명성을 보장하는 시스템입니다.

주요 기능
	- 누가, 언제, 어떤 데이터를, 어떤 방식으로 사용했는지 로그 기록
	- 변경 전후 값 비교, 승인 이력 추적
	- 시계열 저장 및 규제 대응(예: GDPR, 금융감독 기준)

변조 탐지 기술
	- 로그 서명(Signing): 감사 로그에 디지털 서명 적용
	- 해시체인(Hash Chain): 이전 로그의 해시를 다음 로그에 포함
	- WORM(Write Once Read Many) 저장소: 로그 변조 불가 스토리지 사용

⸻

37. Zero Trust Security Model의 데이터베이스 적용 방식

Zero Trust 모델에서 데이터베이스는 더 이상 내부라 하더라도 신뢰하지 않으며, 모든 접근은 인증과 검증을 전제로 합니다.

적용 방식
	- 모든 요청에 대해 인증/인가 수행: IP, 위치, 기기 상태 기반
	- 데이터 액세스 최소 권한 설정(Least Privilege)
	- 행 단위, 컬럼 단위 접근 제어(RLS, CLS)
	- 정책 기반 접근 관리(ABAC, RBAC)
	- 행위 기반 이상 탐지 및 실시간 대응
	- 암호화 및 로그 감사 체계 연동

결과적으로, DB를 보호하는 것이 아니라 DB에 접근하는 경로, 행위, 사용자 자체를 검증함으로써 보안을 강화하는 방식이다.

⸻

다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스 환경에서 BYOK(Bring Your Own Key)와 HYOK(Hold Your Own Key)의 차이를 설명하시오.
- 데이터베이스에서 트랜잭션 로그(Log) 관리의 중요성과 최적화 방안을 설명하시오.
- 트랜잭션에서 Cascade Rollback(연쇄 롤백) 문제와 이를 방지하는 방법을 설명하시오.
- 데이터베이스에서 트랜잭션의 Savepoint(저장점) 기능과 활용 방안을 설명하시오.
  - 좋습니다. 열 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

38. BYOK(Bring Your Own Key)와 HYOK(Hold Your Own Key)의 차이

BYOK
	- 사용자가 클라우드 공급자에게 자신의 암호화 키를 제공하여 해당 키로 데이터를 암호화
	- 클라우드 제공자가 키를 보관하고 데이터 암호화/복호화에 사용
	- 사용자 키의 소유권은 유지되나, 관리권 일부는 클라우드에 있음
	- 예: Microsoft Azure Key Vault, AWS KMS (BYOK 지원)

HYOK
	- 키를 사용자가 직접 보관하고 클라우드 제공자는 키에 전혀 접근 불가
	- 암호화/복호화 처리는 온프레미스 또는 사용자의 보안 모듈에서 수행
	- 보안은 강화되지만, 키 관리 복잡도 및 통합성은 떨어짐

요약
BYOK는 제공자 위탁 모델, HYOK는 완전 자율 통제 모델로 보안과 편의성의 균형에 따라 선택

⸻

39. 트랜잭션 로그(Log) 관리의 중요성과 최적화 방안

중요성
	- 트랜잭션의 영속성(Durability) 보장을 위한 핵심 요소
	- 장애 발생 시 복구(Redo/Undo)에 사용
	- 감사(Audit) 및 리플리케이션의 근간

최적화 방안
	- 로그 파일 분리: 데이터 파일과 물리적 분리하여 디스크 경합 감소
	- 버퍼링 및 배치 기록: I/O 횟수 최소화
	- 압축 및 순차 기록 방식: LSM Tree 구조 등
	- 주기적 백업 및 로그 아카이빙
	- 로그 보존 기간 관리 및 자동 삭제 정책 설정

⸻

40. Cascade Rollback(연쇄 롤백) 문제와 방지 방법

Cascade Rollback
하나의 트랜잭션 실패로 인해 그것을 참조한 다른 트랜잭션들까지 연쇄적으로 롤백되는 문제

예시
T1이 데이터 수정 → T2가 해당 데이터를 읽고 갱신 → T1이 실패 시 T2도 무효화

방지 방법
	- 연쇄제거 스케줄(Cascade-less Schedule) 적용
	- Strict 2PL 사용: 커밋 이전에는 데이터 접근 불가
	- 읽기 전용 복제본 활용(Read Replica)
	- 트랜잭션 간의 격리 수준 조절 (예: Repeatable Read 이상)

⸻

41. Savepoint(저장점)의 개념과 활용 방안

Savepoint는 트랜잭션 내에서 특정 시점을 중간 저장점으로 설정하여, 전체가 아닌 일부만 롤백할 수 있게 해주는 기능입니다.

활용 방안
	- 복잡한 트랜잭션 처리 시, 단계별 검증 및 복구
	- 예외 발생 시, 전체 롤백이 아닌 부분 복원
	- 트랜잭션 내 조건 분기 처리 용이


42. Checkpoint(체크포인트) 기법의 개념과 데이터베이스 복구 시 활용 방안

Checkpoint는 일정 시점까지의 트랜잭션 결과를 디스크에 반영하고, 그 이전의 로그는 복구 시 참조할 필요가 없도록 만드는 기술입니다. 복구 시간 단축과 시스템 안정성 확보가 목적입니다.

역할
	- 시스템 재시작 시 복구 시간 최소화
	- Undo/Redo 범위 축소
	- 메모리 기반 변경 내용을 디스크로 플러시

활용 방안
	- 주기적 또는 조건 기반(CheckPoint Trigger)으로 설정
	- WAL(Write-Ahead Logging) 시스템에서 필수
	- PostgreSQL, Oracle, MySQL 등 대부분의 DBMS에서 내부적으로 사용

예시
트랜잭션 로그: T1, T2, T3 → Checkpoint → T4, T5
→ 복구 시 Checkpoint 이후 로그(T4, T5)만 사용하면 됨

⸻

43. Multi-Granularity Locking(다중 세분화 잠금) 기법

개념
데이터베이스 객체를 다양한 수준(Granularity)으로 잠금하여 병행성과 성능을 조절하는 잠금 기법입니다. 예: 테이블 > 페이지 > 레코드

기능적 특징
	- IS(Intent Shared), IX(Intent Exclusive) 등 의도 잠금 사용
	- 상위 객체를 잠그기 전에 하위 객체에 대한 의도 설정
	- 트리 구조로 잠금 관리 (lock hierarchy)

장점
	- 충돌 최소화
	- 잠금 오버헤드 감소
	- 동시성 제어 강화

활용 예시
대용량 테이블에서 특정 레코드만 갱신 시 테이블 전체가 아닌 레코드 수준에서만 잠금 가능

⸻

44. Shadow Paging(그림자 페이징) 기법의 개념과 장단점

개념
트랜잭션이 데이터 페이지를 변경할 때, 기존 페이지를 수정하지 않고 새로운 페이지 복사본(그림자 페이지)을 만들어 변경 작업 수행. 트랜잭션이 성공하면 새 페이지를 활성화하고, 실패하면 폐기.

장점
	- Undo/Redo 로그 불필요
	- 단순하고 빠른 복구
	- 안정적인 일관성 제공

단점
	- 페이지 단위 복사로 인한 쓰기 비용 증가
	- 디스크 공간 낭비 우려
	- 다중 트랜잭션 처리에는 부적합

활용 사례
초기 파일 시스템, 간단한 임베디드 DB(예: SQLite의 일부 모드)에서 사용

⸻

45. 트랜잭션 로그의 UNDO / REDO 기법의 개념과 차이

UNDO
	- 트랜잭션 실패 또는 Rollback 시, 이전 상태로 되돌리기 위한 로그
	- 변경 전(before image) 저장
	- 아직 커밋되지 않은 작업 취소

REDO
	- 커밋된 트랜잭션이 반영되지 못했을 때, 재실행을 위한 로그
	- 변경 후(after image) 저장
	- 시스템 장애 후 복구에 사용

차이 요약
	- UNDO: 미완료 트랜잭션 무효화
	- REDO: 완료 트랜잭션 재적용
→ WAL(Write-Ahead Logging) 구조에서는 항상 UNDO/REDO 로그를 먼저 기록

⸻

다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 분산 트랜잭션에서 트랜잭션 복구를 위한 Paxos 알고리즘의 개념과 활용 방안을 설명하시오.
- ARIES 복구 알고리즘에서 Analysis, Redo, Undo 단계의 역할을 설명하시오.
- 데이터베이스에서 WAL(Write-Ahead Logging) 기법이 ACID 속성을 보장하는 방식에 대해 설명하시오.
- Edge AI 기반 데이터베이스 기술과 실시간 데이터 분석을 위한 최적화 방안을 설명하시오.
  - 좋습니다. 열두 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

46. Paxos 알고리즘의 개념과 분산 트랜잭션 복구 활용 방안

Paxos 알고리즘은 분산 시스템에서 합의(consensus)를 이루기 위한 알고리즘으로, 여러 노드가 네트워크 장애나 메시지 지연에도 일관된 결정을 내릴 수 있도록 설계되었습니다.

개념 핵심
	- 다수의 노드 중 과반수의 동의를 얻어 하나의 값을 확정
	- 리더(Promiser/Proposer)와 수락자(Acceptor) 구조
	- 장애 허용(Fault-Tolerance)을 보장

분산 트랜잭션 복구 활용
	- 2PC/3PC 대신 Paxos를 사용하여 장애 발생 시 트랜잭션의 일관성 있는 커밋 여부 결정
	- Google Spanner, etcd, CockroachDB 등이 Paxos 또는 유사 알고리즘(Raft) 기반으로 트랜잭션 복구 처리

⸻

47. ARIES 복구 알고리즘의 세 단계 (Analysis, Redo, Undo)

ARIES는 Write-Ahead Logging 기반의 고급 복구 알고리즘으로, 대부분의 상용 DBMS에서 채택하고 있습니다.

1. Analysis 단계
	- 재시작 로그를 읽고, 어떤 트랜잭션이 커밋/비커밋 상태였는지 분석
	- 트랜잭션 테이블, 더티 페이지 테이블 복원

2. Redo 단계
	- 가장 이른 LSN(Log Sequence Number)부터 순차적으로 다시 실행
	- 디스크에 반영되지 않았던 변경 사항을 적용

3. Undo 단계
	- 미커밋 트랜잭션의 작업을 되돌림
	- Compensation Log Record(CLR)를 기록하여 작업의 취소도 로그로 남김

⸻

48. WAL(Write-Ahead Logging)의 ACID 보장 방식

WAL 기법은 데이터를 디스크에 실제 반영하기 전에 트랜잭션 로그를 먼저 기록하는 방식으로, ACID 중 일관성(Consistency)과 내구성(Durability)을 보장합니다.

보장 방식
	- Atomicity: 실패 시 로그 기반 Undo로 전체 롤백 가능
	- Consistency: 변경 순서, 상태 등이 로그로 관리되어 일관성 유지
	- Durability: 트랜잭션이 커밋되면 로그는 디스크에 영구 저장 → 시스템 장애에도 복구 가능
	- 트랜잭션 성공 시점 = 로그 디스크 기록 완료 시점

요약
WAL은 장애 상황에서도 데이터 무결성과 정합성을 유지하는 핵심 메커니즘

⸻

49. Edge AI 기반 데이터베이스 기술과 실시간 분석 최적화 방안

Edge AI 기반 DB는 데이터 생성 지점(엣지 디바이스)에서 AI 추론 및 분석을 수행하고, 핵심 데이터만 중앙 시스템으로 전송하는 구조입니다.

특징
	- 지연 최소화: 실시간 의사결정 가능 (예: 제조 로봇, 스마트 시티)
	- 네트워크 부하 감소: 전체 데이터를 클라우드로 보내지 않음
	- AI 통합: 사물인터넷 + AI + DB 융합

최적화 방안
	- In-Memory 기반 경량 DB 사용 (예: SQLite, Redis, InfluxDB)
	- Federated Learning 기반 분산 학습
	- AI 모델 캐싱 및 로컬 추론
	- 이벤트 기반 데이터 저장 및 알림 트리거 연동

50. Graph Neural Network(GNN)을 활용한 추천 시스템 구현 방안

Graph Neural Network(GNN)는 노드와 엣지로 구성된 그래프 구조에서 관계 기반 학습을 수행하는 딥러닝 기법으로, 추천 시스템에서 복잡한 상호작용과 연관성을 모델링하는 데 효과적입니다.

구현 방안
	- 그래프 구성: 사용자-아이템 간 상호작용을 노드 및 엣지로 표현
	- 노드 임베딩 학습: GCN, GraphSAGE 등을 활용하여 노드 특성을 반영한 벡터 생성
	- 연관도 예측: 유사도 측정 또는 벡터 내적 방식으로 추천 아이템 계산
	- 적용 환경: Neo4j + PyTorch Geometric / DGL 기반 시스템 구축

장점
	- 간접 연결도 학습 가능
	- 다양한 관계와 맥락 정보 반영
	- 기존 협업 필터링보다 유연하고 정밀함

⸻

51. AI 기반 자동 SQL 최적화 기법의 개념과 활용 방안

AI 기반 SQL 최적화는 과거 쿼리 실행 이력, 통계 데이터, 리소스 사용량 등을 분석하여 자동으로 실행 계획을 조정하거나 튜닝 제안을 생성하는 기법입니다.

활용 방안
	- ML 기반 옵티마이저: Reinforcement Learning을 활용한 옵티마이저 강화
	- 실행 계획 예측 및 추천: 다양한 계획 시뮬레이션 후 최적 선택
	- 비효율 쿼리 탐지: AI가 스캔, 조인, 정렬 등 병목 원인 탐지
	- Oracle Autonomous DB, SQL Server Intelligent Query Processing에서 이미 활용 중

장점
	- 자동화에 의한 운영 효율 향상
	- 사람보다 빠르게 수많은 계획을 시뮬레이션 가능

⸻

52. AI/머신러닝 기반 Auto-Tuning 사례

Auto-Tuning은 시스템이 스스로 DB 설정값, 인덱스, 쿼리 등을 분석하고 조정하는 기능입니다. AI를 이용해 과거 데이터를 학습해 최적값을 탐색합니다.

사례
	- Amazon Aurora: AI 기반 인스턴스, 쿼리 자동 튜닝
	- Oracle Autonomous DB: 튜닝, 패치, 백업 자동화
	- SQL Server QDS(쿼리 저장소) 기반 튜닝 조언
	- Self-driving DB 연구: Berkeley’s SageDB, Carnegie Mellon OtterTune

튜닝 항목
	- 버퍼 사이즈, 커넥션 수, 인덱스 전략, 파티셔닝 방식 등

⸻

53. Fog Computing 환경에서의 DB 역할과 적용 사례

Fog Computing은 클라우드와 엣지 사이에서 데이터 처리, 분석, 저장 기능을 중간 지점에서 수행하는 분산 컴퓨팅 아키텍처입니다.

DB의 역할
	- 지연 시간 최소화: 실시간 처리가 필요한 데이터는 Fog 노드에서 처리
	- 데이터 필터링/요약: 중앙 서버에 보낼 데이터만 선별
	- 지역 분산 저장소 역할: 네트워크 단절 시에도 서비스 유지

적용 사례
	- 스마트 공장 → 공정별 분석을 Fog DB에서 처리
	- 자율주행 차량 → Fog 노드가 경로 계산, 주변 센서 분석
	- 스마트 시티 → Fog에서 교통, CCTV, 환경 정보 처리

⸻

54. AI 기반 데이터 품질 관리(Data Quality Management)의 개념과 적용 방안

개념
AI가 데이터의 정합성, 정확성, 중복성, 이상값 등을 자동으로 탐지하고, 품질 개선 작업(정제, 표준화, 보완 등)을 수행하는 시스템입니다.

적용 방안
	- 이상값 탐지: AutoEncoder, Isolation Forest 등 비지도 학습 활용
	- 데이터 프로파일링 자동화: 분포, 패턴, 누락 값 탐지
	- 정제 추천: 컬럼 타입 자동 추론, 표준 코드 추천
	- 품질 평가 지표 자동 계산: 정확도, 일관성, 적시성 등

예시 솔루션
Informatica CLAIRE, IBM Watson DQ, Talend Trust Score

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.


- 대규모 데이터 처리에서 Apache Iceberg, Delta Lake, Hudi 등의 최신 데이터 포맷이 기존 데이터 저장 방식과 차별화되는 점을 설명하시오.
  - 좋습니다. 열네 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

55. Apache Iceberg, Delta Lake, Hudi 등의 최신 데이터 포맷과 기존 저장 방식과의 차이점

기존 저장 방식 (예: CSV, Parquet, ORC 등)
	- 단순한 파일 포맷 중심
	- 트랜잭션, 스키마 변경, 버전 관리 등의 기능 부재
	- 대용량 분산 환경에서 데이터 정합성 보장 어려움

최신 데이터 포맷 (Lakehouse 기반 테이블 포맷)
이들은 Data Lakehouse 아키텍처를 지원하며, 스토리지에 존재하는 데이터를 테이블처럼 관리하게 해줍니다.

⸻

1. Apache Iceberg
	- 스냅샷, 롤백, 시간여행 기능 지원
	- 대규모 파티션 처리 최적화 (Hidden Partition)
	- ANSI SQL 완전 지원
	- Spark, Flink, Trino, Hive 등 다양한 엔진 호환

2. Delta Lake (Databricks)
	- ACID 트랜잭션 지원 (WAL 기반)
	- Merge, Update, Delete 지원
	- 스키마 진화 및 감사 로그
	- ML, BI 분석 환경과 연계에 강함

3. Apache Hudi
	- 실시간 데이터 업데이트 및 증분 처리에 강점
	- Copy-on-Write / Merge-on-Read 방식 선택 가능
	- CDC, Upsert, Streaming 데이터 처리 지원
	- Uber에서 시작된 프로젝트

⸻

차별화 포인트 요약
	- 트랜잭션 지원: Data Lake에서 ACID 구현
	- 스키마 진화: 실시간 스키마 변경 가능
	- 버전 관리 및 롤백: 시간여행 쿼리 가능
	- 성능 최적화: Metadata Index, Z-Ordering 등

이러한 포맷들은 기존 단순 파일 기반의 한계를 극복하고, 데이터 웨어하우스급 기능을 오픈 포맷으로 제공함으로써 Data Lakehouse를 가능하게 만듭니다.


56. 데이터베이스에서 Quantum Computing(양자 컴퓨팅) 적용 가능성과 연구 동향

개념
양자 컴퓨팅은 큐비트(Qubit)를 기반으로 병렬 연산을 수행하여 기존 컴퓨터로는 불가능하거나 시간이 오래 걸리는 연산을 극적으로 단축시킬 수 있는 차세대 컴퓨팅 기술입니다.

데이터베이스 적용 가능성
	- 초고속 쿼리 최적화: 방대한 실행 계획 중 최적 해를 빠르게 탐색
	- 복잡한 조인, 그래프 탐색: NP-완전 문제에 가까운 연산을 효율적으로 처리
	- 양자 암호 및 검색: Grover 알고리즘을 통한 빠른 데이터 검색

연구 동향
	- IBM, Google, Microsoft 등에서 양자 DB 접근 방식 실험
	- QAOA, VQE 기반 쿼리 최적화 알고리즘 연구
	- 아직 실용적 수준의 데이터베이스는 상용화되지 않았으며, 양자-고전 하이브리드 모델 중심으로 연구 진행 중

⸻

57. Web3 기반 탈중앙화 데이터베이스와 중앙 집중식 DB의 차이

Web3 기반 DB (예: OrbitDB, Textile, BigchainDB)
	- 블록체인 또는 P2P 기반 분산 저장 구조
	- 사용자가 데이터에 대한 주권(Self-sovereignty) 보유
	- 스마트 계약 기반 데이터 검증, 변경 추적

중앙 집중식 DB (예: MySQL, Oracle 등)
	- 하나의 중앙 서버에서 데이터 관리 및 통제
	- 속도, 관리 효율성은 뛰어나나 검열, 단일 실패점 존재

차이점 요약
	- 구조: 중앙 vs 분산
	- 신뢰 방식: 중앙 관리자 vs 합의 알고리즘
	- 보안성: 위변조 방지 강도 다름
	- 거버넌스: 중앙 제어 vs 사용자 자율성

⸻

58. AI와 강화 학습 기반 자율 운영 데이터베이스(Autonomous DB)의 개념과 기술

개념
AI 및 강화 학습(RL)을 통해 데이터베이스가 스스로 구성, 튜닝, 모니터링, 문제 해결을 수행하는 자율 운영 시스템입니다.

주요 기술 구성
	- 자동 튜닝: 인덱스, 버퍼, 파라미터 최적화
	- 쿼리 성능 분석: 실행 계획을 학습 기반으로 선택
	- 장애 예측/복구: 이상 감지 및 사전 조치
	- 스케일링 제어: 사용량 분석 후 자동 확장/축소

사례
	- Oracle Autonomous Database
	- OtterTune (카네기멜론)
	- Microsoft SQL Azure 자동 인사이트 제공 기능

⸻

59. Shared Nothing vs Shared Everything 아키텍처의 차이

Shared Nothing
	- 노드 간 리소스 완전 독립
	- CPU, 메모리, 디스크 모두 별도 관리
	- 확장성, 장애 격리 강점 (Ex: Cassandra, Hadoop)

Shared Everything
	- 모든 노드가 공유 리소스에 접근 (Ex: 공통 디스크)
	- 데이터 일관성 보장 쉬움
	- 병목/충돌 위험 있음 (Ex: Oracle RAC)

비교 요약
	- Shared Nothing → 수평 확장 중심, 분산 시스템
	- Shared Everything → 통합 처리 중심, 고성능 노드 기반

⸻

60. Multi-Tenant Architecture(멀티 테넌트 아키텍처)의 개념과 활용 사례

개념
하나의 DB 인프라 또는 애플리케이션이 여러 사용자(테넌트)의 데이터를 논리적으로 분리하여 서비스하는 아키텍처입니다.

유형
	- 공유 DB/스키마: 하나의 DB, 테넌트 ID로 구분
	- 공유 DB/분리 스키마: 하나의 DB에 테넌트별 스키마
	- 완전 분리형: 테넌트별 DB 인스턴스

활용 사례
	- SaaS 서비스 (예: Salesforce, Slack)
	- 클라우드 기반 고객별 환경 분리
	- B2B 플랫폼 서비스에서 조직별 데이터 분리 제공


61. OLTP와 OLAP의 성능 최적화 전략의 차이

OLTP (Online Transaction Processing)
	- 특징: 다수의 짧은 트랜잭션, 빈번한 쓰기/읽기, 실시간 처리
	- 최적화 전략:
	- 정규화 중심 설계 (데이터 중복 최소화)
	- 빠른 인덱스 활용
	- 트랜잭션 격리 수준 조정
	- 커넥션 풀링, 적절한 Locking 관리
	- SSD 등 고속 저장 장치 활용

OLAP (Online Analytical Processing)
	- 특징: 복잡한 쿼리, 집계, 다차원 분석 중심, 주로 읽기 위주
	- 최적화 전략:
	- 비정규화 및 스타/스노우플레이크 스키마
	- 컬럼 기반 저장소 활용 (e.g., Redshift, ClickHouse)
	- 물질화 뷰(Materialized View) 사용
	- 파티셔닝, Z-order 정렬 등 I/O 최적화
	- 분산 처리 기반 병렬 쿼리 엔진 적용

요약
OLTP는 트랜잭션 효율과 정합성, OLAP은 대량 분석과 읽기 성능에 집중한 구조와 전략이 요구된다.

⸻

62. NoSQL의 BASE 모델과 RDBMS의 ACID 모델의 차이

ACID (전통 관계형 DB의 특성)
	- Atomicity: 모두 성공하거나 모두 실패
	- Consistency: 트랜잭션 전후 상태 일관성 유지
	- Isolation: 동시 실행 시 상호 간섭 없음
	- Durability: 커밋 후 데이터 영구 보존

BASE (NoSQL 지향 특성)
	- Basically Available: 언제나 응답하지만 일관성은 보장 안 될 수 있음
	- Soft State: 시스템 상태는 일정하지 않을 수 있음
	- Eventual Consistency: 시간이 지나면 결국 일관된 상태에 도달

비교 요약
	- ACID는 정합성 중심, BASE는 확장성과 가용성 중심
	- 금융, ERP 등은 ACID, SNS/IoT 등은 BASE가 적합

⸻

63. Federated Database System(연합 DB)의 개념과 활용 사례

개념
다양한 이기종 데이터베이스를 하나의 통합된 논리적 시스템처럼 사용할 수 있게 하는 구조. 실제로는 분산되어 있으나 사용자에게는 일관된 인터페이스 제공.

특징
	- 로컬 DB는 자율 운영
	- 질의는 중앙에서 통합 처리되지만, 실제 데이터는 각 DB에 분산
	- 표준 인터페이스(SQL, REST 등) 제공

활용 사례
	- 금융: 계열사별 독립 시스템을 통합 조회
	- 정부기관: 부처 간 시스템 연계
	- 글로벌 기업: 지사별 DB 연합

⸻

64. Sharding Key 선택이 시스템 성능에 미치는 영향

Sharding Key(샤딩 키)는 데이터 분산의 기준이 되는 키로, 이를 잘못 선택하면 성능 저하와 데이터 불균형이 발생할 수 있습니다.

영향 요소
	- 균등 분포 여부: 키가 치우치면 특정 노드에 부하 집중
	- 쿼리 조건과의 일치 여부: 잘못된 키는 모든 샤드를 조회하게 만듦
	- 샤드 간 조인 어려움: 키가 다르면 조인이 느려짐

좋은 샤딩 키 기준
	- 분포 균형
	- 자주 조회되는 조건과 일치
	- 높은 카디널리티
	- 가능한 한 조인 대상과 일치

⸻

65. Read-Heavy vs Write-Heavy 워크로드 처리 전략

Read-Heavy 워크로드 전략
	- 읽기 성능 최적화가 핵심
	- 읽기 복제(Replica) 활용
	- 쿼리 캐싱 및 CDN 사용
	- 인덱싱 최적화, Materialized View 활용

Write-Heavy 워크로드 전략
	- 쓰기 지연 최소화가 중요
	- Batch Write, 비동기 처리 활용
	- LSM Tree 기반 DB 선택 (예: Cassandra, HBase)
	- 파티셔닝 및 병렬 쓰기 전략 설계
	- 트랜잭션 최소화 및 로그 기반 처리


66. HTAP(Hybrid Transactional and Analytical Processing)의 개념과 적용 방안

HTAP는 하나의 시스템에서 OLTP(트랜잭션 처리)와 OLAP(분석 처리)를 동시에 수행할 수 있는 데이터베이스 아키텍처입니다. 전통적으로 분리되어 있던 운영 DB와 분석 DB를 통합하여 실시간 인사이트 제공이 가능해집니다.

특징
	- 실시간 데이터 분석 가능
	- 운영 데이터와 분석 데이터 간 동기화 불필요
	- OLTP와 OLAP 성능을 동시에 고려한 설계

적용 방안
	- In-Memory + Column Store 기술 병행 사용
	- MVCC 기반 동시성 제어
	- 분리된 엔진 또는 통합 엔진(예: TiDB, SAP HANA, SingleStore)
	- AI 기반 쿼리 스케줄링 및 분산 처리

사례
	- 실시간 마케팅 추천 시스템
	- 금융 이상 거래 탐지
	- 유통 재고 분석 및 예측 시스템

⸻

67. Data Lake, Data Warehouse, Data Mart의 차이

Data Lake
	- 원시 데이터 중심, 정형·비정형 데이터 수용
	- 저장 비용 저렴, 스키마 없이 저장(Schema-on-read)
	- 머신러닝, 빅데이터 분석에 적합

Data Warehouse
	- 정형 데이터 중심, ETL 과정을 거쳐 스키마화
	- 고성능 쿼리, BI 분석에 최적화
	- 스키마 기반 저장(Schema-on-write), 비용 높음

Data Mart
	- 특정 부서나 주제 중심의 소규모 데이터 웨어하우스
	- 빠른 접근성과 단순 구조
	- 독립적 또는 DW의 서브셋 형태

요약 비교
	- Data Lake: 유연성 중심, 원시 저장소
	- Data Warehouse: 구조화, 정제 중심
	- Data Mart: 국소적, 목적 특화된 저장소

⸻

68. ORM(Object-Relational Mapping)과 직접 SQL 실행의 차이

ORM
	- 객체지향 언어에서 DB 작업을 객체로 매핑하여 수행하는 방식
	- SQL 코드 작성 없이 데이터 CRUD 가능
	- 예: Hibernate(Java), SQLAlchemy(Python), Django ORM

장점
	- 생산성 향상, 유지보수 용이
	- DBMS 독립성 확보
	- 보안 위험 감소(SQL Injection 방지)

단점
	- 성능 저하 가능성
	- 복잡한 쿼리 표현의 한계
	- ORM 내부 동작 이해 필요

직접 SQL
	- SQL을 직접 작성해 DB 조작
	- 복잡한 쿼리 최적화 가능
	- 디버깅, 성능 튜닝 용이
	- 단, 코드량 증가 및 보안 주의 필요

⸻

69. Schema Evolution(스키마 진화)의 개념과 적용 방안

개념
스키마 진화는 데이터베이스 구조(테이블, 컬럼 등)를 기존 데이터를 유지하면서 유연하게 변경·확장하는 것을 의미합니다.

적용 방안
	- 스키마 버전 관리: 변경 이력 추적
	- Backward/Forward 호환성 고려
	- NULL 허용 컬럼 추가
	- 기존 컬럼 제거 대신 비활성화 처리
	- 데이터 마이그레이션 스크립트 작성
	- JSON 기반 스키마 유효성 검사 도입

지원 플랫폼
Avro, Parquet, BigQuery, Iceberg 등은 스키마 진화를 기본적으로 지원

⸻

70. Archiving Strategy(아카이빙 전략)의 개념과 활용 사례

개념
아카이빙은 오래되었지만 보존이 필요한 데이터를 운영 DB에서 분리하여 저비용 스토리지로 이동시키는 전략입니다.

목적
	- 운영 성능 유지
	- 스토리지 비용 절감
	- 규제 및 감사 대응

활용 사례
	- 5년 이상 거래 기록은 별도 보관 (금융, 공공기관 등)
	- 대용량 로그 데이터 → 오브젝트 스토리지에 이동
	- 클라우드 기반 Glacier, Deep Archive와 연동

전략 요소
	- 아카이빙 주기
	- 검색 가능성 확보
	- 원복(복원) 시나리오 설계
	- 데이터 암호화 및 접근 제어


71. Query Profiling(쿼리 프로파일링) 기법의 개념과 활용 방안

개념
Query Profiling은 SQL 쿼리 실행 과정에서 각 단계별 리소스 사용량, 실행 시간, I/O 비용 등을 분석하여 병목 지점을 파악하고 최적화하는 기법입니다.

활용 방안
	- 실행 계획 비교(Execution Plan): 옵티마이저가 선택한 경로 분석
	- 분석 도구 활용: EXPLAIN, EXPLAIN ANALYZE, SHOW PROFILE, pg_stat_statements 등
	- 쿼리 단계별 시간 측정: 파싱 → 최적화 → 실행
	- 인덱스 사용 여부 및 조인 방식 확인
	- 불필요한 정렬, 전체 테이블 스캔 탐지

효과
	- 쿼리 튜닝 방향 제시
	- 응답 시간 감소, 리소스 효율 향상
	- 트래픽 증가 대비 성능 확보

⸻

72. Change Data Capture(CDC) 기법의 개념과 활용 사례

개념
CDC는 데이터베이스에서 데이터 변경 이력(삽입, 수정, 삭제)을 실시간 또는 준실시간으로 캡처하여 다른 시스템으로 전송하는 기술입니다.

방식 유형
	- 트리거 기반: DB 트리거를 통해 변경 감지
	- 로그 기반: 트랜잭션 로그를 분석하여 변경 사항 추출
	- 타임스탬프 비교: 이전 데이터와 비교

활용 사례
	- 데이터 웨어하우스 실시간 업데이트
	- 마이크로서비스 간 비동기 데이터 동기화
	- Kafka와 연계한 스트리밍 파이프라인 구축
	- 분석 시스템/BI 도구에 실시간 반영

대표 도구
Debezium, AWS DMS, Oracle GoldenGate, SQL Server CDC 기능

⸻

73. Key-Value Store와 Column-Family Store의 차이

Key-Value Store
	- 단순한 Key와 Value 쌍 구조
	- Value는 구조화되지 않은 데이터(Blob)
	- 빠른 읽기/쓰기, 단순한 데이터 저장에 적합
	- 예: Redis, Riak, DynamoDB

Column-Family Store
	- Key-Value 형태를 기본으로 하지만, Value를 컬럼 그룹(Column Family)으로 구성
	- 컬럼 단위 접근 가능, 고정된 스키마 없이 동적 컬럼 추가 가능
	- 대용량 분산 환경에 적합
	- 예: Cassandra, HBase

요약 차이점
	- Key-Value Store: 단순, 빠름, 유연
	- Column-Family Store: 복잡한 쿼리 처리, 컬럼 기반 최적화 가능

⸻

74. Auto Scaling(자동 확장)의 개념과 주요 활용 방안

개념
Auto Scaling은 데이터베이스 인프라가 트래픽 부하나 사용량 변화에 따라 자동으로 리소스를 확장(Scale-Out) 또는 축소(Scale-In) 하는 기술입니다.

활용 방안
	- 읽기 Replica 자동 생성: 읽기 부하 증가 시 자동 복제본 생성
	- 샤딩 자동 분할/병합: 데이터량 증가에 따른 샤드 재구성
	- 서버리스 DB 연동: Aurora Serverless, Spanner 등은 부하에 따라 자동 할당
	- 스케줄 기반 확장: 시간대별 예상 부하에 따라 미리 확장 설정

장점
	- 리소스 비용 절감
	- 피크 타임 대응 용이
	- 운영 자동화 및 서비스 안정성 향상

⸻

계속해서 다음 블럭 설명을 원하시면 “다음”이라고 입력해 주세요.

- 데이터베이스에서 Rebalancing(재조정) 기법의 개념과 필요성을 설명하시오.
- 데이터베이스 성능 모니터링 도구(예: Prometheus, Grafana, pg_stat_statements)의 개념과 활용 방안을 설명하시오.
- 데이터베이스 장애 감지(Anomaly Detection) 및 복구 자동화를 위한 AI 기반 기법을 설명하시오.
- 데이터베이스에서 Serverless Computing 환경에서의 데이터 저장 방식과 기존 방식과의 차이를 설명하시오.
  - 좋습니다. 열아홉 번째 블럭 질문들에 대해 서술형으로 정리해드릴게요.

⸻

75. Rebalancing(재조정) 기법의 개념과 필요성

개념
Rebalancing은 분산 데이터베이스나 스토리지 시스템에서 데이터 또는 트래픽이 특정 노드에 불균형하게 집중되는 현상을 해소하기 위해 데이터를 다시 고르게 분산시키는 작업입니다.

필요성
	- 노드 간 과부하/과소부하 문제 해결
	- 샤딩 후 불균형 해소 (Hot Spot 방지)
	- 스케일 아웃 후 새로운 노드에 데이터 자동 분배
	- 장애 복구 후 데이터 재분산

기법 예시
	- Consistent Hashing 기반 이동
	- 자동 샤딩 재분배 (MongoDB, Cassandra 등)
	- 정책 기반 재조정 (데이터 양, CPU 사용률 등)

⸻

76. 성능 모니터링 도구 (Prometheus, Grafana, pg_stat_statements)의 개념과 활용 방안

Prometheus
	- 시계열 기반 메트릭 수집 도구
	- DB, 애플리케이션, 시스템의 상태 지표 수집 가능
	- AlertManager 연동으로 이상 탐지 및 알림 가능

Grafana
	- Prometheus, InfluxDB 등에서 수집한 데이터를 시각화
	- 대시보드 기반 실시간 모니터링 가능
	- 데이터베이스 쿼리 성능, 지연, 커넥션 수 등을 시각화

pg_stat_statements
	- PostgreSQL의 내장 확장 모듈
	- SQL별 호출 횟수, 평균 실행 시간, I/O 사용량 등의 통계 제공
	- 쿼리 튜닝의 핵심 도구

활용 방안
	- 시스템 부하 분석 및 병목 탐지
	- 쿼리 실행 패턴 및 자원 사용 분석
	- 실시간 장애 알림 설정
	- Capacity Planning 및 자동 스케일링 조건 수립

⸻

77. AI 기반 장애 감지 및 복구 자동화 기법

개념
AI를 활용하여 DB 장애(성능 저하, 오류 등)를 사전에 탐지하거나, 장애 발생 시 자동 복구 조치를 수행하는 기술입니다.

기법
	- 시계열 예측 모델(LSTM, ARIMA): 리소스 사용량 이상 탐지
	- 로그 분석 기반 NLP 모델: 에러 패턴 감지
	- 강화 학습: 반복된 장애 유형에 따른 최적 복구 경로 학습
	- 클러스터 상태 기반 Failover 자동화: Kubernetes + DB Operator 연동

적용 예시
	- 자동 인덱스 재구성
	- 커넥션 풀 재시작
	- 노드 재시작 또는 트래픽 분산
	- 슬로우 쿼리 자동 알림 및 차단

⸻

78. Serverless Computing 환경에서의 데이터 저장 방식과 기존 방식 차이

Serverless 환경의 저장 방식
	- DB 인프라 관리 없이 사용량 기반 과금
	- 자동 확장/축소, 필요 시 자동으로 Sleep 모드
	- Aurora Serverless, Firebase Realtime DB, Google BigQuery 등

기존 방식
	- 고정된 인스턴스 기반, 항상 작동 중
	- 과/소비에 따른 리소스 낭비 발생
	- 확장성과 유지보수 부담 있음

차이점 요약
	- 관리 주체: 기존은 사용자가 관리, Serverless는 클라우드가 관리
	- 비용 구조: Serverless는 요청 기반, 기존은 지속 비용
	- 확장성: Serverless는 자동 확장, 기존은 수동 또는 반자동 확장

79. Query Caching(쿼리 캐싱) 기법의 개념과 활용 방안

개념
쿼리 캐싱은 동일한 쿼리가 반복될 때, 데이터베이스가 매번 실행하지 않고 이전에 계산된 결과를 저장(Cache) 해두고 재사용하는 기법입니다.

기법 유형
	- 결과 캐싱(Result Cache): 쿼리 결과 자체를 저장
	- 플랜 캐싱(Plan Cache): 실행 계획을 재사용
	- 애플리케이션/프록시 레벨 캐싱: Redis, Memcached 활용

활용 방안
	- 읽기 많은 페이지(예: 게시판, 상품 목록)에 캐싱 적용
	- TTL(Time To Live) 설정으로 주기적 갱신
	- 조건: 데이터 변경 빈도가 낮고, 결과가 반복적으로 사용됨

장점
	- 응답 속도 향상
	- DB 부하 감소
	- 스케일링 비용 절감

⸻

80. Adaptive Query Optimization(적응형 쿼리 최적화)의 개념과 적용 사례

개념
Adaptive Query Optimization은 실행 도중 실제 런타임 통계 정보를 반영하여 실행 계획을 동적으로 조정하는 기법입니다.

기법 예시
	- Adaptive Join: 처음에는 Nested Loop → 필요 시 Hash Join으로 전환
	- Cardinality Feedback: 추정 카디널리티가 실제와 다를 경우, 다음 실행 시 수정
	- Deferred Join Planning: 쿼리 실행 중 일부 조건이 결정된 후 조인 전략 결정

적용 사례
	- Oracle Adaptive Query Optimization
	- SQL Server Intelligent Query Processing
	- PostgreSQL의 계획 피드백 기능

효과
	- 실행 환경 변화에 유연하게 대응
	- 통계 정보 부정확 시 성능 하락 방지

⸻

81. 파이프라이닝(Pipelining)과 매핑(Mapping) 기법이 쿼리 성능에 미치는 영향

파이프라이닝
	- 연산 결과를 임시 저장하지 않고, 다음 연산으로 바로 넘기는 방식
	- 메모리 기반 처리에서 빠른 속도 제공
	- 예: 중간 결과를 디스크에 쓰지 않고 연속 수행 (Iterator 방식)

매핑
	- 한 데이터셋을 다른 형식이나 구조로 변환
	- ETL 과정에서 필수적, 데이터 전처리 시 사용
	- 불필요하거나 과도한 매핑은 오히려 병목 유발

성능 영향 요약
	- 파이프라이닝은 I/O 감소로 쿼리 응답 시간 단축
	- 매핑은 계산량이 많거나 비효율적일 경우 오버헤드 증가 가능

⸻

82. Clustered Index와 Non-Clustered Index의 차이

Clustered Index
	- 실제 데이터의 물리적 정렬 순서를 결정
	- 테이블 당 하나만 존재
	- 기본 키에 자동으로 생성되는 경우 많음
	- 검색 속도 빠름 (데이터 페이지 접근이 바로 가능)

Non-Clustered Index
	- 인덱스는 별도 저장되고, 실제 데이터는 참조(리프 노드에 포인터 포함)
	- 여러 개 생성 가능
	- 추가 저장 공간 필요
	- 특정 컬럼 검색에 유리

요약
	- Clustered: 빠른 기본 접근, 정렬된 저장
	- Non-Clustered: 보조 인덱스, 다양한 조건 지원


83. Hash Join과 Nested Loop Join의 차이

Hash Join
	- 한 테이블의 조인 키를 기준으로 해시 테이블 생성 후, 다른 테이블과 비교
	- 대용량 조인에 효과적
	- 인덱스 없어도 성능 우수
	- 전제: 조인 조건이 등치(=)일 때 최적

Nested Loop Join
	- 한 테이블의 각 행마다 다른 테이블을 반복 스캔하며 조건 일치 여부 확인
	- 소규모 조인 또는 인덱스 존재 시 유리
	- 성능은 데이터 크기에 따라 급격히 저하될 수 있음

요약
	- Hash Join: 대규모, 인덱스 없을 때 빠름
	- Nested Loop: 작은 테이블, 인덱스 있을 때 효율적

⸻

84. Execution Plan Caching(실행 계획 캐싱)의 개념과 성능 향상 효과

개념
SQL 실행 시 생성된 실행 계획을 DBMS가 캐시(저장) 하여 동일하거나 유사한 쿼리에서 재사용하는 기법입니다.

성능 효과
	- 파싱 및 최적화 시간 절약
	- CPU 부하 감소
	- 일관된 실행 계획 유지 가능

적용 예시
	- SQL Server의 Plan Cache
	- Oracle의 Shared Pool
	- PostgreSQL의 Prepared Statements

주의점
	- 쿼리 상수 값 차이에 따라 캐시 미적용 가능
	- 비효율적인 캐시 계획 고착(Pinned Plan) 시 성능 저하 발생 가능

⸻

85. Hinted Query Optimization(힌트 기반 쿼리 최적화)의 개념과 활용 방안

개념
힌트(Hint)는 SQL 내부에 DBMS 옵티마이저에게 특정 실행 계획을 유도하는 명령을 삽입하여 성능을 조절하는 기법입니다.

활용 방안
	- 조인 방식 지정 (Nested Loop / Hash Join 등)
	- 인덱스 강제 사용 (USE INDEX)
	- 병렬 처리 활성화 (PARALLEL)
	- 쿼리 분할 또는 스캔 방식 제한

예시

SELECT /*+ USE_NL(t1) */ * FROM t1, t2 WHERE t1.id = t2.id;

주의점
	- 잘못된 힌트는 성능 저하
	- DBMS 버전 또는 통계 변화에 따라 무효화 가능

⸻

86. Adaptive Indexing(적응형 인덱싱)의 개념과 전통 인덱스와의 차이

Adaptive Indexing
	- 데이터에 접근하는 방식에 따라 점진적으로 인덱스를 생성 및 최적화
	- 사용자가 명시적으로 인덱스를 생성하지 않아도 됨
	- DB가 쿼리 실행 중 동적으로 인덱스를 개선

전통 인덱스와 차이점
	- 전통 인덱스: 명시적으로 생성, 변경 필요
	- Adaptive: 실행 과정 중 자동 생성 및 진화
	- 예: SAP HANA의 Index Advisor, adaptive radix tree 방식

장점
	- 튜닝 부담 감소
	- 쿼리 패턴 변화에 유연하게 대응

⸻

87. 데이터 읽기(Read) 성능 최적화를 위한 주요 기법
	- 적절한 인덱스 구성: 범위, 복합, Covering Index
	- 쿼리 리팩토링: 불필요한 조인 제거, 서브쿼리 단순화
	- 결과 캐싱(Query Cache)
	- 읽기 복제본(Read Replica) 활용
	- 파티셔닝 및 샤딩: 읽기 대상 범위 축소
	- Materialized View: 고정 쿼리 결과 미리 저장

⸻

88. 데이터 쓰기(Write) 성능 최적화를 위한 주요 기법
	- Batch Insert/Update: 대량 처리 시 묶어서 실행
	- 비동기 처리: 메시지 큐(Kafka 등) 활용
	- Index 최소화: 쓰기 부하 시 불필요한 인덱스 제거
	- 쓰기 전용 샤드 분리: 읽기와 쓰기 경로 분리
	- LSM Tree 기반 DB 사용: 쓰기 성능 극대화
	- 트랜잭션 범위 최소화: Lock 충돌 방지

89. Eventual Consistency(최종 일관성)의 개념과 적용 사례

개념
분산 시스템에서 모든 노드가 즉시 같은 상태를 유지하지 않아도 되며, 일정 시간이 지난 후에는 결국 동일한 상태로 수렴된다는 일관성 모델입니다.

특징
	- 강한 일관성 보다는 가용성과 응답 속도 우선
	- 데이터가 일시적으로 서로 다를 수 있음
	- 쓰기 후 곧바로 읽으면 이전 값이 보일 수 있음

적용 사례
	- SNS 좋아요 수: 잠시 다른 값 보일 수 있지만 곧 동기화
	- 쇼핑몰 재고 수량: 지역별 캐시에 반영 지연 허용
	- Amazon DynamoDB, Cassandra, Riak 등의 NoSQL 시스템에서 기본 채택

⸻

90. Strong Consistency(강한 일관성) vs Weak Consistency(약한 일관성)

Strong Consistency
	- 쓰기가 완료되면 즉시 모든 노드에 반영
	- 쓰기 직후 읽기 결과는 항상 최신
	- 트랜잭션 처리에 적합
	- 예: RDBMS, Google Spanner

Weak Consistency
	- 최신 데이터 반영 시점 보장 없음
	- 쓰기 직후 읽으면 과거 값일 수 있음
	- 성능 및 가용성 위주 시스템에 사용

비교 요약
	- Strong: 정합성 보장, 속도 느림
	- Weak: 정합성 희생, 속도와 확장성 확보

⸻

91. Multi-Leader Replication과 Single-Leader Replication의 차이

Single-Leader Replication
	- 하나의 리더 노드만 쓰기 가능
	- 팔로워 노드들은 리더의 변경 사항만 복제
	- 간단하고 데이터 충돌 없음
	- 예: MySQL Replication

Multi-Leader Replication
	- 여러 노드에서 쓰기 가능
	- 노드 간에 서로의 변경 사항을 복제
	- 충돌 가능성 있음 → Conflict Resolution 필요
	- 예: Apache CouchDB, ActiveMQ

요약
	- Single-Leader: 안정성, 일관성 중심
	- Multi-Leader: 유연한 쓰기 처리, 복잡한 충돌 처리 요구

⸻

92. 데이터 복제 시 Conflict Resolution(충돌 해결) 기법

개념
다수의 노드에서 동시에 같은 데이터를 수정했을 때, 어느 것이 최종 값인지 결정하는 방식입니다.

주요 기법
	- Last Write Wins (LWW): 타임스탬프 기준 가장 최신 값 채택
	- Version Vector / Vector Clock: 변경 이력 추적 기반 병합
	- Custom Resolution Logic: 비즈니스 룰 기반 수동 선택
	- Three-Way Merge: 공통 조상 비교 후 변경점 병합

적용 예시
	- DynamoDB, CouchDB, Git과 같은 분산 환경
	- 실시간 공동 편집 시스템 (Google Docs 등)

⸻

93. Active-Active vs Active-Passive Replication의 차이

Active-Active Replication
	- 모든 노드가 동시에 요청 처리 (읽기/쓰기)
	- 고가용성과 부하 분산에 유리
	- 충돌 해결 로직 필요
	- 예: Cassandra, Couchbase

Active-Passive Replication
	- 하나의 노드만 쓰기 처리, 나머지는 대기 또는 읽기 전용
	- 장애 발생 시 Passive 노드로 Failover
	- 단순하고 충돌 없음
	- 예: MySQL MHA, PostgreSQL Streaming Replication

비교 요약
	- Active-Active: 성능 확장 우수, 복잡성 높음
	- Active-Passive: 안정성 우수, 유휴 자원 발생 가능

⸻

94. Vector Clocks(벡터 클락)의 개념과 데이터 정합성 유지 방식

개념
Vector Clock은 각 노드에서의 변경 이력을 벡터로 표현하여, 이벤트 간의 순서를 추론할 수 있게 하는 버전 관리 기법입니다.

사용 방식
	- 각 노드는 자신만의 카운터를 갖고, 변경 시 증가
	- 데이터를 교환할 때 서로의 벡터와 비교
	- 충돌 여부 판단 가능 (동시 발생, 선후 관계 등)

정합성 유지
	- 버전 비교로 충돌 탐지 및 병합 가능
	- Git, DynamoDB, Riak 등에서 활용
	- 완벽한 일관성보다 충돌 감지 및 복구 전략에 초점

⸻

- CDC와 데이터 복제의 차이
	- CDC (Change Data Capture)
		- 변경 이력 중심 데이터 흐름
		- 데이터 변경(Insert/Update/Delete)을 이벤트로 추출
		- 로그 기반, 트리거 기반 등 다양한 방식
		- 실시간 스트리밍 및 이벤트 기반 처리에 적합

	- 데이터 복제(Replication)
		- 데이터베이스의 전체 또는 일부 데이터를 동기화 목적으로 복사
		- 실시간 또는 주기적 수행
		- 단순 백업/재해복구 또는 다중 노드 구성에 활용

	- 비교 요약
		- CDC는 변경 중심 → 이벤트 기반 통합, 실시간 파이프라인
		- 복제는 동기화 중심 → 데이터 일관성 확보, 장애 대비